# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2024, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang 0.3\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-11-09 18:38+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../references/production_metrics.md:1
msgid "Production Metrics"
msgstr ""

#: ../../../references/production_metrics.md:3
msgid ""
"sglang exposes the following metrics via Prometheus. The metrics are "
"namespaced by `$name` (the model name)."
msgstr ""

#: ../../../references/production_metrics.md:5
msgid ""
"An example of the monitoring dashboard is available in [examples/monitoring/"
"grafana.json](../examples/monitoring/grafana.json)."
msgstr ""

#: ../../../references/production_metrics.md:7
msgid "Here is an example of the metrics:"
msgstr ""

#: ../../../references/production_metrics.md:9
msgid ""
"# HELP sglang:max_total_num_tokens Maximum total number of tokens\n"
"# TYPE sglang:max_total_num_tokens gauge\n"
"sglang:max_total_num_tokens{name=\"google/gemma-2-9b-it\"} 161721.0\n"
"# HELP sglang:max_prefill_tokens Maximum prefill tokens\n"
"# TYPE sglang:max_prefill_tokens gauge\n"
"sglang:max_prefill_tokens{name=\"google/gemma-2-9b-it\"} 16384.0\n"
"# HELP sglang:max_running_requests Maximum running requests\n"
"# TYPE sglang:max_running_requests gauge\n"
"sglang:max_running_requests{name=\"google/gemma-2-9b-it\"} 4097.0\n"
"# HELP sglang:context_len Context length\n"
"# TYPE sglang:context_len gauge\n"
"sglang:context_len{name=\"google/gemma-2-9b-it\"} 8192.0\n"
"# HELP sglang:prompt_tokens_total Number of prefill tokens processed.\n"
"# TYPE sglang:prompt_tokens_total counter\n"
"sglang:prompt_tokens_total{name=\"google/gemma-2-9b-it\"} 506780.0\n"
"# HELP sglang:generation_tokens_total Number of generation tokens "
"processed.\n"
"# TYPE sglang:generation_tokens_total counter\n"
"sglang:generation_tokens_total{name=\"google/gemma-2-9b-it\"} 424549.0\n"
"# HELP sglang:num_requests_running Number of requests currently running on "
"GPU\n"
"# TYPE sglang:num_requests_running gauge\n"
"sglang:num_requests_running{name=\"google/gemma-2-9b-it\"} 0.0\n"
"# HELP sglang:num_requests_waiting Number of requests waiting to be "
"processed.\n"
"# TYPE sglang:num_requests_waiting gauge\n"
"sglang:num_requests_waiting{name=\"google/gemma-2-9b-it\"} 0.0\n"
"# HELP sglang:gen_throughput Gen token throughput (token/s)\n"
"# TYPE sglang:gen_throughput gauge\n"
"sglang:gen_throughput{name=\"google/gemma-2-9b-it\"} 0.0\n"
"# HELP sglang:token_usage Total token usage\n"
"# TYPE sglang:token_usage gauge\n"
"sglang:token_usage{name=\"google/gemma-2-9b-it\"} 0.01\n"
"# HELP sglang:new_seq Number of new sequences\n"
"# TYPE sglang:new_seq gauge\n"
"sglang:new_seq{name=\"google/gemma-2-9b-it\"} 0.0\n"
"# HELP sglang:new_token Number of new token\n"
"# TYPE sglang:new_token gauge\n"
"sglang:new_token{name=\"google/gemma-2-9b-it\"} 0.0\n"
"# HELP sglang:cached_token Number of cached token\n"
"# TYPE sglang:cached_token gauge\n"
"sglang:cached_token{name=\"google/gemma-2-9b-it\"} 0.0\n"
"# HELP sglang:cache_hit_rate Cache hit rate\n"
"# TYPE sglang:cache_hit_rate gauge\n"
"sglang:cache_hit_rate{name=\"google/gemma-2-9b-it\"} 10.61\n"
"# HELP sglang:queue_req Number of queued requests\n"
"# TYPE sglang:queue_req gauge\n"
"sglang:queue_req{name=\"google/gemma-2-9b-it\"} 0.0\n"
"# HELP sglang:time_to_first_token_seconds Histogram of time to first token "
"in seconds.\n"
"# TYPE sglang:time_to_first_token_seconds histogram\n"
"sglang:time_to_first_token_seconds_sum{name=\"google/gemma-2-9b-it\"} "
"656.0780844688416\n"
"sglang:time_to_first_token_seconds_bucket{le=\"0.001\",name=\"google/"
"gemma-2-9b-it\"} 0.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"0.005\",name=\"google/"
"gemma-2-9b-it\"} 0.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"0.01\",name=\"google/"
"gemma-2-9b-it\"} 0.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"0.02\",name=\"google/"
"gemma-2-9b-it\"} 0.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"0.04\",name=\"google/"
"gemma-2-9b-it\"} 207.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"0.06\",name=\"google/"
"gemma-2-9b-it\"} 456.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"0.08\",name=\"google/"
"gemma-2-9b-it\"} 598.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"0.1\",name=\"google/"
"gemma-2-9b-it\"} 707.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"0.25\",name=\"google/"
"gemma-2-9b-it\"} 1187.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"0.5\",name=\"google/"
"gemma-2-9b-it\"} 1350.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"0.75\",name=\"google/"
"gemma-2-9b-it\"} 2124.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"1.0\",name=\"google/"
"gemma-2-9b-it\"} 2124.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"2.5\",name=\"google/"
"gemma-2-9b-it\"} 2124.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"5.0\",name=\"google/"
"gemma-2-9b-it\"} 2124.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"7.5\",name=\"google/"
"gemma-2-9b-it\"} 2124.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"10.0\",name=\"google/"
"gemma-2-9b-it\"} 2124.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"15.0\",name=\"google/"
"gemma-2-9b-it\"} 2124.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"20.0\",name=\"google/"
"gemma-2-9b-it\"} 2124.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"25.0\",name=\"google/"
"gemma-2-9b-it\"} 2124.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"30.0\",name=\"google/"
"gemma-2-9b-it\"} 2124.0\n"
"sglang:time_to_first_token_seconds_bucket{le=\"+Inf\",name=\"google/"
"gemma-2-9b-it\"} 2124.0\n"
"sglang:time_to_first_token_seconds_count{name=\"google/gemma-2-9b-it\"} "
"2124.0\n"
"# HELP sglang:time_per_output_token_seconds Histogram of time per output "
"token in seconds.\n"
"# TYPE sglang:time_per_output_token_seconds histogram\n"
"sglang:time_per_output_token_seconds_sum{name=\"google/gemma-2-9b-it\"} "
"29846.5393948555\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.005\",name=\"google/"
"gemma-2-9b-it\"} 0.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.01\",name=\"google/"
"gemma-2-9b-it\"} 0.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.015\",name=\"google/"
"gemma-2-9b-it\"} 0.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.02\",name=\"google/"
"gemma-2-9b-it\"} 9602.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.025\",name=\"google/"
"gemma-2-9b-it\"} 30060.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.03\",name=\"google/"
"gemma-2-9b-it\"} 39184.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.04\",name=\"google/"
"gemma-2-9b-it\"} 61387.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.05\",name=\"google/"
"gemma-2-9b-it\"} 78835.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.075\",name=\"google/"
"gemma-2-9b-it\"} 139394.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.1\",name=\"google/"
"gemma-2-9b-it\"} 422029.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.15\",name=\"google/"
"gemma-2-9b-it\"} 422029.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.2\",name=\"google/"
"gemma-2-9b-it\"} 422029.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.3\",name=\"google/"
"gemma-2-9b-it\"} 422424.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.4\",name=\"google/"
"gemma-2-9b-it\"} 422424.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.5\",name=\"google/"
"gemma-2-9b-it\"} 422425.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"0.75\",name=\"google/"
"gemma-2-9b-it\"} 422425.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"1.0\",name=\"google/"
"gemma-2-9b-it\"} 422425.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"2.5\",name=\"google/"
"gemma-2-9b-it\"} 422425.0\n"
"sglang:time_per_output_token_seconds_bucket{le=\"+Inf\",name=\"google/"
"gemma-2-9b-it\"} 422425.0\n"
"sglang:time_per_output_token_seconds_count{name=\"google/gemma-2-9b-it\"} "
"422425.0\n"
"# HELP sglang:request_prompt_tokens Number of prefill tokens processed\n"
"# TYPE sglang:request_prompt_tokens histogram\n"
"sglang:request_prompt_tokens_sum{name=\"google/gemma-2-9b-it\"} 500552.0\n"
"sglang:request_prompt_tokens_bucket{le=\"1.0\",name=\"google/gemma-2-9b-"
"it\"} 0.0\n"
"sglang:request_prompt_tokens_bucket{le=\"2.0\",name=\"google/gemma-2-9b-"
"it\"} 0.0\n"
"sglang:request_prompt_tokens_bucket{le=\"5.0\",name=\"google/gemma-2-9b-"
"it\"} 22.0\n"
"sglang:request_prompt_tokens_bucket{le=\"10.0\",name=\"google/gemma-2-9b-"
"it\"} 191.0\n"
"sglang:request_prompt_tokens_bucket{le=\"20.0\",name=\"google/gemma-2-9b-"
"it\"} 511.0\n"
"sglang:request_prompt_tokens_bucket{le=\"50.0\",name=\"google/gemma-2-9b-"
"it\"} 825.0\n"
"sglang:request_prompt_tokens_bucket{le=\"100.0\",name=\"google/gemma-2-9b-"
"it\"} 997.0\n"
"sglang:request_prompt_tokens_bucket{le=\"200.0\",name=\"google/gemma-2-9b-"
"it\"} 1182.0\n"
"sglang:request_prompt_tokens_bucket{le=\"500.0\",name=\"google/gemma-2-9b-"
"it\"} 1748.0\n"
"sglang:request_prompt_tokens_bucket{le=\"1000.0\",name=\"google/gemma-2-9b-"
"it\"} 2102.0\n"
"sglang:request_prompt_tokens_bucket{le=\"2000.0\",name=\"google/gemma-2-9b-"
"it\"} 2104.0\n"
"sglang:request_prompt_tokens_bucket{le=\"5000.0\",name=\"google/gemma-2-9b-"
"it\"} 2104.0\n"
"sglang:request_prompt_tokens_bucket{le=\"10000.0\",name=\"google/gemma-2-9b-"
"it\"} 2104.0\n"
"sglang:request_prompt_tokens_bucket{le=\"20000.0\",name=\"google/gemma-2-9b-"
"it\"} 2104.0\n"
"sglang:request_prompt_tokens_bucket{le=\"50000.0\",name=\"google/gemma-2-9b-"
"it\"} 2104.0\n"
"sglang:request_prompt_tokens_bucket{le=\"100000.0\",name=\"google/gemma-2-9b-"
"it\"} 2104.0\n"
"sglang:request_prompt_tokens_bucket{le=\"+Inf\",name=\"google/gemma-2-9b-"
"it\"} 2104.0\n"
"sglang:request_prompt_tokens_count{name=\"google/gemma-2-9b-it\"} 2104.0\n"
"# HELP sglang:request_generation_tokens Number of generation tokens "
"processed.\n"
"# TYPE sglang:request_generation_tokens histogram\n"
"sglang:request_generation_tokens_sum{name=\"google/gemma-2-9b-it\"} "
"424529.0\n"
"sglang:request_generation_tokens_bucket{le=\"1.0\",name=\"google/gemma-2-9b-"
"it\"} 0.0\n"
"sglang:request_generation_tokens_bucket{le=\"2.0\",name=\"google/gemma-2-9b-"
"it\"} 0.0\n"
"sglang:request_generation_tokens_bucket{le=\"5.0\",name=\"google/gemma-2-9b-"
"it\"} 49.0\n"
"sglang:request_generation_tokens_bucket{le=\"10.0\",name=\"google/gemma-2-9b-"
"it\"} 202.0\n"
"sglang:request_generation_tokens_bucket{le=\"20.0\",name=\"google/gemma-2-9b-"
"it\"} 448.0\n"
"sglang:request_generation_tokens_bucket{le=\"50.0\",name=\"google/gemma-2-9b-"
"it\"} 814.0\n"
"sglang:request_generation_tokens_bucket{le=\"100.0\",name=\"google/"
"gemma-2-9b-it\"} 979.0\n"
"sglang:request_generation_tokens_bucket{le=\"200.0\",name=\"google/"
"gemma-2-9b-it\"} 1266.0\n"
"sglang:request_generation_tokens_bucket{le=\"500.0\",name=\"google/"
"gemma-2-9b-it\"} 1883.0\n"
"sglang:request_generation_tokens_bucket{le=\"1000.0\",name=\"google/"
"gemma-2-9b-it\"} 2095.0\n"
"sglang:request_generation_tokens_bucket{le=\"2000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:request_generation_tokens_bucket{le=\"5000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:request_generation_tokens_bucket{le=\"10000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:request_generation_tokens_bucket{le=\"20000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:request_generation_tokens_bucket{le=\"50000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:request_generation_tokens_bucket{le=\"100000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:request_generation_tokens_bucket{le=\"+Inf\",name=\"google/gemma-2-9b-"
"it\"} 2104.0\n"
"sglang:request_generation_tokens_count{name=\"google/gemma-2-9b-it\"} "
"2104.0\n"
"# HELP sglang:e2e_request_latency_seconds Histogram of End-to-end request "
"latency in seconds\n"
"# TYPE sglang:e2e_request_latency_seconds histogram\n"
"sglang:e2e_request_latency_seconds_sum{name=\"google/gemma-2-9b-it\"} "
"70517.99934530258\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"1.0\",name=\"google/"
"gemma-2-9b-it\"} 2.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"2.0\",name=\"google/"
"gemma-2-9b-it\"} 21.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"5.0\",name=\"google/"
"gemma-2-9b-it\"} 54.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"10.0\",name=\"google/"
"gemma-2-9b-it\"} 311.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"20.0\",name=\"google/"
"gemma-2-9b-it\"} 733.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"50.0\",name=\"google/"
"gemma-2-9b-it\"} 1563.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"100.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"200.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"500.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"1000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"2000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"5000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"10000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"20000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"50000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"100000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:e2e_request_latency_seconds_bucket{le=\"+Inf\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:e2e_request_latency_seconds_count{name=\"google/gemma-2-9b-it\"} "
"2104.0\n"
"# HELP sglang:waiting_request_latency_seconds Histogram of request waiting "
"time in seconds\n"
"# TYPE sglang:waiting_request_latency_seconds histogram\n"
"sglang:waiting_request_latency_seconds_sum{name=\"google/gemma-2-9b-it\"} "
"24885.007263183594\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"1.0\",name=\"google/"
"gemma-2-9b-it\"} 421.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"2.0\",name=\"google/"
"gemma-2-9b-it\"} 563.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"5.0\",name=\"google/"
"gemma-2-9b-it\"} 900.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"10.0\",name=\"google/"
"gemma-2-9b-it\"} 1270.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"20.0\",name=\"google/"
"gemma-2-9b-it\"} 1623.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"50.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"100.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"200.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"500.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"1000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"2000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"5000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"10000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"20000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"50000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"100000.0\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:waiting_request_latency_seconds_bucket{le=\"+Inf\",name=\"google/"
"gemma-2-9b-it\"} 2104.0\n"
"sglang:waiting_request_latency_seconds_count{name=\"google/gemma-2-9b-it\"} "
"2104.0\n"
msgstr ""

#: ../../../references/production_metrics.md:189
msgid "Setup Guide"
msgstr ""

#: ../../../references/production_metrics.md:191
msgid ""
"To setup a monitoring dashboard, you can use the following docker compose "
"file: [examples/monitoring/docker-compose.yaml](../examples/monitoring/"
"docker-compose.yaml)."
msgstr ""

#: ../../../references/production_metrics.md:193
msgid "Assume you have sglang server running at `localhost:30000`."
msgstr ""

#: ../../../references/production_metrics.md:195
msgid ""
"To start the monitoring dashboard (prometheus + grafana), cd to `examples/"
"monitoring` and run:"
msgstr ""

#: ../../../references/production_metrics.md:197
msgid "docker compose -f compose.yaml -p monitoring up\n"
msgstr ""

#: ../../../references/production_metrics.md:201
msgid "Then you can access the Grafana dashboard at http://localhost:3000."
msgstr ""

#: ../../../references/production_metrics.md:203
msgid "Grafana Dashboard"
msgstr ""

#: ../../../references/production_metrics.md:205
msgid ""
"To import the Grafana dashboard, click `+` -> `Import` -> `Upload JSON file` "
"-> `Upload` and select [grafana.json](../examples/monitoring/grafana.json)."
msgstr ""
