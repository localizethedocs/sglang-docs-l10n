# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2024, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang 0.3\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-11-09 18:38+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../backend/openai_api_embeddings.ipynb:2
msgid ""
"<style>\n"
"    .output_area.stderr, .output_area.stdout {\n"
"        color: #d3d3d3 !important; /* light gray */\n"
"    }\n"
"</style>"
msgstr ""
"<style>\n"
"    .output_area.stderr, .output_area.stdout {\n"
"        color: #d3d3d3 !important; /* light gray */\n"
"    }\n"
"</style>"

#: ../../../backend/openai_api_embeddings.ipynb:9
msgid "OpenAI APIs - Embedding"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:11
msgid ""
"SGLang provides OpenAI-compatible APIs to enable a smooth transition from "
"OpenAI services to self-hosted local models. A complete reference for the "
"API is available in the `OpenAI API Reference <https://platform.openai.com/"
"docs/guides/embeddings>`__."
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:13
msgid "This tutorial covers the embedding APIs for embedding models, such as"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:15
msgid ""
"`intfloat/e5-mistral-7b-instruct <https://huggingface.co/intfloat/e5-"
"mistral-7b-instruct>`__"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:16
msgid ""
"`Alibaba-NLP/gte-Qwen2-7B-instruct <https://huggingface.co/Alibaba-NLP/gte-"
"Qwen2-7B-instruct>`__"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:28
msgid "Launch A Server"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:30
msgid "The following code is equivalent to running this in the shell:"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:32
msgid ""
"python -m sglang.launch_server --model-path Alibaba-NLP/gte-Qwen2-7B-"
"instruct \\\n"
"    --port 30000 --host 0.0.0.0 --is-embedding"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:37
msgid "Remember to add ``--is-embedding`` to the command."
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:-1
msgid "[ ]:"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:-1
msgid ""
"from sglang.utils import (\n"
"    execute_shell_command,\n"
"    wait_for_server,\n"
"    terminate_process,\n"
"    print_highlight,\n"
")\n"
"\n"
"embedding_process = execute_shell_command(\n"
"    \"\"\"\n"
"python -m sglang.launch_server --model-path Alibaba-NLP/gte-Qwen2-7B-"
"instruct \\\n"
"    --port 30000 --host 0.0.0.0 --is-embedding\n"
"\"\"\"\n"
")\n"
"\n"
"wait_for_server(\"http://localhost:30000\")"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:72
msgid "Using cURL"
msgstr "使用 cURL"

#: ../../../backend/openai_api_embeddings.ipynb:-1
msgid ""
"import subprocess, json\n"
"\n"
"text = \"Once upon a time\"\n"
"\n"
"curl_text = f\"\"\"curl -s http://localhost:30000/v1/embeddings \\\n"
"  -d '{{\"model\": \"Alibaba-NLP/gte-Qwen2-7B-instruct\", \"input\": "
"\"{text}\"}}'\"\"\"\n"
"\n"
"text_embedding = json.loads(subprocess.check_output(curl_text, shell=True))"
"[\"data\"][0][\n"
"    \"embedding\"\n"
"]\n"
"\n"
"print_highlight(f\"Text embedding (first 10): {text_embedding[:10]}\")"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:104
msgid "Using Python Requests"
msgstr "使用 Python Requests"

#: ../../../backend/openai_api_embeddings.ipynb:-1
msgid ""
"import requests\n"
"\n"
"text = \"Once upon a time\"\n"
"\n"
"response = requests.post(\n"
"    \"http://localhost:30000/v1/embeddings\",\n"
"    json={\"model\": \"Alibaba-NLP/gte-Qwen2-7B-instruct\", \"input\": "
"text},\n"
")\n"
"\n"
"text_embedding = response.json()[\"data\"][0][\"embedding\"]\n"
"\n"
"print_highlight(f\"Text embedding (first 10): {text_embedding[:10]}\")"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:136
msgid "Using OpenAI Python Client"
msgstr "使用 OpenAI Python 客戶端"

#: ../../../backend/openai_api_embeddings.ipynb:-1
msgid ""
"import openai\n"
"\n"
"client = openai.Client(base_url=\"http://127.0.0.1:30000/v1\", "
"api_key=\"None\")\n"
"\n"
"# Text embedding example\n"
"response = client.embeddings.create(\n"
"    model=\"Alibaba-NLP/gte-Qwen2-7B-instruct\",\n"
"    input=text,\n"
")\n"
"\n"
"embedding = response.data[0].embedding[:10]\n"
"print_highlight(f\"Text embedding (first 10): {embedding}\")"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:168
msgid "Using Input IDs"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:170
msgid "SGLang also supports ``input_ids`` as input to get the embedding."
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:-1
msgid ""
"import json\n"
"import os\n"
"from transformers import AutoTokenizer\n"
"\n"
"os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
"\n"
"tokenizer = AutoTokenizer.from_pretrained(\"Alibaba-NLP/gte-Qwen2-7B-"
"instruct\")\n"
"input_ids = tokenizer.encode(text)\n"
"\n"
"curl_ids = f\"\"\"curl -s http://localhost:30000/v1/embeddings \\\n"
"  -d '{{\"model\": \"Alibaba-NLP/gte-Qwen2-7B-instruct\", \"input\": {json."
"dumps(input_ids)}}}'\"\"\"\n"
"\n"
"input_ids_embedding = json.loads(subprocess.check_output(curl_ids, "
"shell=True))[\"data\"][\n"
"    0\n"
"][\"embedding\"]\n"
"\n"
"print_highlight(f\"Input IDs embedding (first 10): "
"{input_ids_embedding[:10]}\")"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:-1
msgid "[6]:"
msgstr ""

#: ../../../backend/openai_api_embeddings.ipynb:-1
msgid "terminate_process(embedding_process)"
msgstr ""
