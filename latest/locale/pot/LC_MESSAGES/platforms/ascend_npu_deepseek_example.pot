# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang latest\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-01-05 08:33+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../platforms/ascend_npu_deepseek_example.md:1
msgid "DeepSeek examples"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:3
msgid "Running DeepSeek-V3"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:5
msgid "Running DeepSeek in PD mixed mode on 1 x Atlas 800I A3."
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:7
#: ../../../platforms/ascend_npu_deepseek_example.md:56
msgid ""
"W4A8 Model weights could be found [here](https://modelers.cn/models/"
"Modelers_Park/DeepSeek-R1-0528-w4a8)."
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:9
msgid ""
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"#Deepep communication settings\n"
"export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=32\n"
"export HCCL_BUFFSIZE=1600\n"
"\n"
"#spec overlap\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"\n"
"#npu acceleration operator\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"\n"
"python3 -m sglang.launch_server \\\n"
"    --model-path ${MODEL_PATH} \\\n"
"    --tp 16 \\\n"
"    --trust-remote-code \\\n"
"    --attention-backend ascend \\\n"
"    --device npu \\\n"
"    --quantization modelslim \\\n"
"    --watchdog-timeout 9000 \\\n"
"    --cuda-graph-bs 8 16 24 28 32 \\\n"
"    --mem-fraction-static 0.68 \\\n"
"    --max-running-requests 128 \\\n"
"    --context-length 8188 \\\n"
"    --disable-radix-cache \\\n"
"    --chunked-prefill-size -1 \\\n"
"    --max-prefill-tokens 16384 \\\n"
"    --moe-a2a-backend deepep \\\n"
"    --deepep-mode auto \\\n"
"    --enable-dp-attention \\\n"
"    --dp-size 4 \\\n"
"    --enable-dp-lm-head \\\n"
"    --speculative-algorithm NEXTN \\\n"
"    --speculative-num-steps 3 \\\n"
"    --speculative-eagle-topk 1 \\\n"
"    --speculative-num-draft-tokens 4 \\\n"
"    --dtype bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:54
msgid "Running DeepSeek with PD disaggregation mode on 2 x Atlas 800I A3."
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:58
#: ../../../platforms/ascend_npu_deepseek_example.md:181
msgid "Prefill:"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:60
msgid ""
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"#memfabric config store\n"
"export ASCEND_MF_STORE_URL=\"tcp://<PREFILL_HOST_IP>:<PORT>\"\n"
"\n"
"#Deepep communication settings\n"
"export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"export HCCL_BUFFSIZE=1536\n"
"\n"
"#npu acceleration operator\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"export TASK_QUEUE_ENABLE=2\n"
"\n"
"python -m sglang.launch_server \\\n"
"    --model-path ${MODEL_PATH} \\\n"
"    --host $PREFILL_HOST_IP \\\n"
"    --port 8000 \\\n"
"    --disaggregation-mode prefill \\\n"
"    --disaggregation-bootstrap-port 8996 \\\n"
"    --disaggregation-transfer-backend ascend \\\n"
"    --trust-remote-code \\\n"
"    --nnodes 1 \\\n"
"    --node-rank 0 \\\n"
"    --tp-size 16 \\\n"
"    --mem-fraction-static 0.6 \\\n"
"    --attention-backend ascend \\\n"
"    --device npu \\\n"
"    --quantization modelslim \\\n"
"    --max-running-requests 8 \\\n"
"    --context-length 8192 \\\n"
"    --disable-radix-cache \\\n"
"    --chunked-prefill-size -1 \\\n"
"    --max-prefill-tokens 28680 \\\n"
"    --moe-a2a-backend deepep \\\n"
"    --deepep-mode normal \\\n"
"    --speculative-algorithm NEXTN \\\n"
"    --speculative-num-steps 3 \\\n"
"    --speculative-eagle-topk 1 \\\n"
"    --speculative-num-draft-tokens 4 \\\n"
"    --dp-size 2 \\\n"
"    --enable-dp-attention \\\n"
"    --disable-shared-experts-fusion \\\n"
"    --dtype bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:109
#: ../../../platforms/ascend_npu_deepseek_example.md:238
msgid "Decode:"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:111
msgid ""
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"#memfabric config store\n"
"export ASCEND_MF_STORE_URL=\"tcp://<PREFILL_HOST_IP>:<PORT>\"\n"
"\n"
"#Deepep communication settings\n"
"export HCCL_BUFFSIZE=720\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=88\n"
"\n"
"#spec overlap\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"\n"
"#npu acceleration operator\n"
"unset TASK_QUEUE_ENABLE\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"\n"
"# suggest max-running-requests <= max-cuda-graph-bs * dp_size, Because when "
"this value is exceeded, performance will significantly degrade.\n"
"python -m sglang.launch_server \\\n"
"    --model-path ${MODEL_PATH} \\\n"
"    --disaggregation-mode decode \\\n"
"    --host $DECODE_HOST_IP \\\n"
"    --port 8001 \\\n"
"    --trust-remote-code \\\n"
"    --nnodes 1 \\\n"
"    --node-rank 0 \\\n"
"    --tp-size 16 \\\n"
"    --dp-size 16 \\\n"
"    --mem-fraction-static 0.8 \\\n"
"    --max-running-requests 352 \\\n"
"    --attention-backend ascend \\\n"
"    --device npu \\\n"
"    --quantization modelslim \\\n"
"    --moe-a2a-backend deepep \\\n"
"    --enable-dp-attention \\\n"
"    --deepep-mode low_latency \\\n"
"    --enable-dp-lm-head \\\n"
"    --cuda-graph-bs 8 10 12 14 16 18 20 22 \\\n"
"    --disaggregation-transfer-backend ascend \\\n"
"    --watchdog-timeout 9000 \\\n"
"    --context-length 8192 \\\n"
"    --speculative-algorithm NEXTN \\\n"
"    --speculative-num-steps 3 \\\n"
"    --speculative-eagle-topk 1 \\\n"
"    --speculative-num-draft-tokens 4 \\\n"
"    --disable-shared-experts-fusion \\\n"
"    --dtype bfloat16 \\\n"
"    --tokenizer-worker-num 4\n"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:165
msgid "SGLang Router"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:167
msgid ""
"python -m sglang_router.launch_router \\\n"
"    --pd-disaggregation \\\n"
"    --policy cache_aware \\\n"
"    --prefill http://<PREFILL_HOST_IP>:8000 8996 \\\n"
"    --decode http://<DECODE_HOST_IP>:8001 \\\n"
"    --host 127.0.0.1 \\\n"
"    --port 6688\n"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:177
msgid "Running DeepSeek with PD disaggregation on 4 x Atlas 800I A3."
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:179
msgid ""
"W8A8 Model weights could be found [here](https://modelers.cn/models/"
"State_Cloud/Deepseek-R1-bf16-hfd-w8a8)."
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:183
msgid ""
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"#memfabric config store\n"
"export ASCEND_MF_STORE_URL=\"tcp://<P_HOST_IP[0]>:<PORT>\"\n"
"\n"
"#Deepep communication settings\n"
"export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"export HCCL_BUFFSIZE=1536\n"
"\n"
"#npu acceleration operator\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"export TASK_QUEUE_ENABLE=2\n"
"\n"
"#Please list all host ips of Prefill instance\n"
"P_HOST_IP=('xx,xx,xx,xx' 'xx,xx,xx,xx')\n"
"\n"
"for i in \"${!P_HOST_IP[@]}\";\n"
"do\n"
"  python -m sglang.launch_server \\\n"
"      --model-path ${MODEL_PATH} \\\n"
"      --host ${P_HOST_IP[$i]} \\\n"
"      --port 8000 \\\n"
"      --disaggregation-mode prefill \\\n"
"      --disaggregation-bootstrap-port $((8996+$i)) \\\n"
"      --disaggregation-transfer-backend ascend \\\n"
"      --trust-remote-code \\\n"
"      --nnodes 1 \\\n"
"      --node-rank 0 \\\n"
"      --tp-size 16 \\\n"
"      --mem-fraction-static 0.81 \\\n"
"      --attention-backend ascend \\\n"
"      --device npu \\\n"
"      --quantization modelslim \\\n"
"      --max-running-requests 8 \\\n"
"      --context-length 8192 \\\n"
"      --disable-radix-cache \\\n"
"      --chunked-prefill-size -1 \\\n"
"      --max-prefill-tokens 28680 \\\n"
"      --moe-a2a-backend deepep \\\n"
"      --deepep-mode normal \\\n"
"      --speculative-algorithm NEXTN \\\n"
"      --speculative-num-steps 1 \\\n"
"      --speculative-eagle-topk 1 \\\n"
"      --speculative-num-draft-tokens 2 \\\n"
"      --dp-size 2 \\\n"
"      --enable-dp-attention \\\n"
"      --disable-shared-experts-fusion \\\n"
"      --dtype bfloat16\n"
"done\n"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:240
msgid ""
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"#memfabric config store\n"
"export ASCEND_MF_STORE_URL=\"tcp://<P_HOST_IP[0]>:<PORT>\"\n"
"\n"
"#Deepep communication settings\n"
"export HCCL_BUFFSIZE=600\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=78\n"
"\n"
"#spec overlap\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"\n"
"#npu acceleration operator\n"
"unset TASK_QUEUE_ENABLE\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"\n"
"#please list all host ips of Prefill instance\n"
"D_HOST_IP=('xx,xx,xx,xx' 'xx,xx,xx,xx')\n"
"\n"
"for i in \"${!D_HOST_IP[@]}\";\n"
"do\n"
"  python -m sglang.launch_server\n"
"      --model-path ${MODEL_PATH} \\\n"
"      --disaggregation-mode decode \\\n"
"      --disaggregation-transfer-backend ascend \\\n"
"      --host ${D_HOST_IP[$i]} \\\n"
"      --port 8001 \\\n"
"      --trust-remote-code \\\n"
"      --dist-init-addr ${D_HOST_IP[0]}:5000 \\\n"
"      --nnodes 2 \\\n"
"      --node-rank $i \\\n"
"      --tp-size 32 \\\n"
"      --dp-size 32 \\\n"
"      --mem-fraction-static 0.8 \\\n"
"      --max-running-requests 832 \\\n"
"      --attention-backend ascend \\\n"
"      --device npu \\\n"
"      --quantization modelslim \\\n"
"      --moe-a2a-backend deepep \\\n"
"      --enable-dp-attention \\\n"
"      --deepep-mode low_latency \\\n"
"      --enable-dp-lm-head \\\n"
"      --cuda-graph-bs  8 10 12 14 16 18 20 22 24 26 \\\n"
"      --watchdog-timeout 9000 \\\n"
"      --context-length 8192 \\\n"
"      --speculative-algorithm NEXTN \\\n"
"      --speculative-num-steps 2 \\\n"
"      --speculative-eagle-topk 1 \\\n"
"      --speculative-num-draft-tokens 3  \\\n"
"      --tokenizer-worker-num 4 \\\n"
"      --disable-shared-experts-fusion \\\n"
"      --dtype bfloat16\n"
"done\n"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:300
msgid "SGLang Router:"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:302
msgid ""
"python -m sglang_router.launch_router \\\n"
"    --pd-disaggregation \\\n"
"    --policy cache_aware \\\n"
"    --prefill http://<P_HOST_IP[0]>:8000 8996 \\\n"
"    --prefill http://<P_HOST_IP[1]>:8000 8997 \\\n"
"    --decode http://<D_HOST_IP[0]>:8001 \\\n"
"    --host 127.0.0.1 \\\n"
"    --port 6688\n"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:313
msgid "test gsm8k"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:315
msgid ""
"from types import SimpleNamespace\n"
"from sglang.test.few_shot_gsm8k import run_eval\n"
"\n"
"def gsm8k():\n"
"    args = SimpleNamespace(\n"
"        num_shots=5,\n"
"        data_path=None,\n"
"        num_questions=200,\n"
"        max_new_tokens=512,\n"
"        parallel=32,\n"
"        host=f\"http://127.0.0.1\",\n"
"        port=6688,\n"
"    )\n"
"    metrics = run_eval(args)\n"
"    print(f\"{metrics=}\")\n"
"    print(f\"{metrics['accuracy']=}\")\n"
"if __name__ == \"__main__\":\n"
"    gsm8k()\n"
msgstr ""
