# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2026, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang latest\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-02-16 08:46+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../platforms/ascend_npu_best_practice.md:1
msgid "Best Practice on Ascend NPU"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3
msgid ""
"This section describes the best practice data of mainstream LLM models such "
"as DeepSeek and Qwen on the Ascend NPU. If you encounter issues or have any "
"questions, please [open an issue](https://github.com/sgl-project/sglang/"
"issues)."
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:6
msgid "DeepSeek Series Models"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:8
#: ../../../platforms/ascend_npu_best_practice.md:30
msgid "Low Latency"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Model"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Hardware"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Cards"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Deploy Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Dataset"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "TPOT"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Quantization"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Configuration"
msgstr "組態"

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Deepseek-R1"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Atlas 800I A3"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "32"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "PD Separation"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "6K+1.6K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "20ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "W8A8 INT8"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#deepseek-r1-6k-1_6k-20ms-on-a3-32-cards-separation-"
"mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "3.9K+1K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#deepseek-r1-3_9k-1k-20ms-on-a3-32-cards-separation-"
"mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "3.5K+1.5K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#deepseek-r1-3_5k-1_5k-20ms-on-a3-32-cards-"
"separation-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "3.5K+1K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#deepseek-r1-3_5k-1k-20ms-on-a3-32-cards-separation-"
"mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "DeepSeek-V3.2-Exp"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "64K+3K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "30ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#deepseek-v32-exp-64k-3k-30ms-on-a3-32-cards-"
"separation-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:18
#: ../../../platforms/ascend_npu_best_practice.md:41
msgid "High Throughput"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#deepseek-r1-3_5k-1_5k-50ms-on-a3-32-cards-"
"separation-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "8"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "PD Mixed"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "2K+2K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "W4A8 INT8"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#deepseek-r1-2k-2k-50ms-on-a3-8-cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "16"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#deepseek-r1-2k-2k-50ms-on-a3-16-cards-separation-"
"mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#deepseek-r1-3_5k-1_5k-50ms-on-a3-8-cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#deepseek-r1-3_5k-1_5k-50ms-on-a3-16-cards-"
"separation-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:28
msgid "Qwen Series Models"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Qwen3-235B-A22B"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "11K+1K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "10ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "BF16"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-235b-a22b-11k-1k-10ms-on-a3-8-cards-mixed-"
"mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Qwen3-32B"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "4"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "6K+1.5K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "18ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-32b-6k-1_5k-18ms-on-a3-4-cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "4K+1.5K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "11ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-32b-4k-1_5k-11ms-on-a3-4-cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "18K+4K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "12ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-32b-18k-4k-12ms-on-a3-8-cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Atlas 800I A2"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-32b-6k-1_5k-18ms-on-a2-8-cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-32b-4k-1_5k-11ms-on-a2-8-cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "24"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-235b-a22b-3_5k-1_5k-50ms-on-a3-24-cards-"
"separation-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-235b-a22b-3_5k-1_5k-50ms-on-a3-8-cards-mixed-"
"mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "100ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-235b-a22b-2k-2k-100ms-on-a3-8-cards-mixed-"
"mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-235b-a22b-2k-2k-50ms-on-a3-8-cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-235b-a22b-2k-2k-50ms-on-a3-16-cards-mixed-"
"mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "2"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-32b-3_5k-1_5k-50ms-on-a3-2-cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-32b-2k-2k-50ms-on-a3-2-cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Qwen3-30B-A3B"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "1"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-30b-a3b-3_5k-1_5k-50ms-on-a3-1-card-mixed-"
"mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Qwen3-Coder-480B-A35B-Instruct"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-coder-480b-a35b-instruct-3_5k-1_5k-50ms-on-"
"a3-24-cards-separation-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-coder-480b-a35b-instruct-3_5k-1_5k-50ms-on-"
"a3-16-cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-coder-480b-a35b-instruct-3_5k-1_5k-50ms-on-"
"a3-8-cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Qwen3-Next-80B-A3B-Instruct"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-next-80B-a3b-instruct-3_5k-1_5k-50ms-on-a3-2-"
"cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid ""
"[Optimal Configuration](#qwen3-32b-3_5k-1_5k-50ms-on-a2-8-cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-32b-2k-2k-50ms-on-a2-8-cards-mixed-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:60
msgid "Optimal Configuration"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:62
msgid "DeepSeek-R1 3_5K-1_5K 50ms on A3 32 Cards Separation Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:64
#: ../../../platforms/ascend_npu_best_practice.md:183
#: ../../../platforms/ascend_npu_best_practice.md:300
#: ../../../platforms/ascend_npu_best_practice.md:326
#: ../../../platforms/ascend_npu_best_practice.md:352
#: ../../../platforms/ascend_npu_best_practice.md:378
#: ../../../platforms/ascend_npu_best_practice.md:458
#: ../../../platforms/ascend_npu_best_practice.md:583
#: ../../../platforms/ascend_npu_best_practice.md:660
msgid "Model: Deepseek R1"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:66
#: ../../../platforms/ascend_npu_best_practice.md:185
#: ../../../platforms/ascend_npu_best_practice.md:302
#: ../../../platforms/ascend_npu_best_practice.md:328
#: ../../../platforms/ascend_npu_best_practice.md:354
#: ../../../platforms/ascend_npu_best_practice.md:786
msgid "Hardware: Atlas 800I A3 32Card"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:68
#: ../../../platforms/ascend_npu_best_practice.md:187
#: ../../../platforms/ascend_npu_best_practice.md:304
#: ../../../platforms/ascend_npu_best_practice.md:330
#: ../../../platforms/ascend_npu_best_practice.md:356
#: ../../../platforms/ascend_npu_best_practice.md:462
#: ../../../platforms/ascend_npu_best_practice.md:664
#: ../../../platforms/ascend_npu_best_practice.md:788
#: ../../../platforms/ascend_npu_best_practice.md:999
#: ../../../platforms/ascend_npu_best_practice.md:1930
msgid "DeployMode: PD Separation"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:70
#: ../../../platforms/ascend_npu_best_practice.md:189
#: ../../../platforms/ascend_npu_best_practice.md:306
#: ../../../platforms/ascend_npu_best_practice.md:332
#: ../../../platforms/ascend_npu_best_practice.md:358
#: ../../../platforms/ascend_npu_best_practice.md:384
#: ../../../platforms/ascend_npu_best_practice.md:464
#: ../../../platforms/ascend_npu_best_practice.md:589
#: ../../../platforms/ascend_npu_best_practice.md:666
#: ../../../platforms/ascend_npu_best_practice.md:790
#: ../../../platforms/ascend_npu_best_practice.md:1001
#: ../../../platforms/ascend_npu_best_practice.md:1137
#: ../../../platforms/ascend_npu_best_practice.md:1210
#: ../../../platforms/ascend_npu_best_practice.md:1282
#: ../../../platforms/ascend_npu_best_practice.md:1354
#: ../../../platforms/ascend_npu_best_practice.md:1439
#: ../../../platforms/ascend_npu_best_practice.md:1512
#: ../../../platforms/ascend_npu_best_practice.md:1583
#: ../../../platforms/ascend_npu_best_practice.md:1653
#: ../../../platforms/ascend_npu_best_practice.md:1722
#: ../../../platforms/ascend_npu_best_practice.md:1792
#: ../../../platforms/ascend_npu_best_practice.md:1862
#: ../../../platforms/ascend_npu_best_practice.md:1932
#: ../../../platforms/ascend_npu_best_practice.md:2056
#: ../../../platforms/ascend_npu_best_practice.md:2139
#: ../../../platforms/ascend_npu_best_practice.md:2207
#: ../../../platforms/ascend_npu_best_practice.md:2276
#: ../../../platforms/ascend_npu_best_practice.md:2345
#: ../../../platforms/ascend_npu_best_practice.md:2418
#: ../../../platforms/ascend_npu_best_practice.md:2488
msgid "Dataset: random"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:72
#: ../../../platforms/ascend_npu_best_practice.md:334
#: ../../../platforms/ascend_npu_best_practice.md:591
#: ../../../platforms/ascend_npu_best_practice.md:668
#: ../../../platforms/ascend_npu_best_practice.md:1003
#: ../../../platforms/ascend_npu_best_practice.md:1139
#: ../../../platforms/ascend_npu_best_practice.md:1724
#: ../../../platforms/ascend_npu_best_practice.md:1864
#: ../../../platforms/ascend_npu_best_practice.md:1934
#: ../../../platforms/ascend_npu_best_practice.md:2058
#: ../../../platforms/ascend_npu_best_practice.md:2141
#: ../../../platforms/ascend_npu_best_practice.md:2209
#: ../../../platforms/ascend_npu_best_practice.md:2420
msgid "Input Output Length: 3.5K+1.5K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:74
#: ../../../platforms/ascend_npu_best_practice.md:388
#: ../../../platforms/ascend_npu_best_practice.md:468
#: ../../../platforms/ascend_npu_best_practice.md:593
#: ../../../platforms/ascend_npu_best_practice.md:670
#: ../../../platforms/ascend_npu_best_practice.md:1005
#: ../../../platforms/ascend_npu_best_practice.md:1141
#: ../../../platforms/ascend_npu_best_practice.md:1286
#: ../../../platforms/ascend_npu_best_practice.md:1358
#: ../../../platforms/ascend_npu_best_practice.md:1726
#: ../../../platforms/ascend_npu_best_practice.md:1796
#: ../../../platforms/ascend_npu_best_practice.md:1866
#: ../../../platforms/ascend_npu_best_practice.md:1936
#: ../../../platforms/ascend_npu_best_practice.md:2060
#: ../../../platforms/ascend_npu_best_practice.md:2143
#: ../../../platforms/ascend_npu_best_practice.md:2211
#: ../../../platforms/ascend_npu_best_practice.md:2422
#: ../../../platforms/ascend_npu_best_practice.md:2492
msgid "TPOT: 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:76
#: ../../../platforms/ascend_npu_best_practice.md:195
#: ../../../platforms/ascend_npu_best_practice.md:312
#: ../../../platforms/ascend_npu_best_practice.md:338
#: ../../../platforms/ascend_npu_best_practice.md:364
#: ../../../platforms/ascend_npu_best_practice.md:390
#: ../../../platforms/ascend_npu_best_practice.md:470
#: ../../../platforms/ascend_npu_best_practice.md:595
#: ../../../platforms/ascend_npu_best_practice.md:672
#: ../../../platforms/ascend_npu_best_practice.md:796
#: ../../../platforms/ascend_npu_best_practice.md:1007
#: ../../../platforms/ascend_npu_best_practice.md:1143
#: ../../../platforms/ascend_npu_best_practice.md:1216
#: ../../../platforms/ascend_npu_best_practice.md:1288
#: ../../../platforms/ascend_npu_best_practice.md:1360
#: ../../../platforms/ascend_npu_best_practice.md:1445
#: ../../../platforms/ascend_npu_best_practice.md:1518
#: ../../../platforms/ascend_npu_best_practice.md:1589
#: ../../../platforms/ascend_npu_best_practice.md:1659
#: ../../../platforms/ascend_npu_best_practice.md:1728
#: ../../../platforms/ascend_npu_best_practice.md:1798
#: ../../../platforms/ascend_npu_best_practice.md:1868
#: ../../../platforms/ascend_npu_best_practice.md:1938
#: ../../../platforms/ascend_npu_best_practice.md:2062
#: ../../../platforms/ascend_npu_best_practice.md:2145
#: ../../../platforms/ascend_npu_best_practice.md:2213
#: ../../../platforms/ascend_npu_best_practice.md:2282
#: ../../../platforms/ascend_npu_best_practice.md:2351
#: ../../../platforms/ascend_npu_best_practice.md:2424
#: ../../../platforms/ascend_npu_best_practice.md:2494
msgid "Model Deployment"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:78
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"export ASCEND_MF_STORE_URL=\"tcp://your prefill ip1:24669\"\n"
"\n"
"P_IP=('your prefill ip1' 'your prefill ip2')\n"
"\n"
"D_IP=('your decode ip1' 'your decode ip2')\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"# prefill\n"
"for i in \"${!P_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${P_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${P_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${P_IP[$i]}\"\n"
"        export HCCL_BUFFSIZE=1536\n"
"        export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"        export TASK_QUEUE_ENABLE=2\n"
"\n"
"        export HCCL_SOCKET_IFNAME=lo\n"
"        export GLOO_SOCKET_IFNAME=lo\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH}  --"
"disaggregation-mode prefill --host ${P_IP[$i]} \\\n"
"        --port 8000 --disaggregation-bootstrap-port $((8998+$i)) --trust-"
"remote-code --nnodes 1 --node-rank 0 \\\n"
"        --tp-size 16 --mem-fraction-static 0.81 --attention-backend ascend --"
"device npu --quantization modelslim \\\n"
"        --disaggregation-transfer-backend ascend --max-running-requests 8 --"
"context-length 8192  --disable-radix-cache \\\n"
"        --chunked-prefill-size -1 --max-prefill-tokens 28680 --moe-a2a-"
"backend deepep --deepep-mode normal \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 1 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 2  \\\n"
"        --dp-size 2 --enable-dp-attention --disable-shared-experts-fusion --"
"dtype bfloat16 --enable-attn-tp-input-scattered\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
"# decode\n"
"for i in \"${!D_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${D_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${D_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${D_IP[$i]}\"\n"
"        export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"        export SGLANG_ENABLE_SPEC_V2=1\n"
"        export HCCL_BUFFSIZE=650\n"
"        export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=78\n"
"        export TASK_QUEUE_ENABLE=1\n"
"        export SGLANG_SCHEDULER_SKIP_ALL_GATHER=1\n"
"        export HCCL_SOCKET_IFNAME=xxx\n"
"        export GLOO_SOCKET_IFNAME=xxx\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode decode --host ${D_IP[$i]} \\\n"
"        --port 8001 --trust-remote-code --dist-init-addr ${D_IP[0]}:5000 --"
"nnodes 2 --node-rank $i --tp-size 32 --dp-size 32 \\\n"
"        --mem-fraction-static 0.815 --max-running-requests 832 --attention-"
"backend ascend --device npu --quantization modelslim \\\n"
"        --moe-a2a-backend deepep --enable-dp-attention --deepep-mode "
"low_latency --enable-dp-lm-head --moe-dense-tp 1 \\\n"
"        --cuda-graph-bs 12 14 16 18 20 22 24 26 --disaggregation-transfer-"
"backend ascend --watchdog-timeout 9000 --context-length 8192 \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 2 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 3  \\\n"
"        --tokenizer-worker-num 4 --prefill-round-robin-balance --disable-"
"shared-experts-fusion --dtype bfloat16 \\\n"
"        --load-balance-method decode_round_robin\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:160
#: ../../../platforms/ascend_npu_best_practice.md:277
msgid ""
"export SGLANG_DP_ROUND_ROBIN=1\n"
"python -m sglang_router.launch_router \\\n"
"    --pd-disaggregation \\\n"
"    --policy cache_aware \\\n"
"    --prefill http://P_IP:8000 8998 \\\n"
"    --prefill http://P_IP:8000 8999 \\\n"
"    --decode http://D_IP:8001 \\\n"
"    --host 127.0.0.1 \\\n"
"    --port 6688 \\\n"
"    --mini-lb\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:173
#: ../../../platforms/ascend_npu_best_practice.md:290
#: ../../../platforms/ascend_npu_best_practice.md:316
#: ../../../platforms/ascend_npu_best_practice.md:342
#: ../../../platforms/ascend_npu_best_practice.md:368
#: ../../../platforms/ascend_npu_best_practice.md:448
#: ../../../platforms/ascend_npu_best_practice.md:573
#: ../../../platforms/ascend_npu_best_practice.md:650
#: ../../../platforms/ascend_npu_best_practice.md:774
#: ../../../platforms/ascend_npu_best_practice.md:985
#: ../../../platforms/ascend_npu_best_practice.md:1121
#: ../../../platforms/ascend_npu_best_practice.md:1194
#: ../../../platforms/ascend_npu_best_practice.md:1266
#: ../../../platforms/ascend_npu_best_practice.md:1338
#: ../../../platforms/ascend_npu_best_practice.md:1423
#: ../../../platforms/ascend_npu_best_practice.md:1496
#: ../../../platforms/ascend_npu_best_practice.md:1567
#: ../../../platforms/ascend_npu_best_practice.md:1637
#: ../../../platforms/ascend_npu_best_practice.md:1706
#: ../../../platforms/ascend_npu_best_practice.md:1776
#: ../../../platforms/ascend_npu_best_practice.md:1846
#: ../../../platforms/ascend_npu_best_practice.md:1916
#: ../../../platforms/ascend_npu_best_practice.md:2040
#: ../../../platforms/ascend_npu_best_practice.md:2123
#: ../../../platforms/ascend_npu_best_practice.md:2191
#: ../../../platforms/ascend_npu_best_practice.md:2260
#: ../../../platforms/ascend_npu_best_practice.md:2329
#: ../../../platforms/ascend_npu_best_practice.md:2402
#: ../../../platforms/ascend_npu_best_practice.md:2472
#: ../../../platforms/ascend_npu_best_practice.md:2541
msgid "Benchmark"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:175
#: ../../../platforms/ascend_npu_best_practice.md:292
#: ../../../platforms/ascend_npu_best_practice.md:318
#: ../../../platforms/ascend_npu_best_practice.md:344
#: ../../../platforms/ascend_npu_best_practice.md:370
#: ../../../platforms/ascend_npu_best_practice.md:450
#: ../../../platforms/ascend_npu_best_practice.md:575
#: ../../../platforms/ascend_npu_best_practice.md:652
#: ../../../platforms/ascend_npu_best_practice.md:776
#: ../../../platforms/ascend_npu_best_practice.md:987
#: ../../../platforms/ascend_npu_best_practice.md:1123
#: ../../../platforms/ascend_npu_best_practice.md:1196
#: ../../../platforms/ascend_npu_best_practice.md:1268
#: ../../../platforms/ascend_npu_best_practice.md:1340
#: ../../../platforms/ascend_npu_best_practice.md:1425
#: ../../../platforms/ascend_npu_best_practice.md:1498
#: ../../../platforms/ascend_npu_best_practice.md:1569
#: ../../../platforms/ascend_npu_best_practice.md:1639
#: ../../../platforms/ascend_npu_best_practice.md:1708
#: ../../../platforms/ascend_npu_best_practice.md:1778
#: ../../../platforms/ascend_npu_best_practice.md:1848
#: ../../../platforms/ascend_npu_best_practice.md:1918
#: ../../../platforms/ascend_npu_best_practice.md:2042
#: ../../../platforms/ascend_npu_best_practice.md:2125
#: ../../../platforms/ascend_npu_best_practice.md:2193
#: ../../../platforms/ascend_npu_best_practice.md:2262
#: ../../../platforms/ascend_npu_best_practice.md:2331
#: ../../../platforms/ascend_npu_best_practice.md:2404
#: ../../../platforms/ascend_npu_best_practice.md:2474
#: ../../../platforms/ascend_npu_best_practice.md:2543
msgid "We tested it based on the `RANDOM` dataset."
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:177
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 768  --random-input-len 3500 --"
"random-output-len 1500 --num-prompts 3072 --random-range-ratio 1 --request-"
"rate 16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:181
msgid "DeepSeek-R1 6K-1_6K 20ms on A3 32 Cards Separation Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:191
msgid "Input Output Length: 6K+1.6K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:193
#: ../../../platforms/ascend_npu_best_practice.md:310
#: ../../../platforms/ascend_npu_best_practice.md:336
#: ../../../platforms/ascend_npu_best_practice.md:362
msgid "TPOT: 20ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:197
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"export ASCEND_MF_STORE_URL=\"tcp://your prefill ip1:24669\"\n"
"\n"
"P_IP=('your prefill ip1' 'your prefill ip2')\n"
"\n"
"D_IP=('your decode ip1' 'your decode ip2')\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"# prefill\n"
"for i in \"${!P_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${P_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${P_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${P_IP[$i]}\"\n"
"        export HCCL_BUFFSIZE=1536\n"
"        export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"        export TASK_QUEUE_ENABLE=2\n"
"\n"
"        export HCCL_SOCKET_IFNAME=lo\n"
"        export GLOO_SOCKET_IFNAME=lo\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH}  --"
"disaggregation-mode prefill --host ${P_IP[$i]} \\\n"
"        --port 8000 --disaggregation-bootstrap-port $((8998+$i)) --trust-"
"remote-code --nnodes 1 --node-rank 0 \\\n"
"        --tp-size 16 --mem-fraction-static 0.81 --attention-backend ascend --"
"device npu --quantization modelslim \\\n"
"        --disaggregation-transfer-backend ascend --max-running-requests 4 --"
"context-length 8192  --disable-radix-cache \\\n"
"        --chunked-prefill-size -1 --max-prefill-tokens 28680 --moe-a2a-"
"backend deepep --deepep-mode normal \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 1 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 2  \\\n"
"        --dp-size 2 --enable-dp-attention --disable-shared-experts-fusion --"
"dtype bfloat16 --enable-attn-tp-input-scattered\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
"# decode\n"
"for i in \"${!D_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${D_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${D_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${D_IP[$i]}\"\n"
"        export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"        export SGLANG_ENABLE_SPEC_V2=1\n"
"        export HCCL_BUFFSIZE=650\n"
"        export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=12\n"
"        export TASK_QUEUE_ENABLE=1\n"
"        export SGLANG_SCHEDULER_SKIP_ALL_GATHER=1\n"
"        export HCCL_SOCKET_IFNAME=xxx\n"
"        export GLOO_SOCKET_IFNAME=xxx\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode decode --host ${D_IP[$i]} \\\n"
"        --port 8001 --trust-remote-code --dist-init-addr DIP1:5000 --nnodes "
"2 --node-rank $i --tp-size 32 --dp-size 16 \\\n"
"        --mem-fraction-static 0.75 --max-running-requests 32 --attention-"
"backend ascend --device npu --quantization modelslim \\\n"
"        --moe-a2a-backend deepep --enable-dp-attention --deepep-mode "
"low_latency --enable-dp-lm-head --moe-dense-tp 1 \\\n"
"        --cuda-graph-bs 2 4 6 --disaggregation-transfer-backend ascend --"
"watchdog-timeout 9000 --context-length 8192 \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 3 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 4  \\\n"
"        --tokenizer-worker-num 4 --prefill-round-robin-balance --disable-"
"shared-experts-fusion --dtype bfloat16 \\\n"
"        --load-balance-method decode_round_robin\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:294
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 32  --random-input-len 6000 --random-"
"output-len 1600 --num-prompts 32 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:298
msgid "DeepSeek-R1 3_9K-1K 20ms on A3 32 Cards Separation Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:308
msgid "Input Output Length: 3.9K+1K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:314
#: ../../../platforms/ascend_npu_best_practice.md:340
#: ../../../platforms/ascend_npu_best_practice.md:366
msgid ""
"Please Turn to [DeepSeek-R1 6K-1_6K 20ms on A3 32 Cards Separation Mode]"
"(#deepseek-r1-6k-1_6k-20ms-on-a3-32-cards-separation-mode)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:320
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 768  --random-input-len 3900 --"
"random-output-len 1000 --num-prompts 768 --random-range-ratio 1 --request-"
"rate 16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:324
msgid "DeepSeek-R1 3_5K-1_5K 20ms on A3 32 Cards Separation Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:346
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 768  --random-input-len 3500 --"
"random-output-len 1500 --num-prompts 768 --random-range-ratio 1 --request-"
"rate 16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:350
msgid "DeepSeek-R1 3_5K-1K 20ms on A3 32 Cards Separation Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:360
msgid "Input Output Length: 3.5K+1K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:372
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 768  --random-input-len 3500 --"
"random-output-len 1000 --num-prompts 768 --random-range-ratio 1 --request-"
"rate 16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:376
msgid "DeepSeek-R1 2K-2K 50ms on A3 8 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:380
#: ../../../platforms/ascend_npu_best_practice.md:585
#: ../../../platforms/ascend_npu_best_practice.md:1133
#: ../../../platforms/ascend_npu_best_practice.md:1206
#: ../../../platforms/ascend_npu_best_practice.md:1278
#: ../../../platforms/ascend_npu_best_practice.md:1435
#: ../../../platforms/ascend_npu_best_practice.md:1649
#: ../../../platforms/ascend_npu_best_practice.md:2135
msgid "Hardware: Atlas 800I A3 8Card"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:382
#: ../../../platforms/ascend_npu_best_practice.md:587
#: ../../../platforms/ascend_npu_best_practice.md:1135
#: ../../../platforms/ascend_npu_best_practice.md:1208
#: ../../../platforms/ascend_npu_best_practice.md:1280
#: ../../../platforms/ascend_npu_best_practice.md:1352
#: ../../../platforms/ascend_npu_best_practice.md:1437
#: ../../../platforms/ascend_npu_best_practice.md:1510
#: ../../../platforms/ascend_npu_best_practice.md:1581
#: ../../../platforms/ascend_npu_best_practice.md:1651
#: ../../../platforms/ascend_npu_best_practice.md:1720
#: ../../../platforms/ascend_npu_best_practice.md:1790
#: ../../../platforms/ascend_npu_best_practice.md:1860
#: ../../../platforms/ascend_npu_best_practice.md:2054
#: ../../../platforms/ascend_npu_best_practice.md:2137
#: ../../../platforms/ascend_npu_best_practice.md:2205
#: ../../../platforms/ascend_npu_best_practice.md:2274
#: ../../../platforms/ascend_npu_best_practice.md:2343
#: ../../../platforms/ascend_npu_best_practice.md:2416
#: ../../../platforms/ascend_npu_best_practice.md:2486
msgid "DeployMode: PD Mixed"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:386
#: ../../../platforms/ascend_npu_best_practice.md:466
#: ../../../platforms/ascend_npu_best_practice.md:1212
#: ../../../platforms/ascend_npu_best_practice.md:1284
#: ../../../platforms/ascend_npu_best_practice.md:1356
#: ../../../platforms/ascend_npu_best_practice.md:1794
#: ../../../platforms/ascend_npu_best_practice.md:2490
msgid "Input Output Length: 2K+2K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:392
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"export SGLANG_SCHEDULER_DECREASE_PREFILL_IDLE=1\n"
"\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=64\n"
"export HCCL_BUFFSIZE=1600\n"
"export DEEPEP_NORMAL_LONG_SEQ_ROUND=10\n"
"export DEEPEP_NORMAL_LONG_SEQ_PER_ROUND_TOKENS=512\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"\n"
"python3 -m sglang.launch_server --model-path ${MODEL_PATH} \\\n"
"--tp 16 \\\n"
"--trust-remote-code \\\n"
"--attention-backend ascend \\\n"
"--device npu \\\n"
"--quantization modelslim \\\n"
"--watchdog-timeout 9000 \\\n"
"--host 127.0.0.1 --port 6699 \\\n"
"--cuda-graph-bs 4 8 16 \\\n"
"--mem-fraction-static 0.74 \\\n"
"--max-running-requests 256 \\\n"
"--disable-radix-cache --chunked-prefill-size -1 --max-prefill-tokens 1500 "
"\\\n"
"--moe-a2a-backend deepep --deepep-mode auto \\\n"
"--enable-dp-attention --dp-size 16 --enable-dp-lm-head \\\n"
"--speculative-algorithm NEXTN --speculative-num-steps 3 --speculative-eagle-"
"topk 1 --speculative-num-draft-tokens 4 \\\n"
"--dtype bfloat16\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:452
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6699 --max-concurrency 256  --random-input-len 2048 --"
"random-output-len 2048 --num-prompts 1024 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:456
msgid "DeepSeek-R1 2K-2K 50ms on A3 16 Cards Separation Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:460
#: ../../../platforms/ascend_npu_best_practice.md:662
#: ../../../platforms/ascend_npu_best_practice.md:1350
#: ../../../platforms/ascend_npu_best_practice.md:2052
msgid "Hardware: Atlas 800I A3 16Card"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:472
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"export ASCEND_MF_STORE_URL=\"tcp://your prefill ip1:24667\"\n"
"\n"
"P_IP=('your prefill ip1')\n"
"\n"
"D_IP=('your decode ip1')\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"# prefill\n"
"for i in \"${!P_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${P_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${P_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${P_IP[$i]}\"\n"
"        export HCCL_BUFFSIZE=1536\n"
"        export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"        export TASK_QUEUE_ENABLE=2\n"
"\n"
"        export HCCL_SOCKET_IFNAME=lo\n"
"        export GLOO_SOCKET_IFNAME=lo\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH}  --"
"disaggregation-mode prefill --host ${P_IP[$i]} \\\n"
"        --port 8000 --disaggregation-bootstrap-port $((8998+$i)) --trust-"
"remote-code --nnodes 1 --node-rank 0 \\\n"
"        --tp-size 16 --mem-fraction-static 0.6 --attention-backend ascend --"
"device npu --quantization modelslim \\\n"
"        --disaggregation-transfer-backend ascend --max-running-requests 8 --"
"context-length 8192  --disable-radix-cache \\\n"
"        --chunked-prefill-size 32768 --max-prefill-tokens 28680 --moe-a2a-"
"backend deepep --deepep-mode normal \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 1 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 2  \\\n"
"        --dp-size 2 --enable-dp-attention --disable-shared-experts-fusion --"
"dtype bfloat16\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
"# decode\n"
"for i in \"${!D_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${D_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${D_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${D_IP[$i]}\"\n"
"        export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"        export SGLANG_ENABLE_SPEC_V2=1\n"
"        export HCCL_BUFFSIZE=720\n"
"        export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=96\n"
"        export TASK_QUEUE_ENABLE=1\n"
"        export HCCL_SOCKET_IFNAME=xxx\n"
"        export GLOO_SOCKET_IFNAME=xxx\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode decode --host ${D_IP[$i]} \\\n"
"        --port 8001 --trust-remote-code --nnodes 1 --node-rank 0 --tp-size "
"16 --dp-size 16 \\\n"
"        --mem-fraction-static 0.8 --max-running-requests 384 --attention-"
"backend ascend --device npu --quantization modelslim \\\n"
"        --moe-a2a-backend deepep --enable-dp-attention --deepep-mode "
"low_latency --enable-dp-lm-head \\\n"
"        --cuda-graph-bs 8 10 12 14 16 18 20 22 24 --disaggregation-transfer-"
"backend ascend --watchdog-timeout 9000 --context-length 8192 \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 3 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 4  \\\n"
"        --prefill-round-robin-balance --disable-shared-experts-fusion --"
"dtype bfloat16 --tokenizer-worker-num 4 \\\n"
"\t\t    --load-balance-method decode_round_robin\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:561
#: ../../../platforms/ascend_npu_best_practice.md:762
msgid ""
"export SGLANG_DP_ROUND_ROBIN=1\n"
"python -m sglang_router.launch_router \\\n"
"    --pd-disaggregation \\\n"
"    --policy cache_aware \\\n"
"    --prefill http://P_IP:8000 8998 \\\n"
"    --decode http://D_IP:8001 \\\n"
"    --host 127.0.0.1 \\\n"
"    --port 6688 \\\n"
"    --mini-lb\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:577
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 400  --random-input-len 2048 --"
"random-output-len 2048 --num-prompts 3200 --random-range-ratio 1 --request-"
"rate 8\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:581
msgid "DeepSeek-R1 3_5K-1_5K 50ms on A3 8 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:597
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"export STREAMS_PER_DEVICE=32\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export SGLANG_SCHEDULER_DECREASE_PREFILL_IDLE=1\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=36\n"
"export HCCL_BUFFSIZE=1600\n"
"export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"python3 -m sglang.launch_server --model-path ${MODEL_PATH} \\\n"
"--tp 16 \\\n"
"--trust-remote-code \\\n"
"--attention-backend ascend \\\n"
"--device npu \\\n"
"--quantization modelslim \\\n"
"--watchdog-timeout 9000 \\\n"
"--host 127.0.0.1 --port 6699 \\\n"
"--cuda-graph-bs 8 16 24 28 32 36 \\\n"
"--mem-fraction-static 0.71 \\\n"
"--max-running-requests 144 \\\n"
"--context-length 8188  --disable-radix-cache --chunked-prefill-size -1 --max-"
"prefill-tokens 9000 \\\n"
"--moe-a2a-backend deepep --deepep-mode auto \\\n"
"--enable-dp-attention --dp-size 4 --enable-dp-lm-head \\\n"
"--speculative-algorithm NEXTN --speculative-num-steps 3 --speculative-eagle-"
"topk 1 --speculative-num-draft-tokens 4 \\\n"
"--dtype bfloat16\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:654
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6699 --max-concurrency 144  --random-input-len 3500 --"
"random-output-len 1500 --num-prompts 576 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:658
msgid "DeepSeek-R1 3_5K-1_5K 50ms on A3 16 Cards Separation Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:674
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"export ASCEND_MF_STORE_URL=\"tcp://your prefill ip1:24667\"\n"
"\n"
"P_IP=('your prefill ip1')\n"
"\n"
"D_IP=('your decode ip1')\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"# prefill\n"
"for i in \"${!P_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${P_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${P_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${P_IP[$i]}\"\n"
"        export HCCL_BUFFSIZE=1536\n"
"        export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"        export TASK_QUEUE_ENABLE=2\n"
"\n"
"        export HCCL_SOCKET_IFNAME=lo\n"
"        export GLOO_SOCKET_IFNAME=lo\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH}  --"
"disaggregation-mode prefill --host ${P_IP[$i]} \\\n"
"        --port 8000 --disaggregation-bootstrap-port $((8998+$i)) --trust-"
"remote-code --nnodes 1 --node-rank 0 \\\n"
"        --tp-size 16 --mem-fraction-static 0.6 --attention-backend ascend --"
"device npu --quantization modelslim \\\n"
"        --disaggregation-transfer-backend ascend --max-running-requests 8 --"
"context-length 8192  --disable-radix-cache \\\n"
"        --chunked-prefill-size -1 --max-prefill-tokens 28680 --moe-a2a-"
"backend deepep --deepep-mode normal \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 1 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 2  \\\n"
"        --dp-size 2 --enable-dp-attention --disable-shared-experts-fusion --"
"dtype bfloat16\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
"# decode\n"
"for i in \"${!D_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${D_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${D_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${D_IP[$i]}\"\n"
"        export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"        export SGLANG_ENABLE_SPEC_V2=1\n"
"        export HCCL_BUFFSIZE=720\n"
"        export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=96\n"
"        export TASK_QUEUE_ENABLE=1\n"
"        export HCCL_SOCKET_IFNAME=xxx\n"
"        export GLOO_SOCKET_IFNAME=xxx\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode decode --host ${D_IP[$i]} \\\n"
"        --port 8001 --trust-remote-code --nnodes 1 --node-rank 0 --tp-size "
"16 --dp-size 16 \\\n"
"        --mem-fraction-static 0.8 --max-running-requests 384 --attention-"
"backend ascend --device npu --quantization modelslim \\\n"
"        --moe-a2a-backend deepep --enable-dp-attention --deepep-mode "
"low_latency --enable-dp-lm-head \\\n"
"        --cuda-graph-bs 8 10 12 14 16 18 20 22 24 --disaggregation-transfer-"
"backend ascend --watchdog-timeout 9000 --context-length 8192 \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 3 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 4  \\\n"
"        --prefill-round-robin-balance --disable-shared-experts-fusion --"
"dtype bfloat16 --tokenizer-worker-num 4 \\\n"
"\t\t    --load-balance-method decode_round_robin\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:778
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 384  --random-input-len 3500 --"
"random-output-len 1500 --num-prompts 1536 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:782
msgid "DeepSeek-V3.2-Exp 64K-3K 30ms on A3 32 Cards Separation Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:784
msgid "Model: DeepSeek-V3.2-Exp-W8A8"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:792
msgid "Input Output Length: 64K+3K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:794
msgid "TPOT: 30ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:798
msgid "Deploy Prefill Instance"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:800
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export LD_LIBRARY_PATH=/usr/local/Ascend/ascend-toolkit/latest/opp/vendors/"
"customize/op_api/lib/:${LD_LIBRARY_PATH}\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export ASCEND_HOME_PATH=/usr/local/Ascend/ascend-toolkit/latest\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"export HCCL_BUFFSIZE=1024\n"
"export DEEPEP_NORMAL_LONG_SEQ_ROUND=5\n"
"export DEEPEP_NORMAL_LONG_SEQ_PER_ROUND_TOKENS=512\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"export SGLANG_NPU_USE_MULTI_STREAM=1\n"
"export HCCL_OP_EXPANSION_MODE=AIV\n"
"\n"
"IPs=('your prefill ip1' 'your prefill ip2')\n"
"\n"
"# get IP in current node\n"
"LOCAL_HOST=`hostname -I|awk -F \" \" '{print$1}'`\n"
"echo \"LOCAL_HOST = \" ${LOCAL_HOST}\n"
"# get node index\n"
"for i in \"${!IPs[@]}\";\n"
"do\n"
"  echo \"LOCAL_HOST=${LOCAL_HOST}, IPs[${i}]=${IPs[$i]}\"\n"
"  if [ \"$LOCAL_HOST\" == \"${IPs[$i]}\" ]; then\n"
"      echo \"Node Rank : ${i}\"\n"
"      VC_TASK_INDEX=$i\n"
"      break\n"
"  fi\n"
"done\n"
"\n"
"IFNAMES=('xxx' 'xxx')\n"
"\n"
"export HCCL_SOCKET_IFNAME=${IFNAMES[$VC_TASK_INDEX]}\n"
"export GLOO_SOCKET_IFNAME=${HCCL_SOCKET_IFNAME}\n"
"echo \"HCCL_SOCKET_IFNAME : ${HCCL_SOCKET_IFNAME}\"\n"
"nnodes=${#IPs[@]}\n"
"tp_size=`expr 16 \\* ${nnodes}`\n"
"export ASCEND_MF_STORE_URL=tcp://${IPs[0]}:24667\n"
"\n"
"python3 -m sglang.launch_server --model-path ${MODEL_PATH} \\\n"
"--tp $tp_size \\\n"
"--trust-remote-code \\\n"
"--attention-backend ascend \\\n"
"--device npu \\\n"
"--watchdog-timeout 9000 \\\n"
"--host ${IPs[$VC_TASK_INDEX]} --port 8000 \\\n"
"--mem-fraction-static 0.73 \\\n"
"--disable-radix-cache --chunked-prefill-size -1 --max-prefill-tokens 68000 "
"\\\n"
"--max-running-requests 1 \\\n"
"--moe-a2a-backend deepep --deepep-mode normal \\\n"
"--quantization modelslim \\\n"
"--disaggregation-transfer-backend ascend \\\n"
"--disaggregation-mode prefill \\\n"
"--disable-cuda-graph \\\n"
"--nnodes $nnodes --node-rank $VC_TASK_INDEX \\\n"
"--disaggregation-bootstrap-port 8995 \\\n"
"--enable-nsa-prefill-context-parallel  --moe-dense-tp-size 1 \\\n"
"--speculative-algorithm NEXTN --speculative-num-steps 1 --speculative-eagle-"
"topk 1 --speculative-num-draft-tokens 2 \\\n"
"--dist-init-addr ${IPs[0]}:10000\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:881
msgid "Deploy Decode Instance"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:883
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export LD_LIBRARY_PATH=/usr/local/Ascend/ascend-toolkit/latest/opp/vendors/"
"customize/op_api/lib/:${LD_LIBRARY_PATH}\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"export ASCEND_HOME_PATH=/usr/local/Ascend/ascend-toolkit/latest\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_NPU_USE_MULTI_STREAM=1\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export HCCL_OP_EXPANSION_MODE=AIV\n"
"export SGLANG_SCHEDULER_SKIP_ALL_GATHER=1\n"
"export TASK_QUEUE_ENABLE=0\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"IPs=('your decode ip1' 'your decode ip2')\n"
"\n"
"export prefill_ip=your prefill ip1\n"
"# get IP in current node\n"
"LOCAL_HOST=`hostname -I|awk -F \" \" '{print$1}'`\n"
"echo \"LOCAL_HOST = \" ${LOCAL_HOST}\n"
"# get node index\n"
"for i in \"${!IPs[@]}\";\n"
"do\n"
"  echo \"LOCAL_HOST=${LOCAL_HOST}, IPs[${i}]=${IPs[$i]}\"\n"
"  if [ \"$LOCAL_HOST\" == \"${IPs[$i]}\" ]; then\n"
"      echo \"Node Rank : ${i}\"\n"
"      VC_TASK_INDEX=$i\n"
"      break\n"
"  fi\n"
"done\n"
"\n"
"IFNAMES=('xxx' 'xxx')\n"
"\n"
"export HCCL_SOCKET_IFNAME=${IFNAMES[$VC_TASK_INDEX]}\n"
"export GLOO_SOCKET_IFNAME=${HCCL_SOCKET_IFNAME}\n"
"nnodes=${#IPs[@]}\n"
"tp_size=`expr 16 \\* ${nnodes}`\n"
"export ASCEND_MF_STORE_URL=tcp://${prefill_ip}:24667\n"
"\n"
"CHUNKED_SIZE=65536\n"
"DP=8\n"
"export HCCL_BUFFSIZE=400\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=8\n"
"\n"
"python3 -m sglang.launch_server --model-path ${MODEL_PATH} \\\n"
"--tp $tp_size \\\n"
"--dp ${DP} \\\n"
"--ep $tp_size \\\n"
"--moe-dense-tp-size 1 \\\n"
"--enable-dp-attention \\\n"
"--enable-dp-lm-head \\\n"
"--trust-remote-code \\\n"
"--attention-backend ascend \\\n"
"--device npu \\\n"
"--watchdog-timeout 9000 \\\n"
"--host ${IPs[$VC_TASK_INDEX]} --port 8001 \\\n"
"--mem-fraction-static 0.79 \\\n"
"--disable-radix-cache \\\n"
"--chunked-prefill-size -1 --max-prefill-tokens 68000 \\\n"
"--max-running-requests 32 \\\n"
"--cuda-graph-max-bs 4 \\\n"
"--moe-a2a-backend deepep \\\n"
"--deepep-mode low_latency \\\n"
"--quantization modelslim \\\n"
"--speculative-algorithm NEXTN --speculative-num-steps 3 --speculative-eagle-"
"topk 1 --speculative-num-draft-tokens 4 \\\n"
"--disaggregation-transfer-backend ascend \\\n"
"--disaggregation-mode decode \\\n"
"--prefill-round-robin-balance \\\n"
"--load-balance-method round_robin \\\n"
"--nnodes $nnodes --node-rank $VC_TASK_INDEX \\\n"
"--dist-init-addr ${IPs[0]}:10000 --load-balance-method decode_round_robin\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:973
msgid ""
"export SGLANG_DP_ROUND_ROBIN=1\n"
"python -m sglang_router.launch_router \\\n"
"    --pd-disaggregation \\\n"
"    --policy cache_aware \\\n"
"    --prefill http://PIP1:8000 8995 \\\n"
"    --decode http://DIP1:8001 \\\n"
"    --host 127.0.0.1 \\\n"
"    --port 6688 \\\n"
"    --mini-lb\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:989
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 32  --random-input-len 64000 --"
"random-output-len 3000 --num-prompts 64 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:993
msgid "Qwen3-235B-A22B 3_5K-1_5K 50ms on A3 24 Cards Separation Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:995
#: ../../../platforms/ascend_npu_best_practice.md:1131
#: ../../../platforms/ascend_npu_best_practice.md:1204
#: ../../../platforms/ascend_npu_best_practice.md:1276
#: ../../../platforms/ascend_npu_best_practice.md:1348
#: ../../../platforms/ascend_npu_best_practice.md:1433
msgid "Model: Qwen3-235B-A22B-W8A8"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:997
#: ../../../platforms/ascend_npu_best_practice.md:1928
msgid "Hardware: Atlas 800I A3 24Card"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1009
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=16\n"
"\n"
"MODEL_PATH=xxx\n"
"export ASCEND_MF_STORE_URL=\"tcp://your prefill ip1:24667\"\n"
"P_IP=('your prefill ip1')\n"
"D_IP=('your decode ip1' 'your decode ip2')\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export SGLANG_DP_ROUND_ROBIN=1\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"\n"
"for i in \"${!P_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${P_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${P_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${P_IP[$i]}\"\n"
"        source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"        source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"        export DEEPEP_NORMAL_LONG_SEQ_PER_ROUND_TOKENS=1024\n"
"        export DEEPEP_NORMAL_LONG_SEQ_ROUND=16\n"
"        export HCCL_BUFFSIZE=4300\n"
"        export TASK_QUEUE_ENABLE=2\n"
"        export HCCL_SOCKET_IFNAME=lo\n"
"        export GLOO_SOCKET_IFNAME=lo\n"
"        export STREAMS_PER_DEVICE=32\n"
"        export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"\n"
"        # P节点\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode prefill \\\n"
"        --host ${P_IP[$i]} --port 8000 --disaggregation-bootstrap-port 8995 "
"--trust-remote-code \\\n"
"        --nnodes 1 --node-rank $i --tp-size 16 --dp-size 16 --mem-fraction-"
"static 0.6 \\\n"
"        --disable-radix-cache \\\n"
"        --attention-backend ascend --device npu --quantization modelslim --"
"disaggregation-transfer-backend ascend \\\n"
"        --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx "
"\\\n"
"        --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-"
"num-draft-tokens 4 \\\n"
"        --speculative-draft-model-quantization unquant \\\n"
"        --max-running-requests 128 --chunked-prefill-size 262144 --max-"
"prefill-tokens 262144 \\\n"
"        --enable-dp-attention  \\\n"
"        --moe-a2a-backend deepep --deepep-mode normal --dtype bfloat16\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
"\n"
"for i in \"${!D_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${D_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${D_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${D_IP[$i]}\"\n"
"        source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"        source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"        export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=24\n"
"        export HCCL_BUFFSIZE=512\n"
"        export HCCL_SOCKET_IFNAME=data0.3001\n"
"        export GLOO_SOCKET_IFNAME=data0.3001\n"
"        export STREAMS_PER_DEVICE=32\n"
"\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode decode \\\n"
"        --host ${D_IP[$i]} --port 8001 --trust-remote-code \\\n"
"        --nnodes 2 --node-rank $i --tp-size 32 --dp-size 32 --mem-fraction-"
"static 0.83 --max-running-requests 768 \\\n"
"        --attention-backend ascend --device npu --quantization modelslim --"
"enable-dp-attention \\\n"
"        --moe-a2a-backend ascend_fuseep --cuda-graph-bs 6 8 12 15 18 20 22 "
"24 \\\n"
"        --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx "
"\\\n"
"        --speculative-draft-model-quantization unquant \\\n"
"        --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-"
"num-draft-tokens 4 \\\n"
"        --dist-init-addr xxx:5000 \\\n"
"        --disaggregation-transfer-backend ascend --watchdog-timeout 9000 --"
"context-length 8192 \\\n"
"        --prefill-round-robin-balance --enable-dp-lm-head --dtype bfloat16 --"
"tokenizer-worker-num 4 \\\n"
"        --load-balance-method decode_round_robin\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1109
#: ../../../platforms/ascend_npu_best_practice.md:2028
msgid ""
"export SGLANG_DP_ROUND_ROBIN=1\n"
"python -m sglang_router.launch_router \\\n"
"    --pd-disaggregation \\\n"
"    --policy cache_aware \\\n"
"    --prefill http://PIP:8000 8995 \\\n"
"    --decode http://DIP:8001 \\\n"
"    --host 127.0.0.1 \\\n"
"    --port 6688 \\\n"
"    --mini-lb\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1125
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang-oai --"
"host 127.0.0.1 --port 7239 --max-concurrency 860 --random-input-len 3500 --"
"random-output-len 1500 --num-prompts 3440 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1129
msgid "Qwen3-235B-A22B 3_5K-1_5K 50ms on A3 8 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1145
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=1600\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export SGLANG_SCHEDULER_DECREASE_PREFILL_IDLE=2\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu --quantization modelslim  \\\n"
"    --max-running-requests 272 --context-length 8192 --dtype bfloat16 \\\n"
"    --chunked-prefill-size 32768 --max-prefill-tokens 32768 \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 \\\n"
"    --disable-radix-cache --moe-a2a-backend deepep  --deepep-mode auto --"
"speculative-draft-model-quantization unquant \\\n"
"    --tp 16 --dp-size 16 --enable-dp-attention --enable-dp-lm-head --mem-"
"fraction-static 0.8 --cuda-graph-bs 3 4 6 8 10 12 13 14 15 16 17\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1198
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7439 --max-concurrency 272 --random-input-len 3500 --random-"
"output-len 1500 --num-prompts 1088 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1202
msgid "Qwen3-235B-A22B 2K-2K 100ms on A3 8 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1214
msgid "TPOT: 100ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1218
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=1200\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu --quantization modelslim  \\\n"
"    --max-running-requests 576 --context-length 8192 --dtype bfloat16 \\\n"
"    --chunked-prefill-size 32768 --max-prefill-tokens 458880  \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 \\\n"
"    --disable-radix-cache --moe-a2a-backend deepep  --deepep-mode auto --"
"speculative-draft-model-quantization unquant  \\\n"
"    --tp 16 --dp-size 16 --enable-dp-attention --enable-dp-lm-head --mem-"
"fraction-static 0.81 --cuda-graph-bs 8 16 20 24 32 36\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1270
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7439 --max-concurrency 576 --random-input-len 2000 --random-"
"output-len 2000 --num-prompts 576 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1274
msgid "Qwen3-235B-A22B 2K-2K 50ms on A3 8 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1290
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=2100\n"
"export HCCL_SOCKET_IFNAME=xxx\n"
"export GLOO_SOCKET_IFNAME=xxx\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu --quantization modelslim  \\\n"
"    --max-running-requests 480 --context-length 8192 --dtype bfloat16 \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 4096 --speculative-draft-"
"model-quantization unquant  \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 \\\n"
"    --disable-radix-cache --moe-a2a-backend deepep  --deepep-mode auto  \\\n"
"    --tp 16 --dp-size 16 --enable-dp-attention --enable-dp-lm-head --mem-"
"fraction-static 0.75 --cuda-graph-bs 6 8 10 12 15 18 28 30\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1342
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7439 --max-concurrency 480 --random-input-len 2048 --random-"
"output-len 2048 --num-prompts 480 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1346
msgid "Qwen3-235B-A22B 2K-2K 50ms on A3 16 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1362
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=1600\n"
"export HCCL_SOCKET_IFNAME=xxx\n"
"export GLOO_SOCKET_IFNAME=xxx\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"\n"
"MIX_IP=('IP1' 'IP2')\n"
"\n"
"for i in \"${!MIX_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${MIX_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${MIX_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${MIX_IP[$i]}\"\n"
"        export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"        export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} \\\n"
"        --host 127.0.0.1 --port 7439 --trust-remote-code \\\n"
"        --nnodes 2 --node-rank $i --tp-size 32 --dp-size 32 --mem-fraction-"
"static 0.8 --max-running-requests 768 \\\n"
"        --attention-backend ascend --device npu --quantization modelslim --"
"enable-dp-attention \\\n"
"        --moe-a2a-backend deepep --deepep-mode auto --cuda-graph-bs 6 8 10 "
"12 18 24 \\\n"
"        --dist-init-addr ${MIX_IP[0]}:5000 --chunked-prefill-size 131072 --"
"max-prefill-tokens 458880 \\\n"
"        --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx --"
"speculative-draft-model-quantization= unquant \\\n"
"        --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-"
"num-draft-tokens 4 \\\n"
"        --context-length 8192 --disable-radix-cache \\\n"
"        --enable-dp-lm-head --dtype bfloat16\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1427
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7439 --max-concurrency 768 --random-input-len 2000 --random-"
"output-len 2000 --num-prompts 768 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1431
msgid "Qwen3-235B-A22B 11K-1K 10ms on A3 8 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1441
msgid "Input Output Length: 11K+1K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1443
msgid "TPOT: 10ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1447
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=1600\n"
"export HCCL_SOCKET_IFNAME=xxx\n"
"export GLOO_SOCKET_IFNAME=xxx\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu --quantization modelslim  \\\n"
"    --max-running-requests 1  --dtype bfloat16 \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 16384 --speculative-draft-"
"model-quantization unquant  \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 4 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 5 \\\n"
"    --disable-radix-cache --enable-dp-lm-head \\\n"
"    --tp 16 --mem-fraction-static 0.78 --cuda-graph-bs 1\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1500
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7439 --max-concurrency 1 --random-input-len 11000 --random-"
"output-len 1000 --num-prompts 1 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1504
msgid "Qwen3-32B 6K-1_5K 18ms on A3 4 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1506
#: ../../../platforms/ascend_npu_best_practice.md:1577
#: ../../../platforms/ascend_npu_best_practice.md:1647
#: ../../../platforms/ascend_npu_best_practice.md:1716
#: ../../../platforms/ascend_npu_best_practice.md:1786
#: ../../../platforms/ascend_npu_best_practice.md:2270
#: ../../../platforms/ascend_npu_best_practice.md:2339
#: ../../../platforms/ascend_npu_best_practice.md:2412
#: ../../../platforms/ascend_npu_best_practice.md:2482
msgid "Model: Qwen3-32B"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1508
#: ../../../platforms/ascend_npu_best_practice.md:1579
msgid "Hardware: Atlas 800I A3 4Card"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1514
#: ../../../platforms/ascend_npu_best_practice.md:2278
msgid "Input Output Length: 6K+1.5K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1516
#: ../../../platforms/ascend_npu_best_practice.md:2280
msgid "TPOT: 18ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1520
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=xxx\n"
"export GLOO_SOCKET_IFNAME=xxx\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu \\\n"
"    --max-running-requests 32 \\\n"
"    --disable-radix-cache \\\n"
"    --chunked-prefill-size 24576 --max-prefill-tokens 65536 \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 4 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 5 \\\n"
"    --tp-size 8 --mem-fraction-static 0.72 --cuda-graph-bs 8 16 24 32  --"
"dtype bfloat16\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1571
#: ../../../platforms/ascend_npu_best_practice.md:2333
msgid ""
"python3 -m sglang.bench_serving --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 7439 --max-concurrency 32 --random-output-len 1500 --"
"random-input-len 6000 --num-prompts 32 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1575
msgid "Qwen3-32B 4K-1_5K 11ms on A3 4 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1585
#: ../../../platforms/ascend_npu_best_practice.md:2347
msgid "Input Output Length: 4K+1.5K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1587
#: ../../../platforms/ascend_npu_best_practice.md:2349
msgid "TPOT: 11ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1591
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7339 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu   \\\n"
"    --max-running-requests 1 \\\n"
"    --disable-radix-cache \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 4 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 5 \\\n"
"    --chunked-prefill-size 24576 --max-prefill-tokens 65536  \\\n"
"    --tp-size 8 --mem-fraction-static 0.72 --cuda-graph-bs 1 --dtype "
"bfloat16\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1641
msgid ""
"python3 -m sglang.bench_serving --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 7239 --random-range-ratio 1 --max-concurrency 1 --"
"random-output-len 1500 --random-input-len 4096 --num-prompts 4\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1645
msgid "Qwen3-32B 18K-4K 12ms on A3 8 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1655
msgid "Input Output Length: 18K+4K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1657
msgid "TPOT: 12ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1661
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7339 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu   \\\n"
"    --max-running-requests 1 \\\n"
"    --disable-radix-cache --speculative-draft-model-quantization unquant \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 4 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 5 \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 65536  \\\n"
"    --tp-size 16 --mem-fraction-static 0.72 --cuda-graph-bs 1 --dtype "
"bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1710
msgid ""
"python3 -m sglang.bench_serving --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 7339 --random-range-ratio 1 --max-concurrency 1 --"
"random-output-len 18000 --random-input-len 4000 --num-prompts 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1714
msgid "Qwen3-32B 3_5K-1_5K 50ms on A3 2 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1718
#: ../../../platforms/ascend_npu_best_practice.md:1788
#: ../../../platforms/ascend_npu_best_practice.md:2203
msgid "Hardware: Atlas 800I A3 2Card"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1730
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7239 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu  --quantization modelslim  \\\n"
"    --max-running-requests 78 \\\n"
"    --disable-radix-cache --speculative-draft-model-quantization unquant \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 49152  \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 \\\n"
"    --tp-size 4  --mem-fraction-static 0.72 --cuda-graph-bs 16 32 64 68 72 "
"78 --dtype bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1780
#: ../../../platforms/ascend_npu_best_practice.md:2476
msgid ""
"python3 -m sglang.bench_serving --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 7239 --max-concurrency 78 --random-output-len 1500 --"
"random-input-len 3500 --num-prompts 312 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1784
msgid "Qwen3-32B 2K-2K 50ms on A3 2 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1800
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7239 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu  --quantization modelslim  \\\n"
"    --max-running-requests 120 \\\n"
"    --disable-radix-cache --speculative-draft-model-quantization unquant \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 49152 \\\n"
"    --tp-size 4 --mem-fraction-static 0.7 --cuda-graph-bs 54 60 66 72 78 84 "
"90 108 114 120 --dtype bfloat16\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1850
msgid ""
"python3 -m sglang.bench_serving --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 7239 --max-concurrency 120 --random-output-len 2000 --"
"random-input-len 2000 --num-prompts 480 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1854
msgid "Qwen3-30B-A3B 3_5K-1_5K 50ms on A3 1 Card Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1856
msgid "Model: Qwen3-30B-A3B-Instruct-2507"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1858
msgid "Hardware: Atlas 800I A3 1Card"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1870
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7239 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu  --quantization modelslim  \\\n"
"    --max-running-requests 192 \\\n"
"    --disable-radix-cache \\\n"
"    --speculative-draft-model-quantization unquant \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 32768 \\\n"
"    --tp-size 2 --mem-fraction-static 0.86 --cuda-graph-bs 42 88 96 132 144 "
"156 172 178 192 --dtype bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1920
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7239 --max-concurrency 156 --random-input-len 3500 --random-"
"output-len 1500 --num-prompts 624 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1924
msgid ""
"Qwen3-Coder-480B-A35B-Instruct 3_5K-1_5K 50ms on A3 24 Cards Separation Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1926
#: ../../../platforms/ascend_npu_best_practice.md:2050
#: ../../../platforms/ascend_npu_best_practice.md:2133
msgid "Model: Qwen3-Coder-480B-A35B-Instruct"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1940
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=16\n"
"\n"
"MODEL_PATH=xxx\n"
"export ASCEND_MF_STORE_URL=\"tcp://PIP:24667\"\n"
"P_IP=('PIP')\n"
"D_IP=('DIP1' 'DIP2')\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"\n"
"for i in \"${!P_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${P_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${P_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${P_IP[$i]}\"\n"
"        source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"        source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"        export DEEPEP_NORMAL_LONG_SEQ_PER_ROUND_TOKENS=1024\n"
"        export DEEPEP_NORMAL_LONG_SEQ_ROUND=16\n"
"        export HCCL_BUFFSIZE=4300\n"
"        export TASK_QUEUE_ENABLE=2\n"
"        export HCCL_SOCKET_IFNAME=lo\n"
"        export GLOO_SOCKET_IFNAME=lo\n"
"        export STREAMS_PER_DEVICE=32\n"
"        export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode prefill \\\n"
"        --host ${P_IP[$i]} --port 8000 --disaggregation-bootstrap-port 8995 "
"--trust-remote-code \\\n"
"        --nnodes 1 --node-rank $i --tp-size 16 --dp-size 2 --mem-fraction-"
"static 0.6 \\\n"
"        --disable-radix-cache \\\n"
"\t      --attention-backend ascend --device npu --quantization modelslim --"
"disaggregation-transfer-backend ascend \\\n"
"\t      --max-running-requests 128 --chunked-prefill-size 65536 --max-"
"prefill-tokens 262144 \\\n"
"        --enable-dp-attention  \\\n"
"        --moe-a2a-backend deepep --deepep-mode normal --dtype bfloat16\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
"for i in \"${!D_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${D_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${D_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${D_IP[$i]}\"\n"
"        source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"        source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"        export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=72\n"
"        export HCCL_BUFFSIZE=512\n"
"        export HCCL_SOCKET_IFNAME=xxx\n"
"        export GLOO_SOCKET_IFNAME=xxx\n"
"        export STREAMS_PER_DEVICE=32\n"
"\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode decode \\\n"
"        --host ${D_IP[$i]} --port 8001 --trust-remote-code \\\n"
"        --nnodes 2 --node-rank $i --tp-size 32 --dp-size 4 --mem-fraction-"
"static 0.73 --max-running-requests 384 \\\n"
"        --attention-backend ascend --device npu --quantization modelslim --"
"enable-dp-attention \\\n"
"        --moe-a2a-backend ascend_fuseep --cuda-graph-bs 16 32 48 56 64 72 80 "
"88 96 \\\n"
"        --dist-init-addr DIP1:5000 \\\n"
"\t      --disaggregation-transfer-backend ascend --watchdog-timeout 9000 --"
"context-length 8192 \\\n"
"        --prefill-round-robin-balance --enable-dp-lm-head --dtype bfloat16 --"
"tokenizer-worker-num 4 --load-balance-method decode_round_robin\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2044
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7239 --max-concurrency 410 --random-input-len 3500 --random-"
"output-len 1500 --num-prompts 1640 --random-range-ratio 1 --request-rate 8\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2048
msgid "Qwen3-Coder-480B-A35B-Instruct 3_5K-1_5K 50ms on A3 16 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2064
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=16\n"
"\n"
"export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=1800\n"
"export HCCL_SOCKET_IFNAME=xxx\n"
"export GLOO_SOCKET_IFNAME=xxx\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"\n"
"MIX_IP=('IP1' 'IP2')\n"
"\n"
"for i in \"${!MIX_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${MIX_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${MIX_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${MIX_IP[$i]}\"\n"
"\n"
"        python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"        --host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 2 --node-"
"rank $i  \\\n"
"        --dist-init-addr 141.61.133.128:5000 \\\n"
"        --attention-backend ascend --device npu --quantization modelslim  "
"\\\n"
"        --max-running-requests 288 --context-length 8192 --dtype bfloat16  "
"\\\n"
"        --chunked-prefill-size 114688 --max-prefill-tokens 458880  \\\n"
"        --disable-radix-cache --moe-a2a-backend deepep  --deepep-mode auto  "
"\\\n"
"        --tp 32 --dp-size 4 --enable-dp-attention --enable-dp-lm-head --mem-"
"fraction-static 0.7 --cuda-graph-bs 56 64 72\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2127
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7439 --max-concurrency 288 --random-input-len 3500 --random-"
"output-len 1500 --num-prompts 1152 --random-range-ratio 1 --request-rate 20\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2131
msgid "Qwen3-Coder-480B-A35B-Instruct 3_5K-1_5K 50ms on A3 8 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2147
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=2100\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"--host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 1 --node-rank 0  "
"\\\n"
"--attention-backend ascend --device npu --quantization modelslim  \\\n"
"--max-running-requests 80 --context-length 8192 --dtype bfloat16 \\\n"
"--chunked-prefill-size 28672 --max-prefill-tokens 458880  \\\n"
"--disable-radix-cache --moe-a2a-backend deepep  --deepep-mode auto --enable-"
"dp-attention --enable-dp-lm-head \\\n"
"--tp 16 --dp-size 4 --mem-fraction-static 0.7 --cuda-graph-bs  16 20 24\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2195
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7439 --max-concurrency 80 --random-input-len 3500 --random-"
"output-len 1500 --num-prompts 320 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2199
msgid "Qwen3-Next-80B-A3B-Instruct 3_5K-1_5K 50ms on A3 2 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2201
msgid "Model: Qwen3-Next-80B-A3B-Instruct"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2215
msgid ""
"export cann_path=/usr/local/Ascend/ascend-toolkit/latest\n"
"source /usr/local/Ascend/driver/bin/setenv.bash\n"
"source ${cann_path}/../set_env.sh\n"
"source ${cann_path}/../../nnal/atb/set_env.sh\n"
"source ${cann_path}/opp/vendors/customize/bin/set_env.bash\n"
"export ASCEND_HOME_PATH=${cann_path}\n"
"source /usr/local/Ascend/8.5.0/bisheng_toolkit/set_env.sh\n"
"\n"
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"\n"
"export HCCL_OP_EXPANSION_MODE=AIV\n"
"export HCCL_ALGO=\"level0:NA;level1:ring\"\n"
"\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=20\n"
"export HCCL_BUFFSIZE=2000\n"
"\n"
"python -m sglang.launch_server \\\n"
"        --model-path /path/to/Qwen3-Next-80B-A3B-Instruct-W8A8-3 \\\n"
"        --host 127.0.0.1 \\\n"
"        --port 6699 \\\n"
"        --tp-size 4 \\\n"
"        --device npu \\\n"
"        --attention-backend ascend \\\n"
"        --mem-fraction-static 0.685 \\\n"
"        --max-running-requests 80 \\\n"
"        --watchdog-timeout 3600 \\\n"
"        --disable-radix-cache \\\n"
"        --cuda-graph-bs 80 \\\n"
"        --max-prefill-tokens 28672  --max-total-tokens 450560 \\\n"
"        --moe-a2a-backend deepep --deepep-mode auto \\\n"
"        --quantization modelslim \\\n"
"        --chunked-prefill-size -1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2264
msgid ""
"python3 -m sglang.bench_serving --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 6699 --max-concurrency 80 --random-output-len 1536 --"
"random-input-len 3584 --num-prompts 160 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2268
msgid "Qwen3-32B 6K-1_5K 18ms on A2 8 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2272
#: ../../../platforms/ascend_npu_best_practice.md:2341
#: ../../../platforms/ascend_npu_best_practice.md:2414
#: ../../../platforms/ascend_npu_best_practice.md:2484
msgid "Hardware: Atlas 800I A2 8Card"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2284
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu  --quantization modelslim  \\\n"
"    --max-running-requests 32 \\\n"
"    --disable-radix-cache \\\n"
"    --chunked-prefill-size 24576 --max-prefill-tokens 65536 \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 4 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 5 \\\n"
"    --tp-size 8 --mem-fraction-static 0.72 --cuda-graph-bs 8 16 24 32 --"
"dtype bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2337
msgid "Qwen3-32B 4K-1_5K 11ms on A2 8 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2353
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7339 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu   \\\n"
"    --max-running-requests 32 \\\n"
"    --disable-radix-cache \\\n"
"    --speculative-draft-model-quantization unquant \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx  \\\n"
"    --speculative-num-steps 4 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 5 \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 65536  \\\n"
"    --tp-size 8 --mem-fraction-static 0.72 --cuda-graph-bs 1 4 6 12 18 24 30 "
"32 --dtype bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2406
msgid ""
"python3 -m sglang.bench_serving  --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 7339 --random-range-ratio 1 --max-concurrency 1 --"
"random-output-len 1500 --random-input-len 4096 --num-prompts 4\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2410
msgid "Qwen3-32B 3_5K-1_5K 50ms on A2 8 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2426
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7239 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu  --quantization modelslim  \\\n"
"    --max-running-requests 78 \\\n"
"    --disable-radix-cache --speculative-draft-model-quantization unquant \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 65536  \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 \\\n"
"    --tp-size 4  --mem-fraction-static 0.72 --cuda-graph-bs 1 4 8 16 32 64 "
"68 72 78 --dtype bfloat16 --base-gpu-id 4\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2480
msgid "Qwen3-32B 2K-2K 50ms on A2 8 Cards Mixed Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2496
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7239 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu  --quantization modelslim  \\\n"
"    --max-running-requests 120 \\\n"
"    --disable-radix-cache \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 --speculative-draft-model-quantization unquant \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 49152 --base-gpu-id 4 \\\n"
"    --tp-size 4 --mem-fraction-static 0.7 --cuda-graph-bs 54 60 66 72 78 84 "
"90 108 114 120 --dtype bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2545
msgid ""
"python3 -m sglang.bench_serving --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 7239 --max-concurrency 120 --random-output-len 2000 --"
"random-input-len 2000 --num-prompts 120 --random-range-ratio 1\n"
msgstr ""
