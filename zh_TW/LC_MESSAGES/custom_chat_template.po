# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2024, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang 0.2\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-11-09 18:47+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../custom_chat_template.md:1
msgid "Custom Chat Template in SGLang Runtime"
msgstr ""

#: ../../../custom_chat_template.md:3
msgid ""
"By default, the server uses the chat template specified in the model "
"tokenizer from Hugging Face. It should just work for most official models "
"such as Llama-2/Llama-3."
msgstr ""

#: ../../../custom_chat_template.md:5
msgid ""
"If needed, you can also override the chat template when launching the server:"
msgstr ""

#: ../../../custom_chat_template.md:7
msgid ""
"python -m sglang.launch_server --model-path meta-llama/Llama-2-7b-chat-hf --"
"port 30000 --chat-template llama-2\n"
msgstr ""

#: ../../../custom_chat_template.md:11
msgid ""
"If the chat template you are looking for is missing, you are welcome to "
"contribute it. Meanwhile, you can also temporarily register your chat "
"template as follows:"
msgstr ""

#: ../../../custom_chat_template.md:14
msgid ""
"{\n"
"  \"name\": \"my_model\",\n"
"  \"system\": \"<|im_start|>system\",\n"
"  \"user\": \"<|im_start|>user\",\n"
"  \"assistant\": \"<|im_start|>assistant\",\n"
"  \"sep_style\": \"CHATML\",\n"
"  \"sep\": \"<|im_end|>\",\n"
"  \"stop_str\": [\"<|im_end|>\", \"<|im_start|>\"]\n"
"}\n"
msgstr ""

#: ../../../custom_chat_template.md:26
msgid ""
"python -m sglang.launch_server --model-path meta-llama/Llama-2-7b-chat-hf --"
"port 30000 --chat-template ./my_model_template.json\n"
msgstr ""
