# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang stable\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-01-06 08:37+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../references/post_training_integration.md:1
msgid "Post-Training Integration"
msgstr ""

#: ../../../references/post_training_integration.md:3
msgid ""
"SGLang has become the de facto inference backend for modern LLM training "
"frameworks, powering state-of-the-art models across the industry. From "
"GLM-4.6 to Qwen3, leading models leverage SGLang's high-performance "
"inference during reinforcement learning and post-training workflows."
msgstr ""

#: ../../../references/post_training_integration.md:5
msgid "What makes SGLang essential for post-training?"
msgstr ""

#: ../../../references/post_training_integration.md:7
msgid ""
"Open-To-Use Refit Functionality: diverse method for colocate or disaggregate"
msgstr ""

#: ../../../references/post_training_integration.md:8
msgid ""
"Easy To Postpone Generation: enable partial rollout and dedicated rollout "
"control"
msgstr ""

#: ../../../references/post_training_integration.md:9
msgid ""
"Fine-Grained Engine Sleep And Wake Up: facilitate maxium-powered rollout and "
"training"
msgstr ""

#: ../../../references/post_training_integration.md:10
msgid ""
"Training Serving Alignment: ensure the performance consistency in training "
"and serving"
msgstr ""

#: ../../../references/post_training_integration.md:11
msgid ""
"Load Balancing Router: cache-aware load-balancing for high-throughput rollout"
msgstr ""

#: ../../../references/post_training_integration.md:12
msgid ""
"Deterministic Inference: ensure zero kl divergence between rollout and "
"training"
msgstr ""

#: ../../../references/post_training_integration.md:14
msgid ""
"These capabilities, combined with native integration support across major "
"frameworks, have established SGLang as the infrastructure backbone for "
"modern LLM/VLMs post-training. We also share our latest work in this slide, "
"[Optimizing Large-Scale RL with SGLang](https://gamma.app/docs/Optimizing-RL-"
"with-SGLang-y0kqgj877k34779)."
msgstr ""

#: ../../../references/post_training_integration.md:16
msgid "Adoption"
msgstr ""

#: ../../../references/post_training_integration.md:18
msgid ""
"[**Miles**](https://github.com/radixark/miles): Enterprise-scale RL "
"framework for large MoE models with SGLang-native rollout, speculative "
"training, and production-grade stability"
msgstr ""

#: ../../../references/post_training_integration.md:19
msgid ""
"[**slime**](https://github.com/THUDM/slime): Post-training framework "
"combining Megatron and SGLang, used to train GLM-4.6"
msgstr ""

#: ../../../references/post_training_integration.md:20
msgid ""
"[**AReaL**](https://github.com/inclusionAI/AReaL): Fully asynchronous RL "
"system achieving 2.77x speedup with SGLang backend for continuous rollout "
"generation"
msgstr ""

#: ../../../references/post_training_integration.md:21
msgid ""
"[**ROLL**](https://github.com/alibaba/ROLL): ROLL is an efficient and user-"
"friendly RL library designed for Large Language Models utilizing Large Scale "
"GPU resources"
msgstr ""

#: ../../../references/post_training_integration.md:22
msgid ""
"[**verl**](https://github.com/volcengine/verl): Full-stack RLHF framework "
"supporting PPO, GRPO, and ReMax with modular SGLang integration"
msgstr ""

#: ../../../references/post_training_integration.md:23
msgid ""
"[**Unsloth**](https://docs.unsloth.ai/basics/inference-and-deployment/sglang-"
"guide): 2x faster fine-tuning with optimized kernels, deploys seamlessly "
"with SGLang inference"
msgstr ""

#: ../../../references/post_training_integration.md:24
msgid ""
"[**LLaMA Factory**](https://github.com/hiyouga/LLaMA-Factory): Unified "
"framework for training 100+ LLMs with LoRA, QLoRA, and full fine-tuning "
"methods"
msgstr ""

#: ../../../references/post_training_integration.md:25
msgid ""
"[**Tunix**](https://github.com/google/tunix): Google's JAX-native library "
"for LLM post-training with SFT, DPO, PPO, and GRPO support"
msgstr ""

#: ../../../references/post_training_integration.md:26
msgid ""
"[**RL2**](https://github.com/ChenmienTan/RL2): Ray Less Reinforcement "
"Learning, a concise library of post-training for large language models"
msgstr ""

#: ../../../references/post_training_integration.md:29
msgid "Collaboration"
msgstr ""

#: ../../../references/post_training_integration.md:31
msgid ""
"Due to the privacy of the design parternes, we cannot list the companies "
"that adopt SGLang for post-training. However, we are happy to share the "
"details with you if you are interested and trust the choice among 10+ top "
"companies and frontier labs across US and China. If you are interested in "
"integrating SGLang with your training framework or need technical support, "
"we're here to help! Reach out to us at **rl_team@lmsys.org** for "
"partnerships, integration guidance, and custom feature development."
msgstr ""
