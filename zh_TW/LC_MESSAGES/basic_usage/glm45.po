# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang latest\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-12-22 08:33+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../basic_usage/glm45.md:1
msgid "Launch GLM-4.5 / GLM-4.6 / GLM-4.7 with SGLang"
msgstr ""

#: ../../../basic_usage/glm45.md:3
msgid "To serve GLM-4.5 / GLM-4.6 FP8 models on 8xH100/H200 GPUs:"
msgstr ""

#: ../../../basic_usage/glm45.md:5
msgid "python3 -m sglang.launch_server --model zai-org/GLM-4.6-FP8 --tp 8\n"
msgstr ""

#: ../../../basic_usage/glm45.md:9
msgid "Configuration Tips"
msgstr ""

#: ../../../basic_usage/glm45.md:11
msgid ""
"`--max-mamba-cache-size`: Adjust `--max-mamba-cache-size` to increase mamba "
"cache space and max running requests capability. It will decrease KV cache "
"space as a trade-off. You can adjust it according to workload."
msgstr ""

#: ../../../basic_usage/glm45.md:14
msgid "EAGLE Speculative Decoding"
msgstr ""

#: ../../../basic_usage/glm45.md:16
msgid ""
"**Description**: SGLang has supported GLM-4.5 / GLM-4.6 models with [EAGLE "
"speculative decoding](https://docs.sglang.io/advanced_features/"
"speculative_decoding.html#EAGLE-Decoding)."
msgstr ""

#: ../../../basic_usage/glm45.md:19
msgid ""
"**Usage**: Add arguments `--speculative-algorithm`, `--speculative-num-"
"steps`, `--speculative-eagle-topk` and `--speculative-num-draft-tokens` to "
"enable this feature. For example:"
msgstr ""

#: ../../../basic_usage/glm45.md:23
msgid ""
"python3 -m sglang.launch_server \\\n"
"  --model-path zai-org/GLM-4.6-FP8 \\\n"
"  --tp-size 8 \\\n"
"  --tool-call-parser glm45  \\\n"
"  --reasoning-parser glm45  \\\n"
"  --speculative-algorithm EAGLE \\\n"
"  --speculative-num-steps 3  \\\n"
"  --speculative-eagle-topk 1  \\\n"
"  --speculative-num-draft-tokens 4 \\\n"
"  --mem-fraction-static 0.9 \\\n"
"  --served-model-name glm-4.6-fp8 \\\n"
"  --enable-custom-logit-processor\n"
msgstr ""

#: ../../../basic_usage/glm45.md:38
msgid ""
"**Note**: For GLM-4.7, `--tool-call-parser` should be set to `glm47`, for "
"GLM-4.5 and GLM-4.6, it should be set to `glm45`."
msgstr ""

#: ../../../basic_usage/glm45.md:40
msgid "Thinking Budget"
msgstr ""

#: ../../../basic_usage/glm45.md:42
msgid ""
"In SGLang, we can implement thinking budget with `CustomLogitProcessor`."
msgstr ""

#: ../../../basic_usage/glm45.md:44
msgid "Launch a server with `--enable-custom-logit-processor` flag on."
msgstr ""

#: ../../../basic_usage/glm45.md:46
msgid "Sample Request:"
msgstr ""

#: ../../../basic_usage/glm45.md:48
msgid ""
"import openai\n"
"from rich.pretty import pprint\n"
"from sglang.srt.sampling.custom_logit_processor import "
"Glm4MoeThinkingBudgetLogitProcessor\n"
"\n"
"\n"
"client = openai.Client(base_url=\"http://127.0.0.1:30000/v1\", "
"api_key=\"*\")\n"
"response = client.chat.completions.create(\n"
"    model=\"zai-org/GLM-4.6\",\n"
"    messages=[\n"
"        {\n"
"            \"role\": \"user\",\n"
"            \"content\": \"Question: Is Paris the Capital of France?\",\n"
"        }\n"
"    ],\n"
"    max_tokens=1024,\n"
"    extra_body={\n"
"        \"custom_logit_processor\": Glm4MoeThinkingBudgetLogitProcessor()."
"to_str(),\n"
"        \"custom_params\": {\n"
"            \"thinking_budget\": 512,\n"
"        },\n"
"    },\n"
")\n"
"pprint(response)\n"
msgstr ""
