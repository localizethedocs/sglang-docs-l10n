# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang stable\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-12-09 11:06+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:1
msgid "DP for Multi-Modal Encoder in SGLang"
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:3
msgid ""
"A typical VLM architecture involves two main components: an multi-modal "
"encoder and a text decoder."
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:5
msgid ""
"Most VLMs utilize a Vision Transformer (ViT) as their multi-modal encoder, "
"it is responsible for processing visual data, extracting features (objects, "
"colors, textures, etc.), and transforming them into a format that can be "
"understood by the model."
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:7
msgid ""
"The text deocoder is based on LLM. It processes textual data and generates "
"output based on the encoded visual features."
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:9
msgid ""
"However, since the size of ViT is very small compared to language decoders, "
"there is relatively little gain from TP. On the other hand, TP incurs "
"significant communication overhead because of all-reduce being performed "
"after every layer."
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:13
msgid ""
"Placing the ViT in data parallel while keeping the LLM in tensor parallel "
"consistently lowers TTFT and boosts end-to-end throughput. In this hybrid "
"layout, the vision front-end becomes parallel and lightweight, while scarce "
"interconnect bandwidth and collective ops are reserved for the LLM."
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:15
msgid ""
"Data parallelism replicates the entire model across multiple GPU sets and "
"processes different batches of requests in parallel."
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:17
msgid "Pros and Cons for DP Multi-Modal Encoder"
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:19
msgid ""
"Unfavorable compute/communication ratio for small ViTs ViTs used in "
"multimodal stacks are typically modest in parameter count and activation "
"sizes. TP introduces per-layer all-reduce collectives (attention/MLP) whose "
"latency and synchronization overhead outweigh the speedup of splitting "
"relatively small GEMMs. With DP, each GPU runs a full ViT locally—no "
"inference-time collectives—so latency is dominated by compute, not wire time."
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:22
msgid ""
"Graph-capture gaps amplify TP overhead In production, the vision path often "
"has dynamic shapes (pre/post-processing, variable resolution, patching) that "
"break CUDA Graphs and limit torch.compile fusion. Without capture, we need "
"to pay extra kernel-launch and framework overhead; TP then multiplies that "
"cost with additional NCCL synchronizations. Keeping ViT in DP avoids "
"layering collective latency on top of non-captured kernels."
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:25
msgid ""
"Better interconnect hygiene for the true bottleneck (the LLM) The LLM’s "
"prefill and decode phases benefit materially from TP on fast links. "
"Offloading ViT to DP eliminates “chatty” small collectives on the same "
"fabric, reducing congestion and jitter for the LLM’s large, bandwidth-hungry "
"all-reduces."
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:28
msgid ""
"Shorter and steadier critical path → lower TTFT TTFT ≈ T(image encode via "
"ViT) + T(LLM prefill) + T(softmax/sample) DP has several advantages: (a) "
"batch and prefetch ViT encodes independently, (b) overlap them with other "
"requests’ LLM decodes on separate streams, (c) hand off compact visual "
"embeddings to the TP LLM with minimal queuing."
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:35
msgid ""
"For vision encoders that use hardware-unoptimized Conv3D operations, batch-"
"level DP can provide another 40% improvement compared to regular TP."
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:38
msgid ""
"Nevertheless, since the weights of the multi-modal encoder are replicated "
"across each TP rank, there will be a minor increase in memory consumption "
"and may cause OOM if you can barely fit the model already."
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:41
msgid "Command Example"
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:42
msgid ""
"You can enable batch-level DP by setting `mm-enable-dp-encoder`, for example:"
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:43
msgid ""
"SGLANG_MM_FEATURE_CACHE_MB=4096 \\\n"
"SGLANG_USE_CUDA_IPC_TRANSPORT=1 \\\n"
"SGLANG_VLM_CACHE_SIZE_MB=512 \\\n"
"python3 -m sglang.launch_server --host 127.0.0.1 \\\n"
"    --mem-fraction-static 0.7 \\\n"
"    --port 30000 \\\n"
"    --trust-remote-code \\\n"
"    --dtype auto \\\n"
"    --max-running-requests 4 \\\n"
"    --chunked-prefill-size 8192 \\\n"
"    --attention-backend flashinfer \\\n"
"    --tp 4 \\\n"
"    --enable-multimodal \\\n"
"    --chat-template internvl-2-5 \\\n"
"    --model OpenGVLab/InternVL2_5-8B \\\n"
"    --disable-radix-cache \\\n"
"    --mm-enable-dp-encoder\n"
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:62
msgid ""
"!!! important     Batch-level multi-modal DP is not to be confused with API "
"request-level DP     (which is instead controlled by `data_parallel_size`)."
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:66
msgid "Known supported models"
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:67
msgid "Qwen2.5-VL (<https://github.com/sgl-project/sglang/pull/13126>)"
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:68
msgid "Qwen3-VL (<https://github.com/sgl-project/sglang/pull/13724>)"
msgstr ""

#: ../../../advanced_features/dp_for_multi_modal_encoder.md:69
msgid "InternVL (<https://github.com/sgl-project/sglang/pull/13925>)"
msgstr ""
