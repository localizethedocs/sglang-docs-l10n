# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang stable\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-11-09 18:38+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../references/custom_chat_template.md:1
msgid "Custom Chat Template"
msgstr ""

#: ../../../references/custom_chat_template.md:3
msgid ""
"**NOTE**: There are two chat template systems in SGLang project. This "
"document is about setting a custom chat template for the OpenAI-compatible "
"API server (defined at [conversation.py](https://github.com/sgl-project/"
"sglang/blob/main/python/sglang/srt/conversation.py)). It is NOT related to "
"the chat template used in the SGLang language frontend (defined at "
"[chat_template.py](https://github.com/sgl-project/sglang/blob/main/python/"
"sglang/lang/chat_template.py))."
msgstr ""

#: ../../../references/custom_chat_template.md:5
msgid ""
"By default, the server uses the chat template specified in the model "
"tokenizer from Hugging Face. It should just work for most official models "
"such as Llama-2/Llama-3."
msgstr ""

#: ../../../references/custom_chat_template.md:8
msgid ""
"If needed, you can also override the chat template when launching the server:"
msgstr ""

#: ../../../references/custom_chat_template.md:10
msgid ""
"python -m sglang.launch_server \\\n"
"  --model-path meta-llama/Llama-2-7b-chat-hf \\\n"
"  --port 30000 \\\n"
"  --chat-template llama-2\n"
msgstr ""

#: ../../../references/custom_chat_template.md:17
msgid ""
"If the chat template you are looking for is missing, you are welcome to "
"contribute it or load it from a file."
msgstr ""

#: ../../../references/custom_chat_template.md:19
msgid "JSON Format"
msgstr ""

#: ../../../references/custom_chat_template.md:21
msgid "You can load the JSON format, which is defined by `conversation.py`."
msgstr ""

#: ../../../references/custom_chat_template.md:23
msgid ""
"{\n"
"  \"name\": \"my_model\",\n"
"  \"system\": \"<|im_start|>system\",\n"
"  \"user\": \"<|im_start|>user\",\n"
"  \"assistant\": \"<|im_start|>assistant\",\n"
"  \"sep_style\": \"CHATML\",\n"
"  \"sep\": \"<|im_end|>\",\n"
"  \"stop_str\": [\"<|im_end|>\", \"<|im_start|>\"]\n"
"}\n"
msgstr ""

#: ../../../references/custom_chat_template.md:35
msgid ""
"python -m sglang.launch_server \\\n"
"  --model-path meta-llama/Llama-2-7b-chat-hf \\\n"
"  --port 30000 \\\n"
"  --chat-template ./my_model_template.json\n"
msgstr ""

#: ../../../references/custom_chat_template.md:42
msgid "Jinja Format"
msgstr ""

#: ../../../references/custom_chat_template.md:44
msgid ""
"You can also use the [Jinja template format](https://huggingface.co/docs/"
"transformers/main/en/chat_templating) as defined by Hugging Face "
"Transformers."
msgstr ""

#: ../../../references/custom_chat_template.md:46
msgid ""
"python -m sglang.launch_server \\\n"
"  --model-path meta-llama/Llama-2-7b-chat-hf \\\n"
"  --port 30000 \\\n"
"  --chat-template ./my_model_template.jinja\n"
msgstr ""
