# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2026, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang latest\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-01-05 08:33+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../platforms/ascend_npu_best_practice.md:1
msgid "Best Practice on Ascend NPU"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3
msgid ""
"This section describes the best practice data of mainstream LLM models such "
"as DeepSeek and Qwen on the Ascend Npu.If you encounter issues or have any "
"questions, please [open an issue](https://github.com/sgl-project/sglang/"
"issues)."
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:6
msgid "DeepSeek Series Models"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:8
#: ../../../platforms/ascend_npu_best_practice.md:30
msgid "Low Latency"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Model"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Hardware"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "CardNum"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Deploy Mode"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Dataset"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Quantization"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "TPOT(ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Output TPS(per card)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Configuration"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Deepseek-R1"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Atlas 800I A3"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "32"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "PD Separation"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "6K-1.6K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "W8A8"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "19.81"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "36.906"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#ds-r1-atlas-800i-a3-p32-6k1.6k-20ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "3.9K-1K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "19.77"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "35.625"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#ds-r1-atlas-800i-a3-p32-3.9k1k-20ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "3.5K-1.5K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "19.92"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "36.980"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#ds-r1-atlas-800i-a3-p32-3.5k1.5k-20ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "3.5K-1K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "19.52"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "36.344"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#ds-r1-atlas-800i-a3-p32-3.5k1k-20ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Deepseek-V3.2"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "64K-1K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "25.36"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "14.74"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#ds-v32-atlas-800i-a3-p32-64k1k-30ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:18
#: ../../../platforms/ascend_npu_best_practice.md:41
msgid "High Throughput"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "48.10"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "396.796"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#ds-r1-atlas-800i-a3-p32-3.5k1.5k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "8"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "PD Mixed"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "2K-2K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "W4A8"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "49.67"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "528.375"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#ds-r1-atlas-800i-a3-p8-2k2k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "16"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "47.76"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "452.227"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#ds-r1-atlas-800i-a3-p16-2k2k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "49.77"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "312.077"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#ds-r1-atlas-800i-a3-p8-3.5k1.5k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "49.43"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "361.500"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#ds-r1-atlas-800i-a3-p16-3.5k1.5k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:28
msgid "Qwen Series Models"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Qwen3-235B"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "11K-1K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "BF16"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "9.70"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "11.690"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-235b-atlas-800i-a3-p8-11k1k-10ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Qwen3-32B"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "4"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "6K-1.5K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "16.87"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "311.750"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-32b-atlas-800i-a3-p4-6k1.5k-18ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "4K-1.5K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "9.46"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "25.850"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-32b-atlas-800i-a3-p4-4k1.5k-11ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "18K-4K"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "12.27"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "9.955"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-32b-atlas-800i-a3-p8-18k4k-12ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Atlas 800I A2"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "16.46"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "296"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-32b-atlas-800i-a2-p8-6k1.5k-18ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "10.18"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "12"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-32b-atlas-800i-a2-p8-4k1.5k-11ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "24"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "40.75"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "467.416"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-235b-atlas-800i-a3-p24-3.5k1.5k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "51.51"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "477.625"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-235b-atlas-800i-a3-p8-3.5k1.5k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "54.78"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "790.071"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-235b-atlas-800i-a3-p8-2k2k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "50.12"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "519.625"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-235b-atlas-800i-a3-p16-2k2k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "2"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "49.20"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "707.500"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-32b-atlas-800i-a3-p2-3.5k1.5k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "48.30"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "986.150"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-32b-atlas-800i-a3-p2-2k2k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Qwen3-30B"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "1"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "44.35"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "3166.030"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-30b-atlas-800i-a3-p1-3.5k1.5k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Qwen3-480B"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "48.27"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "266.250"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-480b-atlas-800i-a3-p24-3.5k1.5k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "50.34"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "289.813"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-480b-atlas-800i-a3-p16-3.5k1.5k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "48.20"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "187.500"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-480b-atlas-800i-a3-p8-3.5k1.5k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "Qwen3-Next"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "49.91"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "702.83"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-next-atlas-800i-a3-p2-3.5k1.5k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "48.97"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "348.75"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-32b-atlas-800i-a2-p8-3.5k1.5k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "45.88"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "512"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:0
msgid "[Optimal Configuration](#qwen3-32b-atlas-800i-a2-p8-2k2k-50ms)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:59
msgid "Optimal Configuration"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:61
msgid "<a id=\"ds-r1-atlas-800i-a3-p32-3.5k1.5k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:61
msgid "<a id=\"ds-r1-atlas-800i-a3-p32-3.5k1.5k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:61
#: ../../../platforms/ascend_npu_best_practice.md:201
#: ../../../platforms/ascend_npu_best_practice.md:205
#: ../../../platforms/ascend_npu_best_practice.md:347
#: ../../../platforms/ascend_npu_best_practice.md:399
#: ../../../platforms/ascend_npu_best_practice.md:452
#: ../../../platforms/ascend_npu_best_practice.md:505
#: ../../../platforms/ascend_npu_best_practice.md:611
#: ../../../platforms/ascend_npu_best_practice.md:762
#: ../../../platforms/ascend_npu_best_practice.md:867
#: ../../../platforms/ascend_npu_best_practice.md:1026
#: ../../../platforms/ascend_npu_best_practice.md:1262
#: ../../../platforms/ascend_npu_best_practice.md:1423
#: ../../../platforms/ascend_npu_best_practice.md:1523
#: ../../../platforms/ascend_npu_best_practice.md:1626
#: ../../../platforms/ascend_npu_best_practice.md:1725
#: ../../../platforms/ascend_npu_best_practice.md:1843
#: ../../../platforms/ascend_npu_best_practice.md:1942
#: ../../../platforms/ascend_npu_best_practice.md:2045
#: ../../../platforms/ascend_npu_best_practice.md:2147
#: ../../../platforms/ascend_npu_best_practice.md:2242
#: ../../../platforms/ascend_npu_best_practice.md:2343
#: ../../../platforms/ascend_npu_best_practice.md:2445
#: ../../../platforms/ascend_npu_best_practice.md:2545
#: ../../../platforms/ascend_npu_best_practice.md:2696
#: ../../../platforms/ascend_npu_best_practice.md:2804
#: ../../../platforms/ascend_npu_best_practice.md:2895
#: ../../../platforms/ascend_npu_best_practice.md:2989
#: ../../../platforms/ascend_npu_best_practice.md:3091
#: ../../../platforms/ascend_npu_best_practice.md:3190
#: ../../../platforms/ascend_npu_best_practice.md:3289
msgid "</a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:63
msgid "Deepseek-R1 Atlas 800I A3-32Card PD Separation 3.5K-1.5K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:65
#: ../../../platforms/ascend_npu_best_practice.md:207
#: ../../../platforms/ascend_npu_best_practice.md:351
#: ../../../platforms/ascend_npu_best_practice.md:403
#: ../../../platforms/ascend_npu_best_practice.md:456
#: ../../../platforms/ascend_npu_best_practice.md:509
#: ../../../platforms/ascend_npu_best_practice.md:615
#: ../../../platforms/ascend_npu_best_practice.md:766
#: ../../../platforms/ascend_npu_best_practice.md:871
#: ../../../platforms/ascend_npu_best_practice.md:1030
#: ../../../platforms/ascend_npu_best_practice.md:1266
#: ../../../platforms/ascend_npu_best_practice.md:1427
#: ../../../platforms/ascend_npu_best_practice.md:1527
#: ../../../platforms/ascend_npu_best_practice.md:1630
#: ../../../platforms/ascend_npu_best_practice.md:1729
#: ../../../platforms/ascend_npu_best_practice.md:1847
#: ../../../platforms/ascend_npu_best_practice.md:1946
#: ../../../platforms/ascend_npu_best_practice.md:2049
#: ../../../platforms/ascend_npu_best_practice.md:2151
#: ../../../platforms/ascend_npu_best_practice.md:2246
#: ../../../platforms/ascend_npu_best_practice.md:2347
#: ../../../platforms/ascend_npu_best_practice.md:2449
#: ../../../platforms/ascend_npu_best_practice.md:2549
#: ../../../platforms/ascend_npu_best_practice.md:2700
#: ../../../platforms/ascend_npu_best_practice.md:2808
#: ../../../platforms/ascend_npu_best_practice.md:2899
#: ../../../platforms/ascend_npu_best_practice.md:2993
#: ../../../platforms/ascend_npu_best_practice.md:3095
#: ../../../platforms/ascend_npu_best_practice.md:3194
#: ../../../platforms/ascend_npu_best_practice.md:3293
msgid "Model Deployment"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:67
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"export ASCEND_MF_STORE_URL=\"tcp://your prefill ip1:24669\"\n"
"\n"
"P_IP=('your prefill ip1' 'your prefill ip2')\n"
"\n"
"D_IP=('your prefill ip1' 'your prefill ip2')\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"# prefill\n"
"for i in \"${!P_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${P_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${P_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${P_IP[$i]}\"\n"
"        export HCCL_BUFFSIZE=1536\n"
"        export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"        export TASK_QUEUE_ENABLE=2\n"
"\n"
"        export HCCL_SOCKET_IFNAME=lo\n"
"        export GLOO_SOCKET_IFNAME=lo\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH}  --"
"disaggregation-mode prefill --host ${P_IP[$i]} \\\n"
"        --port 8000 --disaggregation-bootstrap-port $((8998+$i)) --trust-"
"remote-code --nnodes 1 --node-rank 0 \\\n"
"        --tp-size 16 --mem-fraction-static 0.81 --attention-backend ascend --"
"device npu --quantization modelslim \\\n"
"        --disaggregation-transfer-backend ascend --max-running-requests 8 --"
"context-length 8192  --disable-radix-cache \\\n"
"        --chunked-prefill-size -1 --max-prefill-tokens 28680 --moe-a2a-"
"backend deepep --deepep-mode normal \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 1 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 2  \\\n"
"        --dp-size 2 --enable-dp-attention --disable-shared-experts-fusion --"
"dtype bfloat16 --enable-attn-tp-input-scattered\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
"# decode\n"
"for i in \"${!D_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${D_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${D_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${D_IP[$i]}\"\n"
"        export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"        export SGLANG_ENABLE_SPEC_V2=1\n"
"        export HCCL_BUFFSIZE=650\n"
"        export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=78\n"
"        export TASK_QUEUE_ENABLE=0\n"
"        export SGLANG_SCHEDULER_SKIP_ALL_GATHER=1\n"
"        export HCCL_SOCKET_IFNAME=xxx\n"
"        export GLOO_SOCKET_IFNAME=xxx\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode decode --host ${D_IP[$i]} \\\n"
"        --port 8001 --trust-remote-code --dist-init-addr DIP1:5000 --nnodes "
"2 --node-rank $i --tp-size 32 --dp-size 32 \\\n"
"        --mem-fraction-static 0.815 --max-running-requests 832 --attention-"
"backend ascend --device npu --quantization modelslim \\\n"
"        --moe-a2a-backend deepep --enable-dp-attention --deepep-mode "
"low_latency --enable-dp-lm-head --moe-dense-tp 1 \\\n"
"        --cuda-graph-bs 12 14 16 18 20 22 24 26 --disaggregation-transfer-"
"backend ascend --watchdog-timeout 9000 --context-length 8192 \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 2 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 3  \\\n"
"        --tokenizer-worker-num 4 --prefill-round-robin-balance --disable-"
"shared-experts-fusion --dtype bfloat16 \\\n"
"        --load-balance-method decode_round_robin\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:149
#: ../../../platforms/ascend_npu_best_practice.md:289
msgid ""
"export SGLANG_DP_ROUND_ROBIN=1\n"
"python -m sglang_router.launch_router \\\n"
"    --pd-disaggregation \\\n"
"    --policy cache_aware \\\n"
"    --prefill http://P_IP:8000 8998 \\\n"
"    --prefill http://P_IP:8000 8999 \\\n"
"    --decode http://D_IP:8001 \\\n"
"    --host 127.0.0.1 \\\n"
"    --port 6688 \\\n"
"    --mini-lb\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:162
#: ../../../platforms/ascend_npu_best_practice.md:302
#: ../../../platforms/ascend_npu_best_practice.md:355
#: ../../../platforms/ascend_npu_best_practice.md:407
#: ../../../platforms/ascend_npu_best_practice.md:460
#: ../../../platforms/ascend_npu_best_practice.md:567
#: ../../../platforms/ascend_npu_best_practice.md:718
#: ../../../platforms/ascend_npu_best_practice.md:821
#: ../../../platforms/ascend_npu_best_practice.md:973
#: ../../../platforms/ascend_npu_best_practice.md:1220
#: ../../../platforms/ascend_npu_best_practice.md:1381
#: ../../../platforms/ascend_npu_best_practice.md:1478
#: ../../../platforms/ascend_npu_best_practice.md:1577
#: ../../../platforms/ascend_npu_best_practice.md:1681
#: ../../../platforms/ascend_npu_best_practice.md:1797
#: ../../../platforms/ascend_npu_best_practice.md:1898
#: ../../../platforms/ascend_npu_best_practice.md:1995
#: ../../../platforms/ascend_npu_best_practice.md:2099
#: ../../../platforms/ascend_npu_best_practice.md:2199
#: ../../../platforms/ascend_npu_best_practice.md:2294
#: ../../../platforms/ascend_npu_best_practice.md:2396
#: ../../../platforms/ascend_npu_best_practice.md:2497
#: ../../../platforms/ascend_npu_best_practice.md:2651
#: ../../../platforms/ascend_npu_best_practice.md:2761
#: ../../../platforms/ascend_npu_best_practice.md:2854
#: ../../../platforms/ascend_npu_best_practice.md:2945
#: ../../../platforms/ascend_npu_best_practice.md:3040
#: ../../../platforms/ascend_npu_best_practice.md:3146
#: ../../../platforms/ascend_npu_best_practice.md:3242
#: ../../../platforms/ascend_npu_best_practice.md:3341
msgid "Benchmark"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:164
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 832  --random-input-len 3500 --"
"random-output-len 1500 --num-prompts 3328 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:168
msgid ""
"============ Serving Benchmark Result ============\n"
"Backend: sqlang\n"
"Traffic request rate: inf\n"
"Max request concurrency: 832\n"
"Successful requests: 3328\n"
"Benchmark duration (s): 393.15\n"
"Total input tokens: 11202837\n"
"Total input text tokens: 11202837\n"
"Total input vision tokens: 0\n"
"Total generated tokens (retokenized): 4992000\n"
"Request throughput (req/s): 8.465\n"
"Output token throughput (tok/s): 12697.4868\n"
"Total token throughput (tok/s): 41192.654\n"
"Concurrency: 696.859\n"
"-----------------End-to-End Latency----------------\n"
"Mean E2E Latency (ms): 82322.96\n"
"Median E2E Latency (ms): 82395.75\n"
"----------------Time to First Token----------------\n"
"Mean TTFT (ms): 10170.34\n"
"Median TTFT (ms): 8273.99\n"
"P99 TTFT (ms): 29787.93\n"
"----------------Output Token (excl. 1st token)----------------\n"
"Mean PTOT (ms): 48.10\n"
"Median PTOT (ms): 49.12\n"
"P99 PTOT (ms): 55.02\n"
"----------------Inter-Token Latency----------------\n"
"Mean ITL (ms): 122.53\n"
"Median ITL (ms): 120.08\n"
"P99 ITL (ms): 278.32\n"
"Max ITL (ms): 838.11\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:201
msgid "<a id=\"ds-r1-atlas-800i-a3-p32-6k1.6k-20ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:201
msgid "<a id=\"ds-r1-atlas-800i-a3-p32-6k1.6k-20ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:203
msgid "Deepseek-R1 Atlas 800I A3-32Card PD Separation 6K-1.6K 20ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:205
msgid "<a id=\"ds-r1-low-latency-deploy\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:205
msgid "<a id=\"ds-r1-low-latency-deploy\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:209
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"export ASCEND_MF_STORE_URL=\"tcp://your prefill ip1:24669\"\n"
"\n"
"P_IP=('your prefill ip1' 'your prefill ip2')\n"
"\n"
"D_IP=('your decode ip1' 'your decode ip2')\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"# prefill\n"
"for i in \"${!P_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${P_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${P_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${P_IP[$i]}\"\n"
"        export HCCL_BUFFSIZE=1536\n"
"        export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"        export TASK_QUEUE_ENABLE=2\n"
"\n"
"        export HCCL_SOCKET_IFNAME=lo\n"
"        export GLOO_SOCKET_IFNAME=lo\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH}  --"
"disaggregation-mode prefill --host ${P_IP[$i]} \\\n"
"        --port 8000 --disaggregation-bootstrap-port $((8998+$i)) --trust-"
"remote-code --nnodes 1 --node-rank 0 \\\n"
"        --tp-size 16 --mem-fraction-static 0.81 --attention-backend ascend --"
"device npu --quantization modelslim \\\n"
"        --disaggregation-transfer-backend ascend --max-running-requests 4 --"
"context-length 8192  --disable-radix-cache \\\n"
"        --chunked-prefill-size -1 --max-prefill-tokens 28680 --moe-a2a-"
"backend deepep --deepep-mode normal \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 1 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 2  \\\n"
"        --dp-size 2 --enable-dp-attention --disable-shared-experts-fusion --"
"dtype bfloat16 --enable-attn-tp-input-scattered\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
"# decode\n"
"for i in \"${!D_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${D_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${D_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${D_IP[$i]}\"\n"
"        export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"        export SGLANG_ENABLE_SPEC_V2=1\n"
"        export HCCL_BUFFSIZE=650\n"
"        export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=12\n"
"        export TASK_QUEUE_ENABLE=0\n"
"        export SGLANG_SCHEDULER_SKIP_ALL_GATHER=1\n"
"        export HCCL_SOCKET_IFNAME=xxx\n"
"        export GLOO_SOCKET_IFNAME=xxx\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode decode --host ${D_IP[$i]} \\\n"
"        --port 8001 --trust-remote-code --dist-init-addr DIP1:5000 --nnodes "
"2 --node-rank $i --tp-size 32 --dp-size 16 \\\n"
"        --mem-fraction-static 0.75 --max-running-requests 32 --attention-"
"backend ascend --device npu --quantization modelslim \\\n"
"        --moe-a2a-backend deepep --enable-dp-attention --deepep-mode "
"low_latency --enable-dp-lm-head --moe-dense-tp 1 \\\n"
"        --cuda-graph-bs 4 --disaggregation-transfer-backend ascend --"
"watchdog-timeout 9000 --context-length 8192 \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 3 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 4  \\\n"
"        --tokenizer-worker-num 4 --prefill-round-robin-balance --disable-"
"shared-experts-fusion --dtype bfloat16 \\\n"
"        --load-balance-method decode_round_robin\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:304
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 32  --random-input-len 6000 --random-"
"output-len 1600 --num-prompts 32 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:308
msgid ""
"========== Serving Benchmark Result ==========\n"
"Backend:                             sglang\n"
"Traffic request rate:                inf\n"
"Max request concurrency:             32\n"
"Successful requests:                 32\n"
"Benchmark duration (s):              43.34\n"
"Total input tokens:                  192000\n"
"Total input text tokens:             192000\n"
"Total input vision tokens:           0\n"
"Total generated tokens:              51200\n"
"Total generated tokens (retokenized): 50985\n"
"Request throughput (req/s):          0.74\n"
"Input token throughput (tok/s):      4429.93\n"
"Output token throughput (tok/s):     1181.31\n"
"Peak output token throughput (tok/s): 1667.00\n"
"Peak concurrent requests:            32\n"
"Total token throughput (tok/s):      5611.24\n"
"Concurrency:                         27.19\n"
"Accept length:                       2.59\n"
"---------- End-To-End Latency ----------\n"
"Mean E2E Latency (ms):               36921.96\n"
"Median E2E Latency (ms):             36785.75\n"
"---------- Time to First Token ----------\n"
"Mean TTFT (ms):                      5149.34\n"
"Median TTFT (ms):                    5146.99\n"
"P99 TTFT (ms):                       9015.93\n"
"---------- Time per Output Token (excl. 1st token) ----------\n"
"Mean TPOT (ms):                      19.81\n"
"Median TPOT (ms):                    20.22\n"
"P99 TPOT (ms):                       23.74\n"
"---------- Inter-Token Latency ----------\n"
"Mean ITL (ms):                       19.81\n"
"Median ITL (ms):                     19.08\n"
"P95 ITL (ms):                        29.95\n"
"P99 ITL (ms):                        55.85\n"
"Max ITL (ms):                        123.03\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:347
msgid "<a id=\"ds-r1-atlas-800i-a3-p32-3.9k1k-20ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:347
msgid "<a id=\"ds-r1-atlas-800i-a3-p32-3.9k1k-20ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:349
msgid "Deepseek-R1 Atlas 800I A3-32Card PD Separation 3.9K-1K 20ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:353
msgid "Please Turn to [Model Deployment](#ds-r1-low-latency-deploy)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:357
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 32  --random-input-len 3900 --random-"
"output-len 1000 --num-prompts 32 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:361
msgid ""
"========== Serving Benchmark Result ==========\n"
"Backend:                              sglang\n"
"Traffic request rate:                 inf\n"
"Max request concurrency:              32\n"
"Successful requests:                  32\n"
"Benchmark duration (s):               28.07\n"
"Total input tokens:                   124800\n"
"Total input text tokens:              0\n"
"Total generated vision tokens:        32000\n"
"Total generated tokens (retokenized): 31809\n"
"Request throughput (req/s):           1.14\n"
"Input token throughput (tok/s):       4446.13\n"
"Output token throughput (tok/s):      1148.03\n"
"Peak output token throughput (tok/s): 1702.00\n"
"Peak concurrent requests:             32\n"
"Output token throughput (tok/s):      5586.16\n"
"Concurrency:                          25.82\n"
"Accept length:                        2.88\n"
"---------- End-to-End Latency ----------\n"
"Mean E2E Latency (ms):                22650.75\n"
"Median E2E Latency (ms):              22649.04\n"
"---------- Time to First Token ----------\n"
"Mean TTFT (ms):                       2901.77\n"
"Median TTFT (ms):                     2357.79\n"
"P99 TTFT (ms):                        4240.04\n"
"---------- Time per Output Token (excl. 1st token) ----------\n"
"Mean TPOT (ms):                       19.77\n"
"Median TPOT (ms):                     19.68\n"
"P99 TPOT (ms):                        23.90\n"
"---------- Inter-Token Latency ----------\n"
"Mean ITL (ms):                        19.77\n"
"Median ITL (ms):                      19.93\n"
"P95 ITL (ms):                         29.72\n"
"P99 ITL (ms):                         57.10\n"
"Max ITL (ms):                         122.71\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:399
msgid "<a id=\"ds-r1-atlas-800i-a3-p32-3.5k1.5k-20ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:399
msgid "<a id=\"ds-r1-atlas-800i-a3-p32-3.5k1.5k-20ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:401
msgid "Deepseek-R1 Atlas 800I A3-32Card PD Separation 3.5K-1.5K 20ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:405
#: ../../../platforms/ascend_npu_best_practice.md:458
msgid "Please turn to [Model Deployment](#ds-r1-low-latency-deploy)"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:409
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 32  --random-input-len 3500 --random-"
"output-len 1500 --num-prompts 32 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:413
msgid ""
"========== Serving Benchmark Result ==========\n"
"Backend:                              sglang\n"
"Traffic request rate:                 inf\n"
"Max request concurrency:              32\n"
"Successful requests:                  32\n"
"Benchmark duration (s):               40.56\n"
"Total input tokens:                   112000\n"
"Total input text tokens:              112000\n"
"Total input vision tokens:            0\n"
"Total generated tokens:               48000\n"
"Total generated tokens (retokenized): 47787\n"
"Request throughput (req/s):           0.79\n"
"Input token throughput (tok/s):       2761.16\n"
"Output token throughput (tok/s):      1183.35\n"
"Peak output token throughput (tok/s): 1665.00\n"
"Peak concurrent requests:             32\n"
"Total token throughput (tok/s):       3944.51\n"
"Concurrency:                          25.66\n"
"Accept length:                        2.84\n"
"---------- End-to-End Latency ----------\n"
"Mean E2E Latency (ms):                32526.35\n"
"Median E2E Latency (ms):              32200.67\n"
"---------- Time to First Token ----------\n"
"Mean TTFT (ms):                       2671.91\n"
"Median TTFT (ms):                     2208.48\n"
"P99 TTFT (ms):                        3960.99\n"
"---------- Time per Output Token (excl. 1st token) ----------\n"
"Mean TPOT (ms):                       19.92\n"
"Median TPOT (ms):                     19.91\n"
"P99 TPOT (ms):                        24.64\n"
"---------- Inter-Token Latency ----------\n"
"Mean ITL (ms):                        19.92\n"
"Median ITL (ms):                      18.91\n"
"P95 ITL (ms):                         30.06\n"
"P99 ITL (ms):                         57.76\n"
"Max ITL (ms):                         189.36\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:452
msgid "<a id=\"ds-r1-atlas-800i-a3-p32-3.5k1k-20ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:452
msgid "<a id=\"ds-r1-atlas-800i-a3-p32-3.5k1k-20ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:454
msgid "Deepseek-R1 Atlas 800I A3-32Card PD Separation 3.5K-1K 20ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:462
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 32  --random-input-len 3500 --random-"
"output-len 1000 --num-prompts 32 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:466
msgid ""
"Backend:\n"
"================ Serving Benchmark Result ===================\n"
"Backend:                                 sglang\n"
"Traffic request rate:                    inf\n"
"Max request concurrency:                 32\n"
"Successful requests:                     32\n"
"Benchmark duration (s):                  27.50\n"
"Total input tokens:                      112000\n"
"Total input text tokens:                 0\n"
"Total input vision tokens:               0\n"
"Total generated tokens:                  32000\n"
"Total generated tokens (retokenized):    31837\n"
"Request throughput (req/s):              1.16\n"
"Input token throughput (tok/s):          4072.55\n"
"Output token throughput (tok/s):         1163.59\n"
"Peak output token throughput (tok/s):    1692.00\n"
"Peak concurrent requests:                32\n"
"Total token throughput (tok/s):          5236.14\n"
"Concurrency:                             25.78\n"
"Accept length:                           2.84\n"
"------------------ End-To-End Latency ------------------\n"
"Mean E2E Latency (ms):                   22154.99\n"
"Median E2E Latency (ms):                 22262.70\n"
"------------------ Time to First Token ------------------\n"
"Mean TTFT (ms):                          2655.44\n"
"Median TTFT (ms):                        2205.10\n"
"P99 TTFT (ms):                           4446.79\n"
"------------------ Time per Output Token (excl. 1st token) "
"------------------\n"
"Mean TPOT (ms):                          19.52\n"
"Median TPOT (ms):                        19.82\n"
"P99 TPOT (ms):                           25.19\n"
"------------------ Inter-Token Latency ------------------\n"
"Mean ITL (ms):                           19.52\n"
"Median ITL (ms):                         18.81\n"
"P99 ITL (ms):                            29.56\n"
"Max ITL (ms):                            65.46\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:505
msgid "<a id=\"ds-r1-atlas-800i-a3-p8-2k2k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:505
msgid "<a id=\"ds-r1-atlas-800i-a3-p8-2k2k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:507
msgid "Deepseek-R1 Atlas 800I A3-8Card PD Mixed 2K-2K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:511
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"export SGLANG_SCHEDULER_DECREASE_PREFILL_IDLE=1\n"
"\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=64\n"
"export HCCL_BUFFSIZE=1600\n"
"export DEEPEP_NORMAL_LONG_SEQ_ROUND=10\n"
"export DEEPEP_NORMAL_LONG_SEQ_PER_ROUND_TOKENS=512\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"\n"
"python3 -m sglang.launch_server --model-path ${MODEL_PATH} \\\n"
"--tp 16 \\\n"
"--trust-remote-code \\\n"
"--attention-backend ascend \\\n"
"--device npu \\\n"
"--quantization modelslim \\\n"
"--watchdog-timeout 9000 \\\n"
"--host 127.0.0.1 --port 6699 \\\n"
"--cuda-graph-bs 4 8 16 \\\n"
"--mem-fraction-static 0.74 \\\n"
"--max-running-requests 256 \\\n"
"--disable-radix-cache --chunked-prefill-size -1 --max-prefill-tokens 1500 "
"\\\n"
"--moe-a2a-backend deepep --deepep-mode auto \\\n"
"--enable-dp-attention --dp-size 16 --enable-dp-lm-head \\\n"
"--speculative-algorithm NEXTN --speculative-num-steps 3 --speculative-eagle-"
"topk 1 --speculative-num-draft-tokens 4 \\\n"
"--dtype bfloat16\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:569
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6699 --max-concurrency 256  --random-input-len 2048 --"
"random-output-len 2048 --num-prompts 1024 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:573
msgid ""
"============= Serving Benchmark Result ================\n"
"Backend                                 sglang\n"
"Traffic request rate:                   inf\n"
"Max request concurrency:                255\n"
"Successful requests:                    1024\n"
"Benchmark duration (s):                 496.11\n"
"Total input tokens:                     2097152\n"
"Total input text tokens:                2097152\n"
"Total input vision tokens:              0\n"
"Total generated tokens:                 2097152\n"
"Total generated tokens (retokenized):   2091432\n"
"Request throughput (req/s):             2.06\n"
"Input token throughput (tok/s):         4227.20\n"
"Output token throughput (tok/s):        4227.20\n"
"Peak output token throughput (tok/s):   7098.00\n"
"Peak concurrent requests:               275\n"
"Total token throughput (tok/s):         8454.39\n"
"Concurrency:                            231.08\n"
"Accept length:                          2.82\n"
"====================End-To-End Latency============\n"
"Mean E2E Latency (ms):                  111956.34\n"
"Median E2E Latency (ms):                113251.95\n"
"====================Time to First Token===========\n"
"Mean TTFT (ms):                         10273.92\n"
"Median TTFT (ms):                       8592.03\n"
"P99 TTFT (ms):                          28535.07\n"
"=== Time per Output Token (excl. 1st tok) ===\n"
"Mean TPOT (ms):                         49.67\n"
"Median TPOT (ms):                       50.30\n"
"P99 TPOT (ms):                          66.12\n"
"====================Inter-Token Latency===========\n"
"Mean ITL (ms):                          49.67\n"
"Median ITL (ms):                        34.83\n"
"P99 ITL (ms):                           75.91\n"
"Max ITL (ms):                           18621.17\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:611
msgid "<a id=\"ds-r1-atlas-800i-a3-p16-2k2k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:611
msgid "<a id=\"ds-r1-atlas-800i-a3-p16-2k2k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:613
msgid "Deepseek-R1 Atlas 800I A3-16Card PD Separation 2K-2K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:617
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"export ASCEND_MF_STORE_URL=\"tcp://your prefill ip1:24667\"\n"
"\n"
"P_IP=('your prefill ip1')\n"
"\n"
"D_IP=('your decode ip1')\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"# prefill\n"
"for i in \"${!P_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${P_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${P_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${P_IP[$i]}\"\n"
"        export HCCL_BUFFSIZE=1536\n"
"        export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"        export TASK_QUEUE_ENABLE=2\n"
"\n"
"        export HCCL_SOCKET_IFNAME=lo\n"
"        export GLOO_SOCKET_IFNAME=lo\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH}  --"
"disaggregation-mode prefill --host ${P_IP[$i]} \\\n"
"        --port 8000 --disaggregation-bootstrap-port $((8998+$i)) --trust-"
"remote-code --nnodes 1 --node-rank 0 \\\n"
"        --tp-size 16 --mem-fraction-static 0.6 --attention-backend ascend --"
"device npu --quantization modelslim \\\n"
"        --disaggregation-transfer-backend ascend --max-running-requests 8 --"
"context-length 8192  --disable-radix-cache \\\n"
"        --chunked-prefill-size 32768 --max-prefill-tokens 28680 --moe-a2a-"
"backend deepep --deepep-mode normal \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 1 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 2  \\\n"
"        --dp-size 2 --enable-dp-attention --disable-shared-experts-fusion --"
"dtype bfloat16\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
"# decode\n"
"for i in \"${!D_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${D_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${D_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${D_IP[$i]}\"\n"
"        export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"        export SGLANG_ENABLE_SPEC_V2=1\n"
"        export HCCL_BUFFSIZE=720\n"
"        export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=96\n"
"        export TASK_QUEUE_ENABLE=0\n"
"        export HCCL_SOCKET_IFNAME=xxx\n"
"        export GLOO_SOCKET_IFNAME=xxx\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode decode --host ${D_IP[$i]} \\\n"
"        --port 8001 --trust-remote-code --nnodes 1 --node-rank 0 --tp-size "
"16 --dp-size 16 \\\n"
"        --mem-fraction-static 0.8 --max-running-requests 384 --attention-"
"backend ascend --device npu --quantization modelslim \\\n"
"        --moe-a2a-backend deepep --enable-dp-attention --deepep-mode "
"low_latency --enable-dp-lm-head \\\n"
"        --cuda-graph-bs 8 10 12 14 16 18 20 22 24 --disaggregation-transfer-"
"backend ascend --watchdog-timeout 9000 --context-length 8192 \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 3 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 4  \\\n"
"        --prefill-round-robin-balance --disable-shared-experts-fusion --"
"dtype bfloat16 --tokenizer-worker-num 4 \\\n"
"\t\t    --load-balance-method decode_round_robin\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:706
#: ../../../platforms/ascend_npu_best_practice.md:961
msgid ""
"export SGLANG_DP_ROUND_ROBIN=1\n"
"python -m sglang_router.launch_router \\\n"
"    --pd-disaggregation \\\n"
"    --policy cache_aware \\\n"
"    --prefill http://P_IP:8000 8998 \\\n"
"    --decode http://D_IP:8001 \\\n"
"    --host 127.0.0.1 \\\n"
"    --port 6688 \\\n"
"    --mini-lb\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:720
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 400  --random-input-len 2048 --"
"random-output-len 2048 --num-prompts 3200 --random-range-ratio 1 --request-"
"rate 8\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:724
msgid ""
"==================== Serving Benchmark Result ====================\n"
"Backend:                             sglang\n"
"Traffic request rate:                8.0\n"
"Max request concurrency:             400\n"
"Successful requests:                 3200\n"
"Benchmark duration (s):              905.74\n"
"Total input tokens:                  6553600\n"
"Total input text tokens:             6553600\n"
"Total input vision tokens:           0\n"
"Total generated tokens (retokenized): 6534368\n"
"Request throughput (req/s):          3.53\n"
"Input token throughput (tok/s):      7235.64\n"
"Output token throughput (tok/s):     7235.64\n"
"Peak output token throughput (tok/s): 9112.00\n"
"Peak concurrent requests:            411\n"
"Total token throughput (tok/s):      14471.28\n"
"Concurrency:                         363.54\n"
"Accept length:                       2.86\n"
"------------------------ End-to-End Latency ------------------------\n"
"Mean E2E Latency (ms):               102896.35\n"
"Median E2E Latency (ms):             104894.80\n"
"------------------------ Time to First Token -----------------------\n"
"Mean TTFT (ms):                      5138.54\n"
"Median TTFT (ms):                    3356.93\n"
"P99 TTFT (ms):                       20223.25\n"
"------------------ Time per Output Token (excl. 1st token) ----------\n"
"Mean TPOT (ms):                      47.76\n"
"Median TPOT (ms):                    48.84\n"
"P99 TPOT (ms):                       62.18\n"
"------------------------ Inter-Token Latency -----------------------\n"
"Mean ITL (ms):                       47.76\n"
"Median ITL (ms):                     40.66\n"
"P95 ITL (ms):                        83.83\n"
"P99 ITL (ms):                        147.10\n"
"Max ITL (ms):                        674.12\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:762
msgid "<a id=\"ds-r1-atlas-800i-a3-p8-3.5k1.5k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:762
msgid "<a id=\"ds-r1-atlas-800i-a3-p8-3.5k1.5k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:764
msgid "Deepseek-R1 Atlas 800I A3-8Card PD Mixed 3.5K-1.5K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:768
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"export STREAMS_PER_DEVICE=32\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export SGLANG_SCHEDULER_DECREASE_PREFILL_IDLE=1\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=36\n"
"export HCCL_BUFFSIZE=1600\n"
"export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"python3 -m sglang.launch_server --model-path ${MODEL_PATH} \\\n"
"--tp 16 \\\n"
"--trust-remote-code \\\n"
"--attention-backend ascend \\\n"
"--device npu \\\n"
"--quantization modelslim \\\n"
"--watchdog-timeout 9000 \\\n"
"--host 127.0.0.1 --port 6699 \\\n"
"--cuda-graph-bs 8 16 24 28 32 36 \\\n"
"--mem-fraction-static 0.71 \\\n"
"--max-running-requests 144 \\\n"
"--context-length 8188  --disable-radix-cache --chunked-prefill-size -1 --max-"
"prefill-tokens 9000 \\\n"
"--moe-a2a-backend deepep --deepep-mode auto \\\n"
"--enable-dp-attention --dp-size 4 --enable-dp-lm-head \\\n"
"--speculative-algorithm NEXTN --speculative-num-steps 3 --speculative-eagle-"
"topk 1 --speculative-num-draft-tokens 4 \\\n"
"--dtype bfloat16\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:823
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6699 --max-concurrency 144  --random-input-len 3500 --"
"random-output-len 1500 --num-prompts 576 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:827
msgid ""
"--------------- Serving Benchmark Result -----------------\n"
"Backend:                             sglang\n"
"Traffic request rate:                inf\n"
"Max request concurrency:             144\n"
"Successful requests:                 576\n"
"Benchmark duration (s):              346.07\n"
"Total input tokens:                  2016000\n"
"Total input text tokens:             2016000\n"
"Total input vision tokens:           0\n"
"Total generated tokens:              864000\n"
"Total generated tokens (retokenized): 861521\n"
"Request throughput (req/s):          1.66\n"
"Input token throughput (tok/s):      5825.46\n"
"Output token throughput (tok/s):     2496.62\n"
"Peak output token throughput (tok/s): 4724.00\n"
"Peak concurrent requests:            157\n"
"Total token throughput (tok/s):      8322.08\n"
"Concurrency:                         135.48\n"
"Accept length:                       2.83\n"
"-----------------------------------------------------------\n"
"-------- End-to-End Latency --------\n"
"Mean E2E Latency (ms):               81395.45\n"
"Median E2E Latency (ms):             82243.44\n"
"-------- Time to First Token --------\n"
"Mean TTFT (ms):                      6788.93\n"
"Median TTFT (ms):                    3911.21\n"
"P99 TTFT (ms):                       26898.02\n"
"-------- Time per Output Token (excl. 1st token) --------\n"
"Mean TPOT (ms):                      49.77\n"
"Median TPOT (ms):                    50.36\n"
"P99 TPOT (ms):                       68.57\n"
"-------- Inter-Token Latency --------\n"
"Mean ITL (ms):                       49.77\n"
"Median ITL (ms):                     29.30\n"
"P95 ITL (ms):                        92.28\n"
"P99 ITL (ms):                        509.53\n"
"Max ITL (ms):                        19821.92\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:867
msgid "<a id=\"ds-r1-atlas-800i-a3-p16-3.5k1.5k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:867
msgid "<a id=\"ds-r1-atlas-800i-a3-p16-3.5k1.5k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:869
msgid "Deepseek-R1 Atlas 800I A3-16Card PD Separation 3.5K-1.5K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:873
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"export ASCEND_MF_STORE_URL=\"tcp://your prefill ip1:24667\"\n"
"\n"
"P_IP=('your prefill ip1')\n"
"\n"
"D_IP=('your decode ip1')\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"# prefill\n"
"for i in \"${!P_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${P_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${P_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${P_IP[$i]}\"\n"
"        export HCCL_BUFFSIZE=1536\n"
"        export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"        export TASK_QUEUE_ENABLE=2\n"
"\n"
"        export HCCL_SOCKET_IFNAME=lo\n"
"        export GLOO_SOCKET_IFNAME=lo\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH}  --"
"disaggregation-mode prefill --host ${P_IP[$i]} \\\n"
"        --port 8000 --disaggregation-bootstrap-port $((8998+$i)) --trust-"
"remote-code --nnodes 1 --node-rank 0 \\\n"
"        --tp-size 16 --mem-fraction-static 0.6 --attention-backend ascend --"
"device npu --quantization modelslim \\\n"
"        --disaggregation-transfer-backend ascend --max-running-requests 8 --"
"context-length 8192  --disable-radix-cache \\\n"
"        --chunked-prefill-size -1 --max-prefill-tokens 28680 --moe-a2a-"
"backend deepep --deepep-mode normal \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 1 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 2  \\\n"
"        --dp-size 2 --enable-dp-attention --disable-shared-experts-fusion --"
"dtype bfloat16\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
"# decode\n"
"for i in \"${!D_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${D_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${D_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${D_IP[$i]}\"\n"
"        export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"        export SGLANG_ENABLE_SPEC_V2=1\n"
"        export HCCL_BUFFSIZE=720\n"
"        export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=96\n"
"        export TASK_QUEUE_ENABLE=0\n"
"        export HCCL_SOCKET_IFNAME=xxx\n"
"        export GLOO_SOCKET_IFNAME=xxx\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode decode --host ${D_IP[$i]} \\\n"
"        --port 8001 --trust-remote-code --nnodes 1 --node-rank 0 --tp-size "
"16 --dp-size 16 \\\n"
"        --mem-fraction-static 0.8 --max-running-requests 384 --attention-"
"backend ascend --device npu --quantization modelslim \\\n"
"        --moe-a2a-backend deepep --enable-dp-attention --deepep-mode "
"low_latency --enable-dp-lm-head \\\n"
"        --cuda-graph-bs 8 10 12 14 16 18 20 22 24 --disaggregation-transfer-"
"backend ascend --watchdog-timeout 9000 --context-length 8192 \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 3 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 4  \\\n"
"        --prefill-round-robin-balance --disable-shared-experts-fusion --"
"dtype bfloat16 --tokenizer-worker-num 4 \\\n"
"\t\t    --load-balance-method decode_round_robin\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:975
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 384  --random-input-len 3500 --"
"random-output-len 1500 --num-prompts 1536 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:979
msgid ""
"=======================================\n"
"Serving Benchmark Result\n"
"=======================================\n"
"Backend:                             sglang\n"
"Traffic request rate:                8.0\n"
"Max request concurrency:             384\n"
"Successful requests:                 1536\n"
"Benchmark duration (s):              398.28\n"
"Total input tokens:                  5376000\n"
"Total input text tokens:             5376000\n"
"Total input vision tokens:           0\n"
"Total generated tokens (retokenized): 2297661\n"
"Request throughput (req/s):          3.86\n"
"Input token throughput (tok/s):      13498.06\n"
"Output token throughput (tok/s):     5784.88\n"
"Peak output token throughput (tok/s): 8359.00\n"
"Peak concurrent requests:            395\n"
"Total token throughput (tok/s):      19282.95\n"
"Concurrency:                         323.46\n"
"Accept length:                       2.87\n"
"---------------------------------------\n"
"End-to-End Latency\n"
"---------------------------------------\n"
"Mean E2E Latency (ms):               83871.76\n"
"Median E2E Latency (ms):             84454.65\n"
"---------------------------------------\n"
"Time to First Token\n"
"---------------------------------------\n"
"Mean TTFT (ms):                      9784.06\n"
"Median TTFT (ms):                    6542.10\n"
"P99 TTFT (ms):                       31487.26\n"
"---------------------------------------\n"
"Time per Output Token (excl. 1st token)\n"
"---------------------------------------\n"
"Mean TPOT (ms):                      49.42\n"
"Median TPOT (ms):                    50.13\n"
"P99 TPOT (ms):                       66.06\n"
"---------------------------------------\n"
"Inter-Token Latency\n"
"---------------------------------------\n"
"Mean ITL (ms):                       49.43\n"
"Median ITL (ms):                     41.87\n"
"P99 ITL (ms):                        85.42\n"
"Max ITL (ms):                        672.12\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1026
msgid "<a id=\"ds-v32-atlas-800i-a3-p32-64k1k-30ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1026
msgid "<a id=\"ds-v32-atlas-800i-a3-p32-64k1k-30ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1028
msgid "Deepseek-V3.2 Atlas 800I A3-32Card PD Separation 64K-1K 30ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1032
msgid "Deploy Prefill Instance"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1034
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export LD_LIBRARY_PATH=/usr/local/Ascend/ascend-toolkit/latest/opp/vendors/"
"customize/op_api/lib/:${LD_LIBRARY_PATH}\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export ASCEND_HOME_PATH=/usr/local/Ascend/ascend-toolkit/latest\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"export HCCL_BUFFSIZE=1024\n"
"export DEEPEP_NORMAL_LONG_SEQ_ROUND=5\n"
"export DEEPEP_NORMAL_LONG_SEQ_PER_ROUND_TOKENS=512\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"export SGLANG_NPU_USE_MULTI_STREAM=1\n"
"export HCCL_OP_EXPANSION_MODE=AIV\n"
"\n"
"IPs=('your prefill ip1' 'your prefill ip2')\n"
"\n"
"# get IP in current node\n"
"LOCAL_HOST=`hostname -I|awk -F \" \" '{print$1}'`\n"
"echo \"LOCAL_HOST = \" ${LOCAL_HOST}\n"
"# get node index\n"
"for i in \"${!IPs[@]}\";\n"
"do\n"
"  echo \"LOCAL_HOST=${LOCAL_HOST}, IPs[${i}]=${IPs[$i]}\"\n"
"  if [ \"$LOCAL_HOST\" == \"${IPs[$i]}\" ]; then\n"
"      echo \"Node Rank : ${i}\"\n"
"      VC_TASK_INDEX=$i\n"
"      break\n"
"  fi\n"
"done\n"
"\n"
"IFNAMES=('xxx' 'xxx')\n"
"\n"
"export HCCL_SOCKET_IFNAME=${IFNAMES[$VC_TASK_INDEX]}\n"
"export GLOO_SOCKET_IFNAME=${HCCL_SOCKET_IFNAME}\n"
"echo \"HCCL_SOCKET_IFNAME : ${HCCL_SOCKET_IFNAME}\"\n"
"nnodes=${#IPs[@]}\n"
"tp_size=`expr 16 \\* ${nnodes}`\n"
"export ASCEND_MF_STORE_URL=tcp://${IPs[0]}:24667\n"
"\n"
"python3 -m sglang.launch_server --model-path ${MODEL_PATH} \\\n"
"--tp $tp_size \\\n"
"--trust-remote-code \\\n"
"--attention-backend ascend \\\n"
"--device npu \\\n"
"--watchdog-timeout 9000 \\\n"
"--host ${IPs[$VC_TASK_INDEX]} --port 8000 \\\n"
"--mem-fraction-static 0.73 \\\n"
"--disable-radix-cache --chunked-prefill-size -1 --max-prefill-tokens 68000 "
"\\\n"
"--max-running-requests 1 \\\n"
"--moe-a2a-backend deepep --deepep-mode normal \\\n"
"--quantization modelslim \\\n"
"--disaggregation-transfer-backend ascend \\\n"
"--disaggregation-mode prefill \\\n"
"--disable-cuda-graph \\\n"
"--nnodes $nnodes --node-rank $VC_TASK_INDEX \\\n"
"--disaggregation-bootstrap-port 8995 \\\n"
"--enable-nsa-prefill-context-parallel  --moe-dense-tp-size 1 \\\n"
"--speculative-algorithm NEXTN --speculative-num-steps 1 --speculative-eagle-"
"topk 1 --speculative-num-draft-tokens 2 \\\n"
"--dist-init-addr ${IPs[0]}:10000\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1115
msgid "Deploy Decode Instance"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1117
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export LD_LIBRARY_PATH=/usr/local/Ascend/ascend-toolkit/latest/opp/vendors/"
"customize/op_api/lib/:${LD_LIBRARY_PATH}\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"export ASCEND_HOME_PATH=/usr/local/Ascend/ascend-toolkit/latest\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_NPU_USE_MULTI_STREAM=1\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export HCCL_OP_EXPANSION_MODE=AIV\n"
"export SGLANG_SCHEDULER_SKIP_ALL_GATHER=1\n"
"export TASK_QUEUE_ENABLE=0\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"IPs=('your decode ip1' 'your decode ip2')\n"
"\n"
"export prefill_ip=your prefill ip1\n"
"# get IP in current node\n"
"LOCAL_HOST=`hostname -I|awk -F \" \" '{print$1}'`\n"
"echo \"LOCAL_HOST = \" ${LOCAL_HOST}\n"
"# get node index\n"
"for i in \"${!IPs[@]}\";\n"
"do\n"
"  echo \"LOCAL_HOST=${LOCAL_HOST}, IPs[${i}]=${IPs[$i]}\"\n"
"  if [ \"$LOCAL_HOST\" == \"${IPs[$i]}\" ]; then\n"
"      echo \"Node Rank : ${i}\"\n"
"      VC_TASK_INDEX=$i\n"
"      break\n"
"  fi\n"
"done\n"
"\n"
"IFNAMES=('xxx' 'xxx')\n"
"\n"
"export HCCL_SOCKET_IFNAME=${IFNAMES[$VC_TASK_INDEX]}\n"
"export GLOO_SOCKET_IFNAME=${HCCL_SOCKET_IFNAME}\n"
"nnodes=${#IPs[@]}\n"
"tp_size=`expr 16 \\* ${nnodes}`\n"
"export ASCEND_MF_STORE_URL=tcp://${prefill_ip}:24667\n"
"\n"
"CHUNKED_SIZE=65536\n"
"DP=8\n"
"export HCCL_BUFFSIZE=400\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=8\n"
"\n"
"python3 -m sglang.launch_server --model-path ${MODEL_PATH} \\\n"
"--tp $tp_size \\\n"
"--dp ${DP} \\\n"
"--ep $tp_size \\\n"
"--moe-dense-tp-size 1 \\\n"
"--enable-dp-attention \\\n"
"--enable-dp-lm-head \\\n"
"--trust-remote-code \\\n"
"--attention-backend ascend \\\n"
"--device npu \\\n"
"--watchdog-timeout 9000 \\\n"
"--host ${IPs[$VC_TASK_INDEX]} --port 8001 \\\n"
"--mem-fraction-static 0.79 \\\n"
"--disable-radix-cache \\\n"
"--chunked-prefill-size -1 --max-prefill-tokens 68000 \\\n"
"--max-running-requests 32 \\\n"
"--cuda-graph-max-bs 4 \\\n"
"--moe-a2a-backend deepep \\\n"
"--deepep-mode low_latency \\\n"
"--quantization modelslim \\\n"
"--speculative-algorithm NEXTN --speculative-num-steps 3 --speculative-eagle-"
"topk 1 --speculative-num-draft-tokens 4 \\\n"
"--disaggregation-transfer-backend ascend \\\n"
"--disaggregation-mode decode \\\n"
"--prefill-round-robin-balance \\\n"
"--load-balance-method round_robin \\\n"
"--nnodes $nnodes --node-rank $VC_TASK_INDEX \\\n"
"--dist-init-addr ${IPs[0]}:10000 --load-balance-method decode_round_robin\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1207
msgid ""
"export SGLANG_DP_ROUND_ROBIN=1\n"
"python -m sglang_router.launch_router \\\n"
"    --pd-disaggregation \\\n"
"    --policy cache_aware \\\n"
"    --prefill http://PIP1:8000 8998 \\\n"
"    --prefill http://PIP2:8000 8999 \\\n"
"    --decode http://DIP1:8001 \\\n"
"    --host 127.0.0.1 \\\n"
"    --port 6688 \\\n"
"    --mini-lb\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1222
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 6688 --max-concurrency 32  --random-input-len 64000 --"
"random-output-len 1000 --num-prompts 64 --random-range-ratio 1 --request-"
"rate 0.25\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1226
msgid ""
"========= Serving Benchmark Result =========\n"
"Backend: sglang\n"
"Traffic request rate: 0.25\n"
"Max request concurrency: 32\n"
"Successful requests: 64\n"
"Benchmark duration (s): 416.83\n"
"Total input tokens: 4096000\n"
"Total input text tokens: 4096000\n"
"Total generated tokens (retokenized): 196608\n"
"Total generated tokens (retokenized): 196530\n"
"Request throughput (req/s): 0.15\n"
"Input token throughput (tok/s): 98866.58\n"
"Output token throughput (tok/s): 471.68\n"
"Peak output token throughput (tok/s): 821.00\n"
"Peak concurrent requests: 33\n"
"Total token throughput (tok/s): 10298.25\n"
"Concurrency: 17.99\n"
"Accept length: 3.18\n"
"----------------- End-to-End Latency -----------------\n"
"Mean E2E Latency (ms): 117181.11\n"
"Median E2E Latency (ms): 100840.21\n"
"Mean TTFT (ms): 39313.10\n"
"Median TTFT (ms): 19198.87\n"
"P99 TTFT (ms): 153478.05\n"
"Mean Time per Output Token (excl. 1st token) (ms): 25.25\n"
"Mean TPOT (ms): 25.52\n"
"P99 TPOT (ms): 29.63\n"
"----------------- Inter-Token Latency -----------------\n"
"Mean ITL (ms): 25.36\n"
"Median ITL (ms): 20.47\n"
"P95 ITL (ms): 40.62\n"
"P99 ITL (ms): 54.63\n"
"Max ITL (ms): 248.81\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1262
msgid "<a id=\"qwen3-235b-atlas-800i-a3-p24-3.5k1.5k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1262
msgid "<a id=\"qwen3-235b-atlas-800i-a3-p24-3.5k1.5k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1264
msgid "Qwen3-235B Atlas 800I A3-24Card PD Separation 3.5K-1.5K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1268
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=16\n"
"\n"
"MODEL_PATH=xxx\n"
"export ASCEND_MF_STORE_URL=\"tcp://your prefill ip1:24667\"\n"
"P_IP=('your prefill ip1')\n"
"D_IP=('your decode ip1' 'your decode ip2')\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export SGLANG_DP_ROUND_ROBIN=1\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"\n"
"for i in \"${!P_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${P_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${P_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${P_IP[$i]}\"\n"
"        source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"        source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"        export DEEPEP_NORMAL_LONG_SEQ_PER_ROUND_TOKENS=1024\n"
"        export DEEPEP_NORMAL_LONG_SEQ_ROUND=16\n"
"        export HCCL_BUFFSIZE=4300\n"
"        export TASK_QUEUE_ENABLE=2\n"
"        export HCCL_SOCKET_IFNAME=lo\n"
"        export GLOO_SOCKET_IFNAME=lo\n"
"        export STREAMS_PER_DEVICE=32\n"
"        export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"\n"
"        # P\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode prefill \\\n"
"        --host ${P_IP[$i]} --port 8000 --disaggregation-bootstrap-port 8995 "
"--trust-remote-code \\\n"
"        --nnodes 1 --node-rank $i --tp-size 16 --dp-size 16 --mem-fraction-"
"static 0.6 \\\n"
"        --disable-radix-cache \\\n"
"        --ep-dispatch-algorithm static --init-expert-location /mnt/share/"
"chenxu/hot_map/expert_distribution_recorder_1765615213.9892833.pt \\\n"
"        --attention-backend ascend --device npu --quantization modelslim --"
"disaggregation-transfer-backend ascend \\\n"
"        --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx "
"\\\n"
"        --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-"
"num-draft-tokens 4 \\\n"
"        --speculative-draft-model-quantization unquant \\\n"
"        --max-running-requests 128 --chunked-prefill-size 262144 --max-"
"prefill-tokens 262144 \\\n"
"        --enable-dp-attention  \\\n"
"        --moe-a2a-backend deepep --deepep-mode normal --dtype bfloat16\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
"\n"
"for i in \"${!D_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${D_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${D_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${D_IP[$i]}\"\n"
"        source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"        source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"        export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=24\n"
"        export HCCL_BUFFSIZE=512\n"
"        export HCCL_SOCKET_IFNAME=data0.3001\n"
"        export GLOO_SOCKET_IFNAME=data0.3001\n"
"        export STREAMS_PER_DEVICE=32\n"
"\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode decode \\\n"
"        --host ${D_IP[$i]} --port 8001 --trust-remote-code \\\n"
"        --nnodes 2 --node-rank $i --tp-size 32 --dp-size 32 --mem-fraction-"
"static 0.83 --max-running-requests 768 \\\n"
"        --attention-backend ascend --device npu --quantization modelslim --"
"enable-dp-attention \\\n"
"        --moe-a2a-backend ascend_fuseep --cuda-graph-bs 6 8 12 15 18 20 22 "
"24 \\\n"
"        --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx "
"\\\n"
"        --speculative-draft-model-quantization unquant \\\n"
"        --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-"
"num-draft-tokens 4 \\\n"
"        --dist-init-addr xxx:5000 \\\n"
"        --disaggregation-transfer-backend ascend --watchdog-timeout 9000 --"
"context-length 8192 \\\n"
"        --prefill-round-robin-balance --enable-dp-lm-head --dtype bfloat16 --"
"tokenizer-worker-num 4 \\\n"
"        --load-balance-method decode_round_robin\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1369
#: ../../../platforms/ascend_npu_best_practice.md:2639
msgid ""
"export SGLANG_DP_ROUND_ROBIN=1\n"
"python -m sglang_router.launch_router \\\n"
"    --pd-disaggregation \\\n"
"    --policy cache_aware \\\n"
"    --prefill http://PIP:8000 8995 \\\n"
"    --decode http://DIP:8001 \\\n"
"    --host 127.0.0.1 \\\n"
"    --port 6688 \\\n"
"    --mini-lb\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1383
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7239 --max-concurrency 768 --random-input-len 3500 --random-"
"output-len 1500 --num-prompts 3072 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1387
msgid ""
"========= Serving Benchmark Result =========\n"
"Backend:                      sglang\n"
"Traffic request rate:         inf\n"
"Max request concurrency:      768\n"
"Successful requests:          3072\n"
"Benchmark duration (s):       410.76\n"
"Total input tokens:           10752000\n"
"Total input text tokens:      10752000\n"
"Total generated tokens (retokenized):  46080000\n"
"Request throughput (req/s):   7.48\n"
"Input token throughput (tok/s): 26176.11\n"
"Output token throughput (tok/s): 11218.33\n"
"Peak output token throughput (tok/s): 15636.00\n"
"Peak concurrent requests:     787\n"
"Total token throughput (tok/s): 37394.45\n"
"Concurrency:                  658.11\n"
"Accept length:                2.87\n"
"----------------- End-to-End Latency -----------------\n"
"Mean E2E Latency (ms):        87995.10\n"
"Median E2E Latency (ms):      80821.00\n"
"Time to First Token\n"
"Mean TTFT (ms):               26924.13\n"
"Median TTFT (ms):             19415.39\n"
"P99 TTFT (ms):                84458.36\n"
"--- Mean Time per Output Token (excl. 1st token) -----\n"
"Mean TPOT (ms):               40.74\n"
"Median TPOT (ms):             38.67\n"
"P99 TPOT (ms):                76.83\n"
"----------------- Inter-Token Latency -----------------\n"
"Mean ITL (ms):                40.75\n"
"Median ITL (ms):              33.99\n"
"P99 ITL (ms):                 87.67\n"
"Max ITL (ms):                 788.71\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1423
msgid "<a id=\"qwen3-235b-atlas-800i-a3-p8-3.5k1.5k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1423
msgid "<a id=\"qwen3-235b-atlas-800i-a3-p8-3.5k1.5k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1425
msgid "Qwen3-235B Atlas 800I A3-8Card PD Mixed 3.5K-1.5K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1429
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=1600\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export SGLANG_SCHEDULER_DECREASE_PREFILL_IDLE=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu --quantization modelslim  \\\n"
"    --max-running-requests 272 --context-length 8192 --dtype bfloat16 \\\n"
"    --chunked-prefill-size 32768 --max-prefill-tokens 32768 \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 \\\n"
"    --disable-radix-cache --moe-a2a-backend deepep  --deepep-mode auto --"
"speculative-draft-model-quantization unquant \\\n"
"    --tp 16 --dp-size 16 --enable-dp-attention --enable-dp-lm-head --mem-"
"fraction-static 0.8 --cuda-graph-bs 3 4 6 8 10 12 13 14 15 16 17\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1480
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7439 --max-concurrency 288 --random-input-len 3500 --random-"
"output-len 1500 --num-prompts 1088 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1484
msgid ""
"========= Serving Benchmark Result =========\n"
"Backend: sglang\n"
"Traffic request rate: inf\n"
"Max request concurrency: 272\n"
"Successful requests: 1088\n"
"Benchmark duration (s): 427.04\n"
"Total input tokens: 3808000\n"
"Total input text tokens: 0\n"
"Total input vision tokens: 0\n"
"Total generated tokens: 1632000\n"
"Total generated tokens (retokenized): 1631408\n"
"Request throughput (req/s): 2.55\n"
"Input token throughput (tok/s): 8917.16\n"
"Output token throughput (tok/s): 3821.64\n"
"Peak output token throughput (tok/s): 9304.00\n"
"Peak concurrent requests: 313\n"
"Total token throughput (tok/s): 12738.79\n"
"Concurrency: 239.32\n"
"Accept length: 2.83\n"
"=== End-to-End Latency ===\n"
"Mean E2E Latency (ms): 93931.66\n"
"Median E2E Latency (ms): 88251.02\n"
"=== Time to First Token ===\n"
"Mean TTFT (ms): 16721.52\n"
"Median TTFT (ms): 15137.02\n"
"P99 TTFT (ms): 42314.45\n"
"=== Time per Output Token (excl. 1st token) ===\n"
"Mean TPOT (ms): 51.51\n"
"Median TPOT (ms): 48.14\n"
"P99 TPOT (ms): 109.71\n"
"=== Inter-Token Latency ===\n"
"Mean ITL (ms): 51.51\n"
"Median ITL (ms): 25.60\n"
"P95 ITL (ms): 103.61\n"
"P99 ITL (ms): 461.44\n"
"Max ITL (ms): 35459.74\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1523
msgid "<a id=\"qwen3-235b-atlas-800i-a3-p8-2k2k-100ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1523
msgid "<a id=\"qwen3-235b-atlas-800i-a3-p8-2k2k-100ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1525
msgid "Qwen3-235B Atlas 800I A3-8Card PD Mixed 2K-2K 100ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1529
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=1200\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu --quantization modelslim  \\\n"
"    --max-running-requests 576 --context-length 8192 --dtype bfloat16 \\\n"
"    --chunked-prefill-size 32768 --max-prefill-tokens 458880  \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 \\\n"
"    --disable-radix-cache --moe-a2a-backend deepep  --deepep-mode auto --"
"speculative-draft-model-quantization unquant  \\\n"
"    --tp 16 --dp-size 16 --enable-dp-attention --enable-dp-lm-head --mem-"
"fraction-static 0.81 --cuda-graph-bs 8 16 20 24 32 36\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1579
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7439 --max-concurrency 576 --random-input-len 2000 --random-"
"output-len 2000 --num-prompts 576 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1583
msgid ""
"========= Serving Benchmark Result =========\n"
"Backend: sglang\n"
"Traffic request rate: inf\n"
"Max request concurrency: 576\n"
"Successful requests: 576\n"
"Benchmark duration (s): 182.26\n"
"Total input tokens: 1152000\n"
"Total input text tokens: 1152000\n"
"Total input vision tokens: 0\n"
"Total generated tokens: 1152000\n"
"Total generated tokens (retokenized): 1151728\n"
"Request throughput (req/s): 3.16\n"
"Input token throughput (tok/s): 6320.57\n"
"Output token throughput (tok/s): 6320.57\n"
"Peak output token throughput (tok/s): 14513.00\n"
"Peak concurrent requests: 576\n"
"Total token throughput (tok/s): 12641.14\n"
"Concurrency: 358.87\n"
"Accept length: 2.94\n"
"\n"
"--------End-to-End Latency--------\n"
"Mean E2E Latency (ms): 113557.20\n"
"Median E2E Latency (ms): 113056.54\n"
"\n"
"--------Time to First Token--------\n"
"Mean TTFT (ms): 4049.94\n"
"Median TTFT (ms): 4004.61\n"
"P99 TTFT (ms): 5926.98\n"
"\n"
"--------Time per Output Token (excl. 1st token)--------\n"
"Mean TPOT (ms): 54.78\n"
"Median TPOT (ms): 54.67\n"
"P99 TPOT (ms): 79.92\n"
"\n"
"--------Inter-Token Latency--------\n"
"Mean ITL (ms): 54.78\n"
"Median ITL (ms): 38.01\n"
"P95 ITL (ms): 82.41\n"
"P99 ITL (ms): 152.56\n"
"Max ITL (ms): 40909.44\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1626
msgid "<a id=\"qwen3-235b-atlas-800i-a3-p8-2k2k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1626
msgid "<a id=\"qwen3-235b-atlas-800i-a3-p8-2k2k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1628
msgid "Qwen3-235B Atlas 800I A3-8Card PD Mixed 2K-2K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1632
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=1600\n"
"export HCCL_SOCKET_IFNAME=xxx\n"
"export GLOO_SOCKET_IFNAME=xxx\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export SGLANG_SCHEDULER_DECREASE_PREFILL_IDLE=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu --quantization modelslim  \\\n"
"    --max-running-requests 480 --context-length 8192 --dtype bfloat16 \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 4096 --speculative-draft-"
"model-quantization unquant  \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 \\\n"
"    --disable-radix-cache --moe-a2a-backend deepep  --deepep-mode auto  \\\n"
"    --tp 16 --dp-size 16 --enable-dp-attention --enable-dp-lm-head --mem-"
"fraction-static 0.75 --cuda-graph-bs 6 8 10 12 15 18 28 30\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1683
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7439 --max-concurrency 480 --random-input-len 2048 --random-"
"output-len 2048 --num-prompts 480 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1687
msgid ""
"========= Serving Benchmark Result =========\n"
"Backend: sglang\n"
"Traffic request rate: inf\n"
"Max request concurrency: 480\n"
"Successful requests: 480\n"
"Benchmark duration (s): 166.51\n"
"Total input tokens: 983040\n"
"Total input text tokens: 983040\n"
"Total input vision tokens: 0\n"
"Total generated tokens: 982844\n"
"Total generated tokens (retokenized): 982844\n"
"Request throughput (req/s): 2.88\n"
"Input token throughput (tok/s): 5903.96\n"
"Output token throughput (tok/s): 5903.96\n"
"Peak output token throughput (tok/s): 13839.00\n"
"Peak concurrent requests: 480\n"
"Total token throughput (tok/s): 11807.92\n"
"Concurrency: 297.23\n"
"Accept length: 2.95\n"
"\n"
"---End-to-End Latency---\n"
"Mean E2E Latency (ms): 103105.60\n"
"Median E2E Latency (ms): 101298.94\n"
"Mean TTFT (ms): 4457.97\n"
"Median TTFT (ms): 4381.36\n"
"P99 TTFT (ms): 6589.31\n"
"Mean Time per Output Token (excl. 1st token): 48.19\n"
"Median TPOt (ms): 47.40\n"
"P99 TPOt (ms): 70.18\n"
"\n"
"---Inter-Token Latency---\n"
"Mean ITL (ms): 48.19\n"
"Median ITL (ms): 33.67\n"
"P99 ITL (ms): 76.04\n"
"Max ITL (ms): 33993.29\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1725
msgid "<a id=\"qwen3-235b-atlas-800i-a3-p16-2k2k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1725
msgid "<a id=\"qwen3-235b-atlas-800i-a3-p16-2k2k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1727
msgid "Qwen3-235B Atlas 800I A3-16Card PD Mixed 2K-2K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1731
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=16\n"
"\n"
"export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=1600\n"
"export HCCL_SOCKET_IFNAME=xxx\n"
"export GLOO_SOCKET_IFNAME=xxx\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"\n"
"MIX_IP=('IP1' 'IP2')\n"
"\n"
"for i in \"${!MIX_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${MIX_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${MIX_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${MIX_IP[$i]}\"+\n"
"        export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"        export SGLANG_ENABLE_SPEC_V2=1\n"
"        export SGLANG_SCHEDULER_DECREASE_PREFILL_IDLE=1\n"
"\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode decode \\\n"
"        --host 127.0.0.1 --port 7439 --trust-remote-code \\\n"
"        --nnodes 2 --node-rank $i --tp-size 32 --dp-size 32 --mem-fraction-"
"static 0.8 --max-running-requests 768 \\\n"
"        --attention-backend ascend --device npu --quantization modelslim --"
"enable-dp-attention \\\n"
"        --moe-a2a-backend ascend_fuseep --cuda-graph-bs 6 8 10 12 18 24 \\\n"
"        --dist-init-addr 141.61.105.131:5000 --chunked-prefill-size 32768 --"
"max-prefill-tokens 458880 \\\n"
"        --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx "
"\\\n"
"        --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-"
"num-draft-tokens 4 \\\n"
"        --disaggregation-transfer-backend ascend --watchdog-timeout 9000 --"
"context-length 8192 \\\n"
"        --prefill-round-robin-balance --enable-dp-lm-head --dtype bfloat16 --"
"tokenizer-worker-num 4\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1799
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7439 --max-concurrency 768 --random-input-len 2000 --random-"
"output-len 2000 --num-prompts 768 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1803
msgid ""
"Backend: sglang\n"
"Traffic request rate: inf\n"
"Max request concurrency: 768\n"
"Successful requests: 768\n"
"Benchmark duration (s): 199.18\n"
"Total input tokens: 1572864\n"
"Total input text tokens: 0\n"
"Total input vision tokens: 0\n"
"Total generated tokens (retokenized): 1572864\n"
"Request throughput (req/s): 4.06\n"
"Input token throughput (tok/s): 8314.05\n"
"Output token throughput (tok/s): 8314.05\n"
"Peak output token throughput (tok/s): 20655.00\n"
"Peak concurrent requests: 768\n"
"Total token throughput (tok/s): 16628.10\n"
"Concurrency: 529.54\n"
"Accept length: 3.20\n"
"\n"
"=== End-to-End Latency ===\n"
"Mean E2E Latency (ms): 130442.47\n"
"Median E2E Latency (ms): 127654.62\n"
"\n"
"=== Time to First Token ===\n"
"Mean TTFT (ms): 27838.48\n"
"Median TTFT (ms): 29338.37\n"
"P99 TTFT (ms): 48169.79\n"
"\n"
"=== Time per Output Token (excl. 1st token) ===\n"
"Mean TPOT (ms): 50.12\n"
"Median TPOT (ms): 49.54\n"
"P99 TPOT (ms): 72.80\n"
"\n"
"=== Inter-Token Latency ===\n"
"Mean ITL (ms): 50.12\n"
"Median ITL (ms): 30.66\n"
"P99 ITL (ms): 133.63\n"
"Max ITL (ms): 36393.04\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1843
msgid "<a id=\"qwen3-235b-atlas-800i-a3-p8-11k1k-10ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1843
msgid "<a id=\"qwen3-235b-atlas-800i-a3-p8-11k1k-10ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1845
msgid "Qwen3-235B Atlas 800I A3-8Card PD Mixed 11K-1K 10ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1849
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=1600\n"
"export HCCL_SOCKET_IFNAME=xxx\n"
"export GLOO_SOCKET_IFNAME=xxx\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu --quantization modelslim  \\\n"
"    --max-running-requests 1  --dtype bfloat16 \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 16384 --speculative-draft-"
"model-quantization unquant  \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 4 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 5 \\\n"
"    --disable-radix-cache --enable-dp-lm-head \\\n"
"    --tp 16 --mem-fraction-static 0.78 --cuda-graph-bs 1\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1900
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7439 --max-concurrency 1 --random-input-len 11000 --random-"
"output-len 1000 --num-prompts 1 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1904
msgid ""
"========= Serving Benchmark Result =========\n"
"Backend: sglang\n"
"Traffic request rate: inf\n"
"Max request concurrency: 1\n"
"Successful requests: 10690\n"
"Benchmark duration (s): 10.69\n"
"Total input tokens: 11000\n"
"Total input text tokens: 0\n"
"Total generated tokens: 1000\n"
"Total generated tokens (retokenized): 1000\n"
"Request throughput (req/s): 0.09\n"
"Input token throughput (tok/s): 1028.75\n"
"Output token throughput (tok/s): 93.52\n"
"Peak output token throughput (tok/s): 110.00\n"
"Peak concurrent requests: 1\n"
"Total token throughput (tok/s): 1122.27\n"
"Concurrency: 1.60\n"
"Accept length: 4.03\n"
"--- End-to-End Latency ---\n"
"Mean E2E Latency (ms): 10661.60\n"
"Median E2E Latency (ms): 10661.60\n"
"--- Time to First Token ---\n"
"Mean TTFT (ms): 973.98\n"
"Median TTFT (ms): 973.98\n"
"P99 TTFT (ms): 973.98\n"
"--- Time per Output Token (excl. 1st token) ---\n"
"Mean TPOT (ms): 9.70\n"
"Median TPOT (ms): 9.70\n"
"P99 TPOT (ms): 9.70\n"
"--- Inter-Token Latency ---\n"
"Mean ITL (ms): 9.70\n"
"Median ITL (ms): 9.28\n"
"P95 ITL (ms): 13.75\n"
"P99 ITL (ms): 14.99\n"
"Max ITL (ms): 19.83\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1942
msgid "<a id=\"qwen3-32b-atlas-800i-a3-p4-6k1.5k-18ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1942
msgid "<a id=\"qwen3-32b-atlas-800i-a3-p4-6k1.5k-18ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1944
msgid "Qwen3-32B Atlas 800I A3-4Card PD Mixed 6K-1.5K 18ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1948
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=xxx\n"
"export GLOO_SOCKET_IFNAME=xxx\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu  --quantization modelslim  \\\n"
"    --max-running-requests 32 \\\n"
"    --disable-radix-cache \\\n"
"    --chunked-prefill-size 32768 --max-prefill-tokens 65536 --speculative-"
"draft-model-quantization unquant \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 4 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 5 \\\n"
"    --tp-size 8 --mem-fraction-static 0.72 --cuda-graph-bs 8 16 24 32  --"
"dtype bfloat16\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1997
#: ../../../platforms/ascend_npu_best_practice.md:2296
#: ../../../platforms/ascend_npu_best_practice.md:2398
#: ../../../platforms/ascend_npu_best_practice.md:3042
#: ../../../platforms/ascend_npu_best_practice.md:3244
#: ../../../platforms/ascend_npu_best_practice.md:3343
msgid "We tested it based on the GSM8K dataset."
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:1999
#: ../../../platforms/ascend_npu_best_practice.md:3044
msgid ""
"python3 -m sglang.bench_serving --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 7439 --max-concurrency 32 --random-output-len 1500 --"
"random-input-len 6000 --num-prompts 32\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2003
msgid ""
"========= Serving Benchmark Result =========\n"
"Backend: sglang\n"
"Traffic request rate: inf\n"
"Max request concurrency: 32\n"
"Successful requests: 32\n"
"Benchmark duration (s): 38.48\n"
"Total input tokens: 199000\n"
"Total input text tokens: 192000\n"
"Total input vision tokens: 0\n"
"Total generated tokens (retokenized): 48000\n"
"Request throughput (req/s): 0.83\n"
"Input token throughput (tok/s): 4988.98\n"
"Output token throughput (tok/s): 1247.24\n"
"Peak output token throughput (tok/s): 2245.00\n"
"Peak concurrent requests: 32\n"
"Total token throughput (tok/s): 6236.22\n"
"Concurrency: 28.44\n"
"Accept length: 2.15\n"
"\n"
"=== End-to-End Latency ===\n"
"Mean E2E Latency (ms): 34202.32\n"
"Median E2E Latency (ms): 33902.93\n"
"\n"
"=== Time to First Token ===\n"
"Mean TTFT (ms): 8908.53\n"
"Median TTFT (ms): 8557.18\n"
"P99 TTFT (ms): 12373.42\n"
"\n"
"=== Time per Output Token (excl. 1st token) ===\n"
"Mean TPOT (ms): 16.87\n"
"Median TPOT (ms): 16.75\n"
"P99 TPOT (ms): 22.71\n"
"\n"
"=== Inter-Token Latency ===\n"
"Mean ITL (ms): 16.87\n"
"Median ITL (ms): 10.77\n"
"P95 ITL (ms): 32.01\n"
"P99 ITL (ms): 32.62\n"
"Max ITL (ms): 7912.53\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2045
msgid "<a id=\"qwen3-32b-atlas-800i-a3-p4-4k1.5k-11ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2045
msgid "<a id=\"qwen3-32b-atlas-800i-a3-p4-4k1.5k-11ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2047
msgid "Qwen3-32B Atlas 800I A3-4Card PD Mixed 4K-1.5K 11ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2051
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=xxx\n"
"export GLOO_SOCKET_IFNAME=xxx\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export DISABLE_EAGLE3_QUANT=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7339 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu   \\\n"
"    --max-running-requests 32 \\\n"
"    --disable-radix-cache \\\n"
"    --base-gpu-id 4 \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 4 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 5 \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 65536  \\\n"
"    --tp-size 8 --mem-fraction-static 0.72 --cuda-graph-bs 1 4 6 12 18 24 30 "
"32 --dtype bfloat1\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2101
msgid ""
"python3 -m sglang.bench_serving --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 7239 --random-range-ratio 1 -max-concurrency 1 --"
"random-output-len 1500 --random-input-len 4096 --num-prompts 4\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2105
msgid ""
"========= Serving Benchmark Result =========\n"
"Backend: sglang\n"
"Traffic request rate: inf\n"
"Max request concurrency: 1\n"
"Successful requests: 58.03\n"
"Benchmark duration (s): 16000\n"
"Total input tokens: 16000\n"
"Total input text tokens: 0\n"
"Total input vision tokens: 0\n"
"Total generated tokens (retokenized): 6000\n"
"Request throughput (req/s): 0.07\n"
"Input token throughput (tok/s): 275.74\n"
"Output token throughput (tok/s): 103.40\n"
"Peak output token throughput (tok/s): 132.00\n"
"Peak concurrent requests: 2\n"
"Total token throughput (tok/s): 379.14\n"
"Concurrency: 1.00\n"
"Accept length: 2.03\n"
"\n"
"---End-to-End Latency---\n"
"Mean E2E Latency (ms): 14502.58\n"
"Median E2E Latency (ms): 14752.39\n"
"\n"
"---Time to First Token---\n"
"Mean TTFT (ms): 317.68\n"
"Median TTFT (ms): 315.90\n"
"P99 TTFT (ms): 324.07\n"
"\n"
"---Time per Output Token (excl. 1st token)---\n"
"Mean TPOT (ms): 9.46\n"
"Median TPOT (ms): 9.63\n"
"P99 TPOT (ms): 10.87\n"
"\n"
"---Inter-Token Latency---\n"
"Mean ITL (ms): 9.46\n"
"Median ITL (ms): 6.64\n"
"P95 ITL (ms): 19.78\n"
"P99 ITL (ms): 20.73\n"
"Max ITL (ms): 33.84\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2147
msgid "<a id=\"qwen3-32b-atlas-800i-a3-p8-18k4k-12ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2147
msgid "<a id=\"qwen3-32b-atlas-800i-a3-p8-18k4k-12ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2149
msgid "Qwen3-32B Atlas 800I A3-8Card PD Mixed 18K-4K 12ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2153
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export DISABLE_EAGLE3_QUANT=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7339 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu   \\\n"
"    --max-running-requests 1 \\\n"
"    --disable-radix-cache \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 4 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 5 \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 65536  \\\n"
"    --tp-size 16 --mem-fraction-static 0.72 --cuda-graph-bs 1 --dtype "
"bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2201
msgid ""
"python3 -m sglang.bench_serving --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 7339 --random-range-ratio 1 --max-concurrency 1 --"
"random-output-len 18000 --random-input-len 4000 --num-prompts 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2205
msgid ""
"========= Serving Benchmark Result =========\n"
"Max request concurrency: 1\n"
"Successful requests: 1\n"
"Benchmark duration (s): 50.22\n"
"Total input tokens: 18000\n"
"Total input text tokens: 18000\n"
"Total input vision tokens: 0\n"
"Total generated tokens: 4000\n"
"Total generated tokens (retokenized): 4000\n"
"Request throughput (req/s): 0.02\n"
"Input token throughput (tok/s): 358.40\n"
"Output token throughput (tok/s): 79.64\n"
"Peak output token throughput (tok/s): 100.00\n"
"Peak concurrent requests: 1\n"
"Total token throughput (tok/s): 438.05\n"
"Concurrency: 1.00\n"
"Accept length: 2.15\n"
"----------------------------------------\n"
"---End-to-End Latency---\n"
"Mean E2E Latency (ms): 50204.39\n"
"Median E2E Latency (ms): 50204.39\n"
"---Time to First Token---\n"
"Mean TTFT (ms): 1132.62\n"
"Median TTFT (ms): 1132.62\n"
"P99 TTFT (ms): 1132.62\n"
"---Time per Output Token (excl. 1st token)---\n"
"Mean TPOT (ms): 12.27\n"
"Median TPOT (ms): 12.27\n"
"P99 TPOT (ms): 12.27\n"
"---Inter-Token Latency---\n"
"Mean ITL (ms): 12.27\n"
"Median ITL (ms): 7.52\n"
"P99 ITL (ms): 27.23\n"
"Max ITL (ms): 32.56\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2242
msgid "<a id=\"qwen3-32b-atlas-800i-a3-p2-3.5k1.5k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2242
msgid "<a id=\"qwen3-32b-atlas-800i-a3-p2-3.5k1.5k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2244
msgid "Qwen3-32B Atlas 800I A3-2Card PD Mixed 3.5K-1.5K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2248
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7239 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu  --quantization modelslim  \\\n"
"    --max-running-requests 78 \\\n"
"    --disable-radix-cache --speculative-draft-model-quantization unquant \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 65536  \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 \\\n"
"    --tp-size 4  --mem-fraction-static 0.72 --cuda-graph-bs 16 32 64 68 72 "
"78 --dtype bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2298
#: ../../../platforms/ascend_npu_best_practice.md:3246
msgid ""
"python3 -m sglang.bench_serving --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 7239 --max-concurrency 78 --random-output-len 1500 --"
"random-input-len 3500 --num-prompts 312\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2302
msgid ""
"Backend:                                   sglang\n"
"Traffic request rate:                      inf\n"
"Max request concurrency:                   78\n"
"Successful requests:                       312\n"
"Benchmark duration (s):                    330.60\n"
"Total input tokens:                        1092000\n"
"Total input text tokens:                   1092000\n"
"Total input vision tokens:                 0\n"
"Total generated tokens:                    468000\n"
"Total generated tokens (retokenized):      467994\n"
"Request throughput (req/s):                0.94\n"
"Input token throughput (tok/s):            3303.13\n"
"Output token throughput (tok/s):           1415.63\n"
"Peak output token throughput (tok/s):      2344.00\n"
"Peak concurrent requests:                  83\n"
"Peak token throughput (tok/s):             4718.76\n"
"Concurrency:                               74.73\n"
"Accept length:                             2.05\n"
"-------------------------------------------\n"
"Mean E2E Latency (ms):                     79188.24\n"
"Median E2E Latency (ms):                   78524.54\n"
"-------------------------------------------\n"
"Time to First Token\n"
"Mean TTFT (ms):                            5371.45\n"
"Median TTFT (ms):                          485.89\n"
"P99 TTFT (ms):                             24619.48\n"
"-------------------------------------------\n"
"Time per Output Token (excl. 1st token)\n"
"Mean TPOT (ms):                            49.24\n"
"Median TPOT (ms):                          49.50\n"
"P99 TPOT (ms):                             66.33\n"
"-------------------------------------------\n"
"Inter-Token Latency\n"
"Mean ITL (ms):                             49.24\n"
"Median ITL (ms):                           32.50\n"
"P95 ITL (ms):                              127.73\n"
"P99 ITL (ms):                              380.22\n"
"Max ITL (ms):                              12362.57\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2343
msgid "<a id=\"qwen3-32b-atlas-800i-a3-p2-2k2k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2343
msgid "<a id=\"qwen3-32b-atlas-800i-a3-p2-2k2k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2345
msgid "Qwen3-32B Atlas 800I A3-2Card PD Mixed 2K-2K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2349
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export DISABLE_EAGLE3_QUANT=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7239 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu  --quantization modelslim  \\\n"
"    --max-running-requests 120 \\\n"
"    --disable-radix-cache \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 49152 \\\n"
"    --tp-size 4 --mem-fraction-static 0.7 --cuda-graph-bs 54 60 66 72 78 84 "
"90 108 114 120 --dtype bfloat16\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2400
#: ../../../platforms/ascend_npu_best_practice.md:3345
msgid ""
"python3 -m sglang.bench_serving --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 7239 --max-concurrency 120 --random-output-len 2000 --"
"random-input-len 2000 --num-prompts 120\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2404
msgid ""
"Backend: sglang\n"
"Traffic request rate: inf\n"
"Max request concurrency: 120\n"
"Successful requests: 120\n"
"Benchmark duration (s): 121.69\n"
"Total input tokens: 240000\n"
"Total input text tokens: 240000\n"
"Total input vision tokens: 0\n"
"Total generated tokens: 240000\n"
"Total generated tokens (retokenized): 240000\n"
"Request throughput (req/s): 0.99\n"
"Input token throughput (tok/s): 1972.30\n"
"Output token throughput (tok/s): 1972.30\n"
"Peak output token throughput (tok/s): 2983.00\n"
"Peak concurrent requests: 120\n"
"Total token throughput (tok/s): 3944.60\n"
"Concurrency: 111.22\n"
"Accept length: 1.69\n"
"\n"
"---End-to-End Latency---\n"
"Mean E2E Latency (ms): 112785.77\n"
"Median E2E Latency (ms): 112758.61\n"
"\n"
"---Time to First Token---\n"
"Mean TTFT (ms): 16144.60\n"
"Median TTFT (ms): 17229.95\n"
"P99 TTFT (ms): 21366.64\n"
"\n"
"---Time per Output Token (excl. 1st token)---\n"
"Mean TPOT (ms): 48.34\n"
"Median TPOT (ms): 48.06\n"
"P99 TPOT (ms): 55.74\n"
"\n"
"---Inter-Token Latency---\n"
"Mean ITL (ms): 48.34\n"
"Median ITL (ms): 39.36\n"
"P99 ITL (ms): 81.71\n"
"Max ITL (ms): 12772.77\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2445
msgid "<a id=\"qwen3-30b-atlas-800i-a3-p1-3.5k1.5k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2445
msgid "<a id=\"qwen3-30b-atlas-800i-a3-p1-3.5k1.5k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2447
msgid "Qwen3-30B Atlas 800I A3-1Card PD Mixed 3.5K-1.5K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2451
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export DISABLE_EAGLE3_QUANT=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7239 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu  --quantization modelslim  \\\n"
"    --max-running-requests 192 \\\n"
"    --disable-radix-cache \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 32768 \\\n"
"    --tp-size 2 --mem-fraction-static 0.86 --cuda-graph-bs 42 88 96 132 144 "
"156 172 178 192 --dtype bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2499
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7239 --max-concurrency 156 --random-input-len 3500 --random-"
"output-len 1500 --num-prompts 624 --random-range-ratio 1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2503
msgid ""
"Backend: sglang\n"
"Traffic request rate: 1nf\n"
"Max request concurrency: 156\n"
"Successful requests: 624\n"
"Benchmark duration (s): 295.64\n"
"Total input tokens: 2184000\n"
"Total input text tokens: 0\n"
"Total input vision tokens: 0\n"
"Total generated tokens: 936000\n"
"Total generated tokens (retokenized): 935999\n"
"Request throughput (req/s): 2.11\n"
"Input token throughput (tok/s): 7387.40\n"
"Output token throughput (tok/s): 3166.03\n"
"Peak output token throughput (tok/s): 5631.00\n"
"Peak concurrent requests: 166\n"
"Total token throughput (tok/s): 10553.42\n"
"Concurrency: 148.81\n"
"Accept length: 3.17\n"
"\n"
"---End-to-End Latency---\n"
"Mean E2E Latency (ms): 70504.60\n"
"Median E2E Latency (ms): 70144.81\n"
"\n"
"---Time to First Token---\n"
"Mean TTFT (ms): 4020.19\n"
"Median TTFT (ms): 734.31\n"
"P99 TTFT (ms): 22554.77\n"
"\n"
"---Time per Output Token (excl. 1st token)---\n"
"Mean TPOT (ms): 44.35\n"
"Median TPOT (ms): 44.46\n"
"P99 TPOT (ms): 62.78\n"
"\n"
"---Inter-Token Latency---\n"
"Mean ITL (ms): 44.35\n"
"Median ITL (ms): 26.29\n"
"P99 ITL (ms): 118.72\n"
"P95 ITL (ms): 240.57\n"
"Max ITL (ms): 18382.51\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2545
msgid "<a id=\"qwen3-480b-atlas-800i-a3-p24-3.5k1.5k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2545
msgid "<a id=\"qwen3-480b-atlas-800i-a3-p24-3.5k1.5k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2547
msgid "Qwen3-480B Atlas 800I A3-24Card PD Separation 3.5K-1.5K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2551
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=16\n"
"\n"
"MODEL_PATH=xxx\n"
"export ASCEND_MF_STORE_URL=\"tcp://PIP:24667\"\n"
"P_IP=('PIP')\n"
"D_IP=('DIP1' 'DIP2')\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"\n"
"for i in \"${!P_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${P_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${P_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${P_IP[$i]}\"\n"
"        source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"        source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"        export DEEPEP_NORMAL_LONG_SEQ_PER_ROUND_TOKENS=1024\n"
"        export DEEPEP_NORMAL_LONG_SEQ_ROUND=16\n"
"        export HCCL_BUFFSIZE=4300\n"
"        export TASK_QUEUE_ENABLE=2\n"
"        export HCCL_SOCKET_IFNAME=lo\n"
"        export GLOO_SOCKET_IFNAME=lo\n"
"        export STREAMS_PER_DEVICE=32\n"
"        export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode prefill \\\n"
"        --host ${P_IP[$i]} --port 8000 --disaggregation-bootstrap-port 8995 "
"--trust-remote-code \\\n"
"        --nnodes 1 --node-rank $i --tp-size 16 --dp-size 2 --mem-fraction-"
"static 0.6 \\\n"
"        --disable-radix-cache \\\n"
"\t      --attention-backend ascend --device npu --quantization modelslim --"
"disaggregation-transfer-backend ascend \\\n"
"\t      --max-running-requests 128 --chunked-prefill-size 65536 --max-"
"prefill-tokens 262144 \\\n"
"        --enable-dp-attention  \\\n"
"        --moe-a2a-backend deepep --deepep-mode normal --dtype bfloat16\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
"for i in \"${!D_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${D_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${D_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${D_IP[$i]}\"\n"
"        source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"        source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"        export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=72\n"
"        export HCCL_BUFFSIZE=512\n"
"        export HCCL_SOCKET_IFNAME=xxx\n"
"        export GLOO_SOCKET_IFNAME=xxx\n"
"        export STREAMS_PER_DEVICE=32\n"
"\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode decode \\\n"
"        --host ${D_IP[$i]} --port 8001 --trust-remote-code \\\n"
"        --nnodes 2 --node-rank $i --tp-size 32 --dp-size 4 --mem-fraction-"
"static 0.73 --max-running-requests 384 \\\n"
"        --attention-backend ascend --device npu --quantization modelslim --"
"enable-dp-attention \\\n"
"        --moe-a2a-backend ascend_fuseep --cuda-graph-bs 16 32 48 56 64 72 80 "
"88 96 \\\n"
"        --dist-init-addr DIP1:5000 \\\n"
"\t      --disaggregation-transfer-backend ascend --watchdog-timeout 9000 --"
"context-length 8192 \\\n"
"        --prefill-round-robin-balance --enable-dp-lm-head --dtype bfloat16 --"
"tokenizer-worker-num 4 --load-balance-method decode_round_robin\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2653
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7239 --max-concurrency 410 --random-input-len 3500 --random-"
"output-len 1500 --num-prompts 1640 --random-range-ratio 1 --request-rate 8\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2657
msgid ""
"Backend: sglang\n"
"Traffic request rate: 8.0\n"
"Max request concurrency: 410\n"
"Successful requests: 1640\n"
"Benchmark duration (s): 384.95\n"
"Total input tokens: 5740000\n"
"Total input text tokens: 5740000\n"
"Total input vision tokens: 0\n"
"Total generated tokens: 2460000\n"
"Total generated tokens (retokenized): 2449627\n"
"Request throughput (req/s): 4.26\n"
"Output token throughput (tok/s): 14911.21\n"
"Peak output token throughput (tok/s): 6390.52\n"
"Peak concurrent requests: 429\n"
"Total token throughput (tok/s): 21301.73\n"
"Concurrency: 327.33\n"
"\n"
"---End-to-End Latency---\n"
"Mean E2E Latency (ms): 76831.52\n"
"Median E2E Latency (ms): 77111.46\n"
"\n"
"---Time to First Token---\n"
"Mean TTFT (ms): 4470.95\n"
"Median TTFT (ms): 3432.63\n"
"P99 TTFT (ms): 17805.87\n"
"\n"
"---Time per Output Token (excl. 1st token)---\n"
"Mean TPOT (ms): 48.27\n"
"Median TPOT (ms): 49.12\n"
"P99 TPOT (ms): 50.17\n"
"\n"
"---Inter-Token Latency---\n"
"Mean ITL (ms): 48.27\n"
"Median ITL (ms): 45.43\n"
"P99 ITL (ms): 128.57\n"
"Max ITL (ms): 728.88\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2696
msgid "<a id=\"qwen3-480b-atlas-800i-a3-p16-3.5k1.5k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2696
msgid "<a id=\"qwen3-480b-atlas-800i-a3-p16-3.5k1.5k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2698
msgid "Qwen3-480B Atlas 800I A3-16Card PD Mixed 3.5K-1.5K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2702
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=16\n"
"\n"
"export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=1800\n"
"export HCCL_SOCKET_IFNAME=xxx\n"
"export GLOO_SOCKET_IFNAME=xxx\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"\n"
"MIX_IP=('IP1' 'IP2')\n"
"\n"
"for i in \"${!MIX_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${MIX_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${MIX_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${MIX_IP[$i]}\"\n"
"\n"
"        python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"        --host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 2 --node-"
"rank $i  \\\n"
"        --dist-init-addr 141.61.133.128:5000 \\\n"
"        --attention-backend ascend --device npu --quantization modelslim  "
"\\\n"
"        --max-running-requests 288 --context-length 8192 --dtype bfloat16  "
"\\\n"
"        --chunked-prefill-size 114688 --max-prefill-tokens 458880  \\\n"
"        --disable-radix-cache --moe-a2a-backend deepep  --deepep-mode auto  "
"\\\n"
"        --tp 32 --dp-size 4 --enable-dp-attention --enable-dp-lm-head --mem-"
"fraction-static 0.7 --cuda-graph-bs 56 64 72\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2763
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7439 --max-concurrency 288 --random-input-len 3500 --random-"
"output-len 1500 --num-prompts 1152 --random-range-ratio 1 --request-rate 20\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2767
msgid ""
"Backend: sglang\n"
"Traffic request rate: 20.0\n"
"Max request concurrency: 288\n"
"Successful requests: 1152\n"
"Benchmark duration (s): 372.58\n"
"Total input tokens: 4032000\n"
"Total input text tokens: 4932000\n"
"Total input vision tokens: 0\n"
"Total generated tokens: 1728000\n"
"Total generated tokens (retokenized): 1723296\n"
"Request throughput (req/s): 3.09\n"
"Input token throughput (tok/s): 10821.87\n"
"Output token throughput (tok/s): 4637.95\n"
"Peak output token throughput (tok/s): 6912.00\n"
"Peak concurrent requests: 408\n"
"Total token throughput (tok/s): 15459.82\n"
"Concurrency: 281.13\n"
"End-to-End Latency\n"
"Mean E2E Latency (ms): 90923.48\n"
"Median E2E Latency (ms): 92344.71\n"
"Time to First Token\n"
"Mean TTFT (ms): 15466.24\n"
"Median TTFT (ms): 14426.93\n"
"P99 TTFT (ms): 26498.92\n"
"Time per Output Token (excl. 1st token)\n"
"Mean TPOT (ms): 50.34\n"
"Median TPOT (ms): 49.91\n"
"P99 TPOT (ms): 59.31\n"
"Inter-Token Latency\n"
"Mean ITL (ms): 50.34\n"
"Median ITL (ms): 42.35\n"
"P95 ITL (ms): 90.51\n"
"P99 ITL (ms): 389.41\n"
"Max ITL (ms): 24730.36\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2804
msgid "<a id=\"qwen3-480b-atlas-800i-a3-p8-3.5k1.5k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2804
msgid "<a id=\"qwen3-480b-atlas-800i-a3-p8-3.5k1.5k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2806
msgid "Qwen3-480B Atlas 800I A3-8Card PD Mixed 3.5K-1.5K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2810
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=2100\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"--host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 1 --node-rank 0  "
"\\\n"
"--attention-backend ascend --device npu --quantization modelslim  \\\n"
"--max-running-requests 80 --context-length 8192 --dtype bfloat16 \\\n"
"--chunked-prefill-size 28672 --max-prefill-tokens 458880  \\\n"
"--disable-radix-cache --moe-a2a-backend deepep  --deepep-mode auto --enable-"
"dp-attention --enable-dp-lm-head \\\n"
"--tp 16 --dp-size 4 --mem-fraction-static 0.7 --cuda-graph-bs  16 20\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2856
msgid ""
"python -m sglang.bench_serving --dataset-name random --backend sglang --host "
"127.0.0.1 --port 7439 --max-concurrency 80 --random-input-len 3500 --random-"
"output-len 1500 --num-prompts 320 --random-range-ratio 1 --request-rate 8\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2860
msgid ""
"Backend: sglang\n"
"Traffic request rate: 8.0\n"
"Max request concurrency: 80\n"
"Successful requests: 320\n"
"Benchmark duration (s): 319.89\n"
"Total input tokens: 1120000\n"
"Total input text tokens: 1120000\n"
"Total input vision tokens: 0\n"
"Total generated tokens (retokenized): 477727\n"
"Request throughput (req/s): 1.00\n"
"Output token throughput (tok/s): 3501.16\n"
"Input token throughput (tok/s): 1500.50\n"
"Peak output token throughput (tok/s): 1840.00\n"
"Peak concurrent requests: 160\n"
"Total token throughput (tok/s): 5001.66\n"
"Concurrency: 78.91\n"
"----------------- End-to-End Latency -----------------\n"
"Mean E2E Latency (ms): 78883.93\n"
"Median E2E Latency (ms): 79526.23\n"
"----------------- Time to First Token -----------------\n"
"Mean TTFT (ms): 6627.14\n"
"Median TTFT (ms): 6103.91\n"
"P99 TTFT (ms): 11953.96\n"
"Mean TPTOT (ms): 48.20\n"
"Median TPTOT (ms): 48.10\n"
"P99 TPTOT (ms): 52.33\n"
"----------------- Inter-Token Latency -----------------\n"
"Mean ITL (ms): 48.20\n"
"Median ITL (ms): 45.16\n"
"P99 ITL (ms): 51.04\n"
"P99 ITL (ms): 55.76\n"
"Max ITL (ms): 16869.36\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2895
msgid "<a id=\"qwen3-next-atlas-800i-a3-p2-3.5k1.5k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2895
msgid "<a id=\"qwen3-next-atlas-800i-a3-p2-3.5k1.5k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2897
msgid "Qwen3-Next Atlas 800I A3-2Card PD Mixed 3.5K-1.5K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2901
msgid ""
"export cann_path=/usr/local/Ascend/ascend-toolkit/latest\n"
"source /usr/local/Ascend/driver/bin/setenv.bash\n"
"source ${cann_path}/../set_env.sh\n"
"source ${cann_path}/../../nnal/atb/set_env.sh\n"
"source ${cann_path}/opp/vendors/customize/bin/set_env.bash\n"
"export ASCEND_HOME_PATH=${cann_path}\n"
"source /usr/local/Ascend/8.5.0/bisheng_toolkit/set_env.sh\n"
"\n"
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"\n"
"export HCCL_OP_EXPANSION_MODE=AIV\n"
"export HCCL_ALGO=\"level0:NA;level1:ring\"\n"
"\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=20\n"
"export HCCL_BUFFSIZE=2000\n"
"\n"
"python -m sglang.launch_server \\\n"
"        --model-path /mnt/share/weight/Qwen3-Next-80B-A3B-Instruct-W8A8-3 "
"\\\n"
"        --host 127.0.0.1 \\\n"
"        --port 6699 \\\n"
"        --tp-size 4 \\\n"
"        --attention-backend ascend \\\n"
"        --mem-fraction-static 0.685 \\\n"
"        --max-running-requests 80 \\\n"
"        --watchdog-timeout 3600 \\\n"
"        --disable-radix-cache \\\n"
"        --cuda-graph-bs 80 \\\n"
"        --max-prefill-tokens 28672  --max-total-tokens 450560 \\\n"
"        --moe-a2a-backend deepep --deepep-mode auto \\\n"
"        --quantization modelslim \\\n"
"        --chunked-prefill-size -1\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2947
msgid ""
"python3 -m sglang.bench_serving --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 6699 --max-concurrency 80 --random-output-len 1536 --"
"random-input-len 3584 --num-prompts 160\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2951
msgid ""
"==================== Serving Benchmark Result ====================\n"
"Backend: sglang\n"
"Traffic request rate: inf\n"
"Max request concurrency: 80\n"
"Successful requests: 160\n"
"Benchmark duration (s): 174.90\n"
"Total input tokens: 573440\n"
"Total input text tokens: 573440\n"
"Total input vision tokens: 0\n"
"Total generated tokens: 245760\n"
"Total generated tokens (retokenized): 245760\n"
"Request throughput (req/s): 0.91\n"
"Input token throughput (tok/s): 3278.74\n"
"Output token throughput (tok/s): 1405.17\n"
"Peak output token throughput (tok/s): 1840.00\n"
"Peak concurrent requests: 160\n"
"Total token throughput (tok/s): 4683.91\n"
"Concurrency: 79.87\n"
"------------------- End-to-End Latency -------------------\n"
"Mean E2E Latency (ms): 87303.49\n"
"Median E2E Latency (ms): 87283.35\n"
"------------------- Time to First Token -------------------\n"
"Mean TTFT (ms): 10688.91\n"
"Median TTFT (ms): 10365.16\n"
"P99 TTFT (ms): 19285.56\n"
"------------------- Time per Output Token (excl. 1st token) "
"-------------------\n"
"Mean TPOT (ms): 49.91\n"
"Median TPOT (ms): 49.93\n"
"P99 TPOT (ms): 55.63\n"
"------------------- Inter-Token Latency -------------------\n"
"Mean ITL (ms): 49.91\n"
"Median ITL (ms): 44.75\n"
"P95 ITL (ms): 45.54\n"
"P99 ITL (ms): 46.08\n"
"Max ITL (ms): 17803.50\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2989
msgid "<a id=\"qwen3-32b-atlas-800i-a2-p8-6k1.5k-18ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2989
msgid "<a id=\"qwen3-32b-atlas-800i-a2-p8-6k1.5k-18ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2991
msgid "Qwen3-32B Atlas 800I A2-8Card PD Mixed 6K-1.5K 18ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:2995
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7439 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu  --quantization modelslim  \\\n"
"    --max-running-requests 32 \\\n"
"    --disable-radix-cache \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 135168  --speculative-"
"draft-model-quantization unquant \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 4 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 5 \\\n"
"    --tp-size 8 --mem-fraction-static 0.72 --cuda-graph-bs 1 4 8 16 24 28 "
"32  --dtype bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3048
msgid ""
"-------- Serving Benchmark Result --------\n"
"Backend:                          sglang\n"
"Traffic request rate:             inf\n"
"Max request concurrency:          32\n"
"Successful requests:              32\n"
"Benchmark duration (s):           40.52\n"
"Total input tokens:               192000\n"
"Total input text tokens:          192000\n"
"Total input vision tokens:        0\n"
"Total generated tokens:           48000\n"
"Total generated tokens (retokenized): 47984\n"
"Request throughput (req/s):       0.79\n"
"Input token throughput (tok/s):   4738.46\n"
"Output token throughput (tok/s):  1184.62\n"
"Peak output token throughput (tok/s): 2045.00\n"
"Peak concurrent requests:         32\n"
"Total token throughput (tok/s):   5923.08\n"
"Concurrency:                      28.60\n"
"Accept length:                    2.11\n"
"\n"
"-------- End-to-End Latency --------\n"
"Mean E2E Latency (ms):            36214.23\n"
"Median E2E Latency (ms):          36358.20\n"
"\n"
"-------- Time to First Token --------\n"
"Mean TTFT (ms):                   11544.97\n"
"Median TTFT (ms):                 11587.54\n"
"P99 TTFT (ms):                    11879.45\n"
"\n"
"-------- Time per Output Token (excl. 1st token) --------\n"
"Mean TPOT (ms):                   16.46\n"
"Median TPOT (ms):                 16.50\n"
"P99 TPOT (ms):                    21.34\n"
"\n"
"-------- Inter-Token Latency --------\n"
"Mean ITL (ms):                    16.46\n"
"Median ITL (ms):                  11.75\n"
"P95 ITL (ms):                     34.80\n"
"P99 ITL (ms):                     35.88\n"
"Max ITL (ms):                     1991.03\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3091
msgid "<a id=\"qwen3-32b-atlas-800i-a2-p8-4k1.5k-11ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3091
msgid "<a id=\"qwen3-32b-atlas-800i-a2-p8-4k1.5k-11ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3093
msgid "Qwen3-32B Atlas 800I A2-8Card PD Mixed 4K-1.5K 11ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3097
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"#export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export DISABLE_EAGLE3_QUANT=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7339 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu   \\\n"
"    --max-running-requests 32 \\\n"
"    --disable-radix-cache \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx  \\\n"
"    --speculative-num-steps 4 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 5 \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 65536  \\\n"
"    --tp-size 8 --mem-fraction-static 0.72 --cuda-graph-bs 1 4 6 12 18 24 30 "
"32 --dtype bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3148
msgid ""
"python3 -m sglang.bench_serving  --dataset-name random --backend sglang --"
"host 127.0.0.1 --port 7339 --random-range-ratio 1 --max-concurrency 1 --"
"random-output-len 1500 --random-input-len 4096 --num-prompts 4\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3152
msgid ""
"========== Serving Benchmark Result ==========\n"
"Backend: sglang\n"
"Traffic request rate: inf\n"
"Max request concurrency: 1\n"
"Successful requests: 4\n"
"Benchmark duration (s): 62.33\n"
"Total input tokens: 16000\n"
"Total input text tokens: 16000\n"
"Total input vision tokens: 0\n"
"Total generated tokens: 6000\n"
"Total generated tokens (retokenized): 6000\n"
"Request throughput (req/s): 0.06\n"
"Input token throughput (tok/s): 256.71\n"
"Output token throughput (tok/s): 96.26\n"
"Peak output token throughput (tok/s): 124.00\n"
"Peak concurrent requests: 2\n"
"Total token throughput (tok/s): 352.97\n"
"Concurrency: 1.00\n"
"Accept length: 2.04\n"
"---------- End-to-End Latency ----------\n"
"Mean E2E Latency (ms): 15577.88\n"
"Median E2E Latency (ms): 15965.08\n"
"---------- Time to First Token ----------\n"
"Mean TTFT (ms): 312.47\n"
"Median TTFT (ms): 312.07\n"
"P99 TTFT (ms): 317.13\n"
"---------- Time per Output Token (excl. 1st token) ----------\n"
"Mean TPOT (ms): 10.18\n"
"Median TPOT (ms): 10.44\n"
"P99 TPOT (ms): 11.51\n"
"---------- Inter-Token Latency ----------\n"
"Mean ITL (ms): 10.18\n"
"Median ITL (ms): 7.07\n"
"P95 ITL (ms): 21.00\n"
"Max ITL (ms): 27.61\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3190
msgid "<a id=\"qwen3-32b-atlas-800i-a2-p8-3.5k1.5k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3190
msgid "<a id=\"qwen3-32b-atlas-800i-a2-p8-3.5k1.5k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3192
msgid "Qwen3-32B Atlas 800I A2-8Card PD Mixed 3.5K-1.5K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3196
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7239 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu  --quantization modelslim  \\\n"
"    --max-running-requests 78 \\\n"
"    --disable-radix-cache --speculative-draft-model-quantization unquant \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 65536  \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 \\\n"
"    --tp-size 4  --mem-fraction-static 0.72 --cuda-graph-bs 1 4 8 16 32 64 "
"68 72 78 --dtype bfloat16 --base-gpu-id 4\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3250
msgid ""
"========== Serving Benchmark Result ==========\n"
"Backend:                              sglang\n"
"Traffic request rate:                 inf\n"
"Max request concurrency:              78\n"
"Successful requests:                  312\n"
"Benchmark duration (s):               335.40\n"
"Total input tokens:                   1092000\n"
"Total input text tokens:              1092000\n"
"Total input vision tokens:            0\n"
"Total generated tokens:               468000\n"
"Total generated tokens (retokenized): 467916\n"
"Request throughput (req/s):           0.93\n"
"Input token throughput (tok/s):       3255.77\n"
"Output token throughput (tok/s):      1395.33\n"
"Peak output token throughput (tok/s): 2417.00\n"
"Peak concurrent requests:             84\n"
"Total token throughput (tok/s):       4651.10\n"
"Concurrency:                          73.66\n"
"Accept length:                        2.05\n"
"---------- End-to-End Latency ----------\n"
"Mean E2E Latency (ms):                79186.66\n"
"Median E2E Latency (ms):              78608.81\n"
"---------- Time to First Token ----------\n"
"Mean TTFT (ms):                       5786.98\n"
"Median TTFT (ms):                     645.64\n"
"P99 TTFT (ms):                        26569.53\n"
"---------- Time per Output Token (excl. 1st token) ----------\n"
"Mean TPOT (ms):                       48.97\n"
"Median TPOT (ms):                     49.06\n"
"P99 TPOT (ms):                        67.17\n"
"---------- Inter-Token Latency ----------\n"
"Mean ITL (ms):                        48.97\n"
"Median ITL (ms):                      33.00\n"
"P95 ITL (ms):                         131.60\n"
"P99 ITL (ms):                         391.27\n"
"Max ITL (ms):                         13391.14\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3289
msgid "<a id=\"qwen3-32b-atlas-800i-a2-p8-2k2k-50ms\"></a>"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3289
msgid "<a id=\"qwen3-32b-atlas-800i-a2-p8-2k2k-50ms\">"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3291
msgid "Qwen3-32B Atlas 800I A2-8Card PD Mixed 2K-2K 50ms"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3295
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset https_proxy\n"
"unset http_proxy\n"
"unset HTTPS_PROXY\n"
"unset HTTP_PROXY\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"source /usr/local/Ascend/ascend-toolkit/latest/opp/vendors/customize/bin/"
"set_env.bash\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT=600\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"\n"
"export HCCL_BUFFSIZE=400\n"
"export HCCL_SOCKET_IFNAME=lo\n"
"export GLOO_SOCKET_IFNAME=lo\n"
"export HCCL_OP_EXPANSION_MODE=\"AIV\"\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export DISABLE_EAGLE3_QUANT=1\n"
"\n"
"python -m sglang.launch_server --model-path $MODEL_PATH \\\n"
"    --host 127.0.0.1 --port 7239 --trust-remote-code --nnodes 1 --node-rank "
"0  \\\n"
"    --attention-backend ascend --device npu  --quantization modelslim  \\\n"
"    --max-running-requests 120 \\\n"
"    --disable-radix-cache \\\n"
"    --speculative-algorithm EAGLE3 --speculative-draft-model-path xxx \\\n"
"    --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-"
"draft-tokens 4 --speculative-draft-model-quantization unquant \\\n"
"    --chunked-prefill-size -1 --max-prefill-tokens 49152 --base-gpu-id 4 \\\n"
"    --tp-size 4 --mem-fraction-static 0.7 --cuda-graph-bs 54 60 66 72 78 84 "
"90 108 114 120 --dtype bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_best_practice.md:3349
msgid ""
"========== Serving Benchmark Result ==========\n"
"Backend:                         sglang\n"
"Traffic request rate:            inf\n"
"Max request concurrency:         120\n"
"Successful requests:             120\n"
"Benchmark duration (s):          117.18\n"
"Total input tokens:              2400000\n"
"Total input text tokens:         240000\n"
"Total input vision tokens:       0\n"
"Total generated tokens:          2400000\n"
"Total generated tokens (retokenized): 239960\n"
"Request throughput (req/s):      1.02\n"
"Input token throughput (tok/s):  2048.10\n"
"Output token throughput (tok/s): 2048.10\n"
"Peak output token throughput (tok/s): 3133.00\n"
"Peak concurrent requests:        120\n"
"Total token throughput (tok/s):  4096.20\n"
"Concurrency:                     111.43\n"
"Accept length:                   1.69\n"
"---------- End-to-End Latency ----------\n"
"Mean E2E Latency (ms):           108815.31\n"
"Median E2E Latency (ms):         108737.30\n"
"---------- Time to First Token ----------\n"
"Mean TTFT (ms):                  17096.53\n"
"Median TTFT (ms):                18159.44\n"
"P99 TTFT (ms):                   22681.91\n"
"---------- Time per Output Token (excl. 1st token) ----------\n"
"Mean TPOT (ms):                  45.88\n"
"Median TPOT (ms):                45.71\n"
"P99 TPOT (ms):                   53.49\n"
"---------- Inter-Token Latency ----------\n"
"Mean ITL (ms):                   45.88\n"
"Median ITL (ms):                 37.46\n"
"P95 ITL (ms):                    77.55\n"
"P99 ITL (ms):                    81.31\n"
"Max ITL (ms):                    13530.47\n"
msgstr ""
