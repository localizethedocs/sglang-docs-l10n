# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2026, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang 0.5\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-02-10 09:10+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../supported_models/diffusion_models.md:1
msgid "Diffusion Models"
msgstr ""

#: ../../../supported_models/diffusion_models.md:3
msgid ""
"SGLang Diffusion is an inference framework for accelerated image and video "
"generation using diffusion models. It provides an end-to-end unified "
"pipeline with optimized kernels from sgl-kernel and an efficient scheduler "
"loop."
msgstr ""

#: ../../../supported_models/diffusion_models.md:5
msgid "Key Features"
msgstr ""

#: ../../../supported_models/diffusion_models.md:7
msgid ""
"**Broad Model Support**: Wan series, FastWan series, Hunyuan, Qwen-Image, "
"Qwen-Image-Edit, Flux, Z-Image, GLM-Image, and more"
msgstr ""

#: ../../../supported_models/diffusion_models.md:8
msgid ""
"**Fast Inference**: Optimized kernels from sgl-kernel, efficient scheduler "
"loop, and Cache-DiT acceleration"
msgstr ""

#: ../../../supported_models/diffusion_models.md:9
msgid "**Ease of Use**: OpenAI-compatible API, CLI, and Python SDK"
msgstr ""

#: ../../../supported_models/diffusion_models.md:10
msgid ""
"**Multi-Platform**: NVIDIA GPUs (H100, H200, A100, B200, 4090) and AMD GPUs "
"(MI300X, MI325X)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:14
msgid "Install SGLang-diffusion"
msgstr ""

#: ../../../supported_models/diffusion_models.md:16
msgid "You can install sglang-diffusion using one of the methods below."
msgstr ""

#: ../../../supported_models/diffusion_models.md:18
msgid ""
"This page primarily applies to common NVIDIA GPU platforms. For AMD Instinct/"
"ROCm environments see the dedicated [ROCm quickstart](#rocm-quickstart-for-"
"sgl-diffusion), which lists the exact steps (including kernel builds) we "
"used to validate sgl-diffusion on MI300X."
msgstr ""

#: ../../../supported_models/diffusion_models.md:20
msgid "Method 1: With pip or uv"
msgstr ""

#: ../../../supported_models/diffusion_models.md:22
msgid "It is recommended to use uv for a faster installation:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:24
msgid ""
"pip install --upgrade pip\n"
"pip install uv\n"
"uv pip install \"sglang[diffusion]\" --prerelease=allow\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:30
msgid "Method 2: From source"
msgstr ""

#: ../../../supported_models/diffusion_models.md:32
msgid ""
"# Use the latest release branch\n"
"git clone https://github.com/sgl-project/sglang.git\n"
"cd sglang\n"
"\n"
"# Install the Python packages\n"
"pip install --upgrade pip\n"
"pip install -e \"python[diffusion]\"\n"
"\n"
"# With uv\n"
"uv pip install -e \"python[diffusion]\" --prerelease=allow\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:45
msgid "Method 3: Using Docker"
msgstr ""

#: ../../../supported_models/diffusion_models.md:47
msgid ""
"The Docker images are available on Docker Hub at [lmsysorg/sglang](https://"
"hub.docker.com/r/lmsysorg/sglang), built from the [Dockerfile](https://"
"github.com/sgl-project/sglang/blob/main/docker/Dockerfile). Replace "
"`<secret>` below with your HuggingFace Hub [token](https://huggingface.co/"
"docs/hub/en/security-tokens)."
msgstr ""

#: ../../../supported_models/diffusion_models.md:50
msgid ""
"docker run --gpus all \\\n"
"    --shm-size 32g \\\n"
"    -p 30000:30000 \\\n"
"    -v ~/.cache/huggingface:/root/.cache/huggingface \\\n"
"    --env \"HF_TOKEN=<secret>\" \\\n"
"    --ipc=host \\\n"
"    lmsysorg/sglang:dev \\\n"
"    sglang generate --model-path black-forest-labs/FLUX.1-dev \\\n"
"    --prompt \"A logo With Bold Large text: SGL Diffusion\" \\\n"
"    --save-output\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:65
msgid "ROCm quickstart for sgl-diffusion"
msgstr ""

#: ../../../supported_models/diffusion_models.md:67
msgid ""
"docker run --device=/dev/kfd --device=/dev/dri --ipc=host \\\n"
"  -v ~/.cache/huggingface:/root/.cache/huggingface \\\n"
"  --env HF_TOKEN=<secret> \\\n"
"  lmsysorg/sglang:v0.5.5.post2-rocm700-mi30x \\\n"
"  sglang generate --model-path black-forest-labs/FLUX.1-dev --prompt \"A "
"logo With Bold Large text: SGL Diffusion\" --save-output\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:77
msgid "Compatibility Matrix"
msgstr ""

#: ../../../supported_models/diffusion_models.md:79
msgid ""
"The table below shows every supported model and the optimizations supported "
"for them."
msgstr ""

#: ../../../supported_models/diffusion_models.md:81
msgid "The symbols used have the following meanings:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:83
msgid "✅ = Full compatibility"
msgstr ""

#: ../../../supported_models/diffusion_models.md:84
msgid "❌ = No compatibility"
msgstr ""

#: ../../../supported_models/diffusion_models.md:85
msgid "⭕ = Does not apply to this model"
msgstr ""

#: ../../../supported_models/diffusion_models.md:87
msgid "Models x Optimization"
msgstr ""

#: ../../../supported_models/diffusion_models.md:89
msgid ""
"The `HuggingFace Model ID` can be passed directly to `from_pretrained()` "
"methods, and sglang-diffusion will use the optimal default parameters when "
"initializing and generating videos."
msgstr ""

#: ../../../supported_models/diffusion_models.md:93
msgid "Video Generation Models"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Model Name"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Hugging Face Model ID"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Resolutions"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "TeaCache"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Sliding Tile Attn"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Sage Attn"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Video Sparse Attention (VSA)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "FastWan2.1 T2V 1.3B"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`FastVideo/FastWan2.1-T2V-1.3B-Diffusers`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "480p"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "⭕"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "✅"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "FastWan2.2 TI2V 5B Full Attn"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`FastVideo/FastWan2.2-TI2V-5B-FullAttn-Diffusers`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "720p"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Wan2.2 TI2V 5B"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`Wan-AI/Wan2.2-TI2V-5B-Diffusers`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Wan2.2 T2V A14B"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`Wan-AI/Wan2.2-T2V-A14B-Diffusers`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "480p<br>720p"
msgstr ""

#: ../../../supported_models/diffusion_models.md:100
#: ../../../supported_models/diffusion_models.md:101
#: ../../../supported_models/diffusion_models.md:102
#: ../../../supported_models/diffusion_models.md:103
#: ../../../supported_models/diffusion_models.md:137
#: ../../../supported_models/diffusion_models.md:139
#: ../../../supported_models/diffusion_models.md:140
#: ../../../supported_models/diffusion_models.md:141
#: ../../../supported_models/diffusion_models.md:142
msgid "<br>"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "❌"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Wan2.2 I2V A14B"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`Wan-AI/Wan2.2-I2V-A14B-Diffusers`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "HunyuanVideo"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`hunyuanvideo-community/HunyuanVideo`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "720×1280<br>544×960"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "FastHunyuan"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`FastVideo/FastHunyuan-diffusers`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Wan2.1 T2V 1.3B"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`Wan-AI/Wan2.1-T2V-1.3B-Diffusers`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Wan2.1 T2V 14B"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`Wan-AI/Wan2.1-T2V-14B-Diffusers`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "480p, 720p"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Wan2.1 I2V 480P"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`Wan-AI/Wan2.1-I2V-14B-480P-Diffusers`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Wan2.1 I2V 720P"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`Wan-AI/Wan2.1-I2V-14B-720P-Diffusers`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:109
msgid ""
"**Note**: Wan2.2 TI2V 5B has some quality issues when performing I2V "
"generation. We are working on fixing this issue."
msgstr ""

#: ../../../supported_models/diffusion_models.md:111
msgid "Image Generation Models"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "HuggingFace Model ID"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "FLUX.1-dev"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`black-forest-labs/FLUX.1-dev`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Any resolution"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "FLUX.2-dev"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`black-forest-labs/FLUX.2-dev`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "FLUX.2-Klein"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`black-forest-labs/FLUX.2-klein-4B`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Z-Image-Turbo"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`Tongyi-MAI/Z-Image-Turbo`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "GLM-Image"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`zai-org/GLM-Image`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Qwen Image"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`Qwen/Qwen-Image`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Qwen Image 2512"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`Qwen/Qwen-Image-2512`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Qwen Image Edit"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`Qwen/Qwen-Image-Edit`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:124
msgid "Verified LoRA Examples"
msgstr ""

#: ../../../supported_models/diffusion_models.md:126
msgid ""
"This section lists example LoRAs that have been explicitly tested and "
"verified with each base model in the **SGLang Diffusion** pipeline."
msgstr ""

#: ../../../supported_models/diffusion_models.md:128
msgid ""
"Important: LoRAs that are not listed here are not necessarily incompatible. "
"In practice, most standard LoRAs are expected to work, especially those "
"following common Diffusers or SD-style conventions. The entries below simply "
"reflect configurations that have been manually validated by the SGLang team."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "<br />\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "\\\\\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:133
msgid "Verified LoRAs by Base Model"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Base Model"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Supported LoRAs"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Wan2.2"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid ""
"`lightx2v/Wan2.2-Distill-Loras`<br>`Cseti/wan2.2-14B-Arcane_Jinx-lora-v1`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Wan2.1"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`lightx2v/Wan2.1-Distill-Loras`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid ""
"`tarn59/pixel_art_style_lora_z_image_turbo`<br>`wcde/Z-Image-Turbo-DeJPEG-"
"Lora`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Qwen-Image"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid ""
"`lightx2v/Qwen-Image-Lightning`<br>`flymy-ai/qwen-image-realism-"
"lora`<br>`prithivMLmods/Qwen-Image-HeadshotX`<br>`starsfriday/Qwen-Image-EVA-"
"LoRA`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Qwen-Image-Edit"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid ""
"`ostris/qwen_image_edit_inpainting`<br>`lightx2v/Qwen-Image-Edit-2511-"
"Lightning`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Flux"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid ""
"`dvyio/flux-lora-simple-illustration`<br>`XLabs-AI/flux-furry-"
"lora`<br>`XLabs-AI/flux-RealismLora`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:144
msgid "Special Requirements"
msgstr ""

#: ../../../supported_models/diffusion_models.md:146
msgid ""
"[!NOTE] Sliding Tile Attention: Currently, only Hopper GPUs (H100s) are "
"supported."
msgstr ""

#: ../../../supported_models/diffusion_models.md:152
msgid "SGLang diffusion CLI Inference"
msgstr ""

#: ../../../supported_models/diffusion_models.md:154
msgid ""
"The SGLang-diffusion CLI provides a quick way to access the inference "
"pipeline for image and video generation."
msgstr ""

#: ../../../supported_models/diffusion_models.md:156
msgid "Prerequisites"
msgstr ""

#: ../../../supported_models/diffusion_models.md:158
msgid ""
"A working SGLang diffusion installation and the `sglang` CLI available in "
"`$PATH`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:159
msgid "Python 3.11+ if you plan to use the OpenAI Python SDK."
msgstr ""

#: ../../../supported_models/diffusion_models.md:162
msgid "Supported Arguments"
msgstr ""

#: ../../../supported_models/diffusion_models.md:164
msgid "Server Arguments"
msgstr ""

#: ../../../supported_models/diffusion_models.md:166
msgid "`--model-path {MODEL_PATH}`: Path to the model or model ID"
msgstr ""

#: ../../../supported_models/diffusion_models.md:167
msgid ""
"`--vae-path {VAE_PATH}`: Path to a custom VAE model or HuggingFace model ID "
"(e.g., `fal/FLUX.2-Tiny-AutoEncoder`). If not specified, the VAE will be "
"loaded from the main model path."
msgstr ""

#: ../../../supported_models/diffusion_models.md:168
msgid ""
"`--lora-path {LORA_PATH}`: Path to a LoRA adapter (local path or HuggingFace "
"model ID). If not specified, LoRA will not be applied."
msgstr ""

#: ../../../supported_models/diffusion_models.md:169
msgid ""
"`--lora-nickname {NAME}`: Nickname for the LoRA adapter. (default: "
"`default`)."
msgstr ""

#: ../../../supported_models/diffusion_models.md:170
msgid "`--num-gpus {NUM_GPUS}`: Number of GPUs to use"
msgstr ""

#: ../../../supported_models/diffusion_models.md:171
msgid ""
"`--tp-size {TP_SIZE}`: Tensor parallelism size (only for the encoder; should "
"not be larger than 1 if text encoder offload is enabled, as layer-wise "
"offload plus prefetch is faster)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:172
msgid ""
"`--sp-degree {SP_SIZE}`: Sequence parallelism size (typically should match "
"the number of GPUs)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:173
msgid ""
"`--ulysses-degree {ULYSSES_DEGREE}`: The degree of DeepSpeed-Ulysses-style "
"SP in USP"
msgstr ""

#: ../../../supported_models/diffusion_models.md:174
msgid ""
"`--ring-degree {RING_DEGREE}`: The degree of ring attention-style SP in USP"
msgstr ""

#: ../../../supported_models/diffusion_models.md:177
msgid "Sampling Parameters"
msgstr ""

#: ../../../supported_models/diffusion_models.md:179
msgid ""
"`--prompt {PROMPT}`: Text description for the video you want to generate"
msgstr ""

#: ../../../supported_models/diffusion_models.md:180
msgid "`--num-inference-steps {STEPS}`: Number of denoising steps"
msgstr ""

#: ../../../supported_models/diffusion_models.md:181
msgid ""
"`--negative-prompt {PROMPT}`: Negative prompt to guide generation away from "
"certain concepts"
msgstr ""

#: ../../../supported_models/diffusion_models.md:182
msgid "`--seed {SEED}`: Random seed for reproducible generation"
msgstr ""

#: ../../../supported_models/diffusion_models.md:185
msgid "Image/Video Configuration"
msgstr ""

#: ../../../supported_models/diffusion_models.md:187
msgid "`--height {HEIGHT}`: Height of the generated output"
msgstr ""

#: ../../../supported_models/diffusion_models.md:188
msgid "`--width {WIDTH}`: Width of the generated output"
msgstr ""

#: ../../../supported_models/diffusion_models.md:189
msgid "`--num-frames {NUM_FRAMES}`: Number of frames to generate"
msgstr ""

#: ../../../supported_models/diffusion_models.md:190
msgid ""
"`--fps {FPS}`: Frames per second for the saved output, if this is a video-"
"generation task"
msgstr ""

#: ../../../supported_models/diffusion_models.md:193
msgid "Output Options"
msgstr ""

#: ../../../supported_models/diffusion_models.md:195
msgid "`--output-path {PATH}`: Directory to save the generated video"
msgstr ""

#: ../../../supported_models/diffusion_models.md:196
msgid "`--save-output`: Whether to save the image/video to disk"
msgstr ""

#: ../../../supported_models/diffusion_models.md:197
msgid "`--return-frames`: Whether to return the raw frames"
msgstr ""

#: ../../../supported_models/diffusion_models.md:199
msgid "Using Configuration Files"
msgstr ""

#: ../../../supported_models/diffusion_models.md:201
msgid ""
"Instead of specifying all parameters on the command line, you can use a "
"configuration file:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:203
msgid "sglang generate --config {CONFIG_FILE_PATH}\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:207
msgid ""
"The configuration file should be in JSON or YAML format with the same "
"parameter names as the CLI options. Command-line arguments take precedence "
"over settings in the configuration file, allowing you to override specific "
"values while keeping the rest from the configuration file."
msgstr ""

#: ../../../supported_models/diffusion_models.md:209
msgid "Example configuration file (config.json):"
msgstr ""

#: ../../../supported_models/diffusion_models.md:211
msgid ""
"{\n"
"    \"model_path\": \"FastVideo/FastHunyuan-diffusers\",\n"
"    \"prompt\": \"A beautiful woman in a red dress walking down a street\",\n"
"    \"output_path\": \"outputs/\",\n"
"    \"num_gpus\": 2,\n"
"    \"sp_size\": 2,\n"
"    \"tp_size\": 1,\n"
"    \"num_frames\": 45,\n"
"    \"height\": 720,\n"
"    \"width\": 1280,\n"
"    \"num_inference_steps\": 6,\n"
"    \"seed\": 1024,\n"
"    \"fps\": 24,\n"
"    \"precision\": \"bf16\",\n"
"    \"vae_precision\": \"fp16\",\n"
"    \"vae_tiling\": true,\n"
"    \"vae_sp\": true,\n"
"    \"vae_config\": {\n"
"        \"load_encoder\": false,\n"
"        \"load_decoder\": true,\n"
"        \"tile_sample_min_height\": 256,\n"
"        \"tile_sample_min_width\": 256\n"
"    },\n"
"    \"text_encoder_precisions\": [\n"
"        \"fp16\",\n"
"        \"fp16\"\n"
"    ],\n"
"    \"mask_strategy_file_path\": null,\n"
"    \"enable_torch_compile\": false\n"
"}\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:244
msgid "Or using YAML format (config.yaml):"
msgstr ""

#: ../../../supported_models/diffusion_models.md:246
msgid ""
"model_path: \"FastVideo/FastHunyuan-diffusers\"\n"
"prompt: \"A beautiful woman in a red dress walking down a street\"\n"
"output_path: \"outputs/\"\n"
"num_gpus: 2\n"
"sp_size: 2\n"
"tp_size: 1\n"
"num_frames: 45\n"
"height: 720\n"
"width: 1280\n"
"num_inference_steps: 6\n"
"seed: 1024\n"
"fps: 24\n"
"precision: \"bf16\"\n"
"vae_precision: \"fp16\"\n"
"vae_tiling: true\n"
"vae_sp: true\n"
"vae_config:\n"
"  load_encoder: false\n"
"  load_decoder: true\n"
"  tile_sample_min_height: 256\n"
"  tile_sample_min_width: 256\n"
"text_encoder_precisions:\n"
"  - \"fp16\"\n"
"  - \"fp16\"\n"
"mask_strategy_file_path: null\n"
"enable_torch_compile: false\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:276
msgid "To see all the options, you can use the `--help` flag:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:278
msgid "sglang generate --help\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:282
#: ../../../supported_models/diffusion_models.md:403
msgid "Serve"
msgstr ""

#: ../../../supported_models/diffusion_models.md:284
msgid ""
"Launch the SGLang diffusion HTTP server and interact with it using the "
"OpenAI SDK and curl."
msgstr ""

#: ../../../supported_models/diffusion_models.md:286
#: ../../../supported_models/diffusion_models.md:407
msgid "Start the server"
msgstr ""

#: ../../../supported_models/diffusion_models.md:288
msgid "Use the following command to launch the server:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:290
msgid ""
"SERVER_ARGS=(\n"
"  --model-path Wan-AI/Wan2.1-T2V-1.3B-Diffusers\n"
"  --text-encoder-cpu-offload\n"
"  --pin-cpu-memory\n"
"  --num-gpus 4\n"
"  --ulysses-degree=2\n"
"  --ring-degree=2\n"
")\n"
"\n"
"sglang serve \"${SERVER_ARGS[@]}\"\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:303
msgid ""
"**--model-path**: Which model to load. The example uses `Wan-AI/Wan2.1-"
"T2V-1.3B-Diffusers`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:304
msgid "**--port**: HTTP port to listen on (the default here is `30010`)."
msgstr ""

#: ../../../supported_models/diffusion_models.md:306
msgid ""
"For detailed API usage, including Image, Video Generation and LoRA "
"management, please refer to the [OpenAI API Documentation](#sglang-diffusion-"
"openai-api)."
msgstr ""

#: ../../../supported_models/diffusion_models.md:309
msgid "Generate"
msgstr ""

#: ../../../supported_models/diffusion_models.md:311
msgid "Run a one-off generation task without launching a persistent server."
msgstr ""

#: ../../../supported_models/diffusion_models.md:313
msgid ""
"To use it, pass both server arguments and sampling parameters in one "
"command, after the `generate` subcommand, for example:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:315
msgid ""
"SERVER_ARGS=(\n"
"  --model-path Wan-AI/Wan2.2-T2V-A14B-Diffusers\n"
"  --text-encoder-cpu-offload\n"
"  --pin-cpu-memory\n"
"  --num-gpus 4\n"
"  --ulysses-degree=2\n"
"  --ring-degree=2\n"
")\n"
"\n"
"SAMPLING_ARGS=(\n"
"  --prompt \"A curious raccoon\"\n"
"  --save-output\n"
"  --output-path outputs\n"
"  --output-file-name \"A curious raccoon.mp4\"\n"
")\n"
"\n"
"sglang generate \"${SERVER_ARGS[@]}\" \"${SAMPLING_ARGS[@]}\"\n"
"\n"
"# Or, users can set `SGLANG_CACHE_DIT_ENABLED` env as `true` to enable cache "
"acceleration\n"
"SGLANG_CACHE_DIT_ENABLED=true sglang generate \"${SERVER_ARGS[@]}\" "
"\"${SAMPLING_ARGS[@]}\"\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:338
msgid ""
"Once the generation task has finished, the server will shut down "
"automatically."
msgstr ""

#: ../../../supported_models/diffusion_models.md:340
msgid ""
"[!NOTE] The HTTP server-related arguments are ignored in this subcommand."
msgstr ""

#: ../../../supported_models/diffusion_models.md:343
msgid "Diffusers Backend"
msgstr ""

#: ../../../supported_models/diffusion_models.md:345
msgid ""
"SGLang diffusion supports a **diffusers backend** that allows you to run any "
"diffusers-compatible model through SGLang's infrastructure using vanilla "
"diffusers pipelines. This is useful for running models without native SGLang "
"implementations or models with custom pipeline classes."
msgstr ""

#: ../../../supported_models/diffusion_models.md:347
msgid "Arguments"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Argument"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Values"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Description"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`--backend`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`auto` (default), `sglang`, `diffusers`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid ""
"`auto`: prefer native SGLang, fallback to diffusers. `sglang`: force native "
"(fails if unavailable). `diffusers`: force vanilla diffusers pipeline."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`--diffusers-attention-backend`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`flash`, `_flash_3_hub`, `sage`, `xformers`, `native`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid ""
"Attention backend for diffusers pipelines. See [diffusers attention backends]"
"(https://huggingface.co/docs/diffusers/main/en/optimization/"
"attention_backends)."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`--trust-remote-code`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "flag"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Required for models with custom pipeline classes (e.g., Ovis)."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`--vae-tiling`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Enable VAE tiling for large image support (decodes tile-by-tile)."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`--vae-slicing`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Enable VAE slicing for lower memory usage (decodes slice-by-slice)."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`--dit-precision`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`fp16`, `bf16`, `fp32`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Precision for the diffusion transformer."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`--vae-precision`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Precision for the VAE."
msgstr ""

#: ../../../supported_models/diffusion_models.md:359
msgid "Example: Running Ovis-Image-7B"
msgstr ""

#: ../../../supported_models/diffusion_models.md:361
msgid ""
"[Ovis-Image-7B](https://huggingface.co/AIDC-AI/Ovis-Image-7B) is a 7B text-"
"to-image model optimized for high-quality text rendering."
msgstr ""

#: ../../../supported_models/diffusion_models.md:363
msgid ""
"sglang generate \\\n"
"  --model-path AIDC-AI/Ovis-Image-7B \\\n"
"  --backend diffusers \\\n"
"  --trust-remote-code \\\n"
"  --diffusers-attention-backend flash \\\n"
"  --prompt \"A serene Japanese garden with cherry blossoms\" \\\n"
"  --height 1024 \\\n"
"  --width 1024 \\\n"
"  --num-inference-steps 30 \\\n"
"  --save-output \\\n"
"  --output-path outputs \\\n"
"  --output-file-name ovis_garden.png\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:378
msgid "Extra Diffusers Arguments"
msgstr ""

#: ../../../supported_models/diffusion_models.md:380
msgid ""
"For pipeline-specific parameters not exposed via CLI, use `diffusers_kwargs` "
"in a config file:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:382
msgid ""
"{\n"
"    \"model_path\": \"AIDC-AI/Ovis-Image-7B\",\n"
"    \"backend\": \"diffusers\",\n"
"    \"prompt\": \"A beautiful landscape\",\n"
"    \"diffusers_kwargs\": {\n"
"        \"cross_attention_kwargs\": {\"scale\": 0.5}\n"
"    }\n"
"}\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:393
msgid "sglang generate --config config.json\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:399
msgid "SGLang Diffusion OpenAI API"
msgstr ""

#: ../../../supported_models/diffusion_models.md:401
msgid ""
"The SGLang diffusion HTTP server implements an OpenAI-compatible API for "
"image and video generation, as well as LoRA adapter management."
msgstr ""

#: ../../../supported_models/diffusion_models.md:405
msgid "Launch the server using the `sglang serve` command."
msgstr ""

#: ../../../supported_models/diffusion_models.md:409
msgid ""
"SERVER_ARGS=(\n"
"  --model-path Wan-AI/Wan2.1-T2V-1.3B-Diffusers\n"
"  --text-encoder-cpu-offload\n"
"  --pin-cpu-memory\n"
"  --num-gpus 4\n"
"  --ulysses-degree=2\n"
"  --ring-degree=2\n"
"  --port 30010\n"
")\n"
"\n"
"sglang serve \"${SERVER_ARGS[@]}\"\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:423
msgid "**--model-path**: Path to the model or model ID."
msgstr ""

#: ../../../supported_models/diffusion_models.md:424
msgid "**--port**: HTTP port to listen on (default: `30000`)."
msgstr ""

#: ../../../supported_models/diffusion_models.md:426
msgid "Get Model Information"
msgstr ""

#: ../../../supported_models/diffusion_models.md:428
msgid "**Endpoint:** `GET /models`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:430
msgid ""
"Returns information about the model served by this server, including model "
"path, task type, pipeline configuration, and precision settings."
msgstr ""

#: ../../../supported_models/diffusion_models.md:432
#: ../../../supported_models/diffusion_models.md:484
#: ../../../supported_models/diffusion_models.md:537
#: ../../../supported_models/diffusion_models.md:567
#: ../../../supported_models/diffusion_models.md:591
#: ../../../supported_models/diffusion_models.md:621
#: ../../../supported_models/diffusion_models.md:715
#: ../../../supported_models/diffusion_models.md:730
#: ../../../supported_models/diffusion_models.md:743
msgid "**Curl Example:**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:434
msgid "curl -sS -X GET \"http://localhost:30010/models\"\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:438
#: ../../../supported_models/diffusion_models.md:749
msgid "**Response Example:**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:440
msgid ""
"{\n"
"  \"model_path\": \"Wan-AI/Wan2.1-T2V-1.3B-Diffusers\",\n"
"  \"task_type\": \"T2V\",\n"
"  \"pipeline_name\": \"wan_pipeline\",\n"
"  \"pipeline_class\": \"WanPipeline\",\n"
"  \"num_gpus\": 4,\n"
"  \"dit_precision\": \"bf16\",\n"
"  \"vae_precision\": \"fp16\"\n"
"}\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:454
msgid "Endpoints"
msgstr ""

#: ../../../supported_models/diffusion_models.md:456
msgid "Image Generation"
msgstr ""

#: ../../../supported_models/diffusion_models.md:458
msgid ""
"The server implements an OpenAI-compatible Images API under the `/v1/images` "
"namespace."
msgstr ""

#: ../../../supported_models/diffusion_models.md:460
msgid "Create an image"
msgstr ""

#: ../../../supported_models/diffusion_models.md:462
msgid "**Endpoint:** `POST /v1/images/generations`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:464
msgid "**Python Example (b64_json response):**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:466
msgid ""
"import base64\n"
"from openai import OpenAI\n"
"\n"
"client = OpenAI(api_key=\"sk-proj-1234567890\", base_url=\"http://"
"localhost:30010/v1\")\n"
"\n"
"img = client.images.generate(\n"
"    prompt=\"A calico cat playing a piano on stage\",\n"
"    size=\"1024x1024\",\n"
"    n=1,\n"
"    response_format=\"b64_json\",\n"
")\n"
"\n"
"image_bytes = base64.b64decode(img.data[0].b64_json)\n"
"with open(\"output.png\", \"wb\") as f:\n"
"    f.write(image_bytes)\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:486
msgid ""
"curl -sS -X POST \"http://localhost:30010/v1/images/generations\" \\\n"
"  -H \"Content-Type: application/json\" \\\n"
"  -H \"Authorization: Bearer sk-proj-1234567890\" \\\n"
"  -d '{\n"
"        \"prompt\": \"A calico cat playing a piano on stage\",\n"
"        \"size\": \"1024x1024\",\n"
"        \"n\": 1,\n"
"        \"response_format\": \"b64_json\"\n"
"      }'\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:498
msgid ""
"**Note** The `response_format=url` option is not supported for `POST /v1/"
"images/generations` and will return a `400` error."
msgstr ""

#: ../../../supported_models/diffusion_models.md:501
msgid "Edit an image"
msgstr ""

#: ../../../supported_models/diffusion_models.md:503
msgid "**Endpoint:** `POST /v1/images/edits`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:505
msgid ""
"This endpoint accepts a multipart form upload with input images and a text "
"prompt. The server can return either a base64-encoded image or a URL to "
"download the image."
msgstr ""

#: ../../../supported_models/diffusion_models.md:507
msgid "**Curl Example (b64_json response):**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:509
msgid ""
"curl -sS -X POST \"http://localhost:30010/v1/images/edits\" \\\n"
"  -H \"Authorization: Bearer sk-proj-1234567890\" \\\n"
"  -F \"image=@local_input_image.png\" \\\n"
"  -F \"url=image_url.jpg\" \\\n"
"  -F \"prompt=A calico cat playing a piano on stage\" \\\n"
"  -F \"size=1024x1024\" \\\n"
"  -F \"response_format=b64_json\"\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:519
msgid "**Curl Example (URL response):**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:521
msgid ""
"curl -sS -X POST \"http://localhost:30010/v1/images/edits\" \\\n"
"  -H \"Authorization: Bearer sk-proj-1234567890\" \\\n"
"  -F \"image=@local_input_image.png\" \\\n"
"  -F \"url=image_url.jpg\" \\\n"
"  -F \"prompt=A calico cat playing a piano on stage\" \\\n"
"  -F \"size=1024x1024\" \\\n"
"  -F \"response_format=url\"\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:531
msgid "Download image content"
msgstr ""

#: ../../../supported_models/diffusion_models.md:533
msgid ""
"When `response_format=url` is used with `POST /v1/images/edits`, the API "
"returns a relative URL like `/v1/images/<IMAGE_ID>/content`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:535
msgid "**Endpoint:** `GET /v1/images/{image_id}/content`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:539
msgid ""
"curl -sS -L \"http://localhost:30010/v1/images/<IMAGE_ID>/content\" \\\n"
"  -H \"Authorization: Bearer sk-proj-1234567890\" \\\n"
"  -o output.png\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:545
msgid "Video Generation"
msgstr ""

#: ../../../supported_models/diffusion_models.md:547
msgid ""
"The server implements a subset of the OpenAI Videos API under the `/v1/"
"videos` namespace."
msgstr ""

#: ../../../supported_models/diffusion_models.md:549
msgid "Create a video"
msgstr ""

#: ../../../supported_models/diffusion_models.md:551
msgid "**Endpoint:** `POST /v1/videos`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:553
#: ../../../supported_models/diffusion_models.md:583
#: ../../../supported_models/diffusion_models.md:602
msgid "**Python Example:**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:555
msgid ""
"from openai import OpenAI\n"
"\n"
"client = OpenAI(api_key=\"sk-proj-1234567890\", base_url=\"http://"
"localhost:30010/v1\")\n"
"\n"
"video = client.videos.create(\n"
"    prompt=\"A calico cat playing a piano on stage\",\n"
"    size=\"1280x720\"\n"
")\n"
"print(f\"Video ID: {video.id}, Status: {video.status}\")\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:569
msgid ""
"curl -sS -X POST \"http://localhost:30010/v1/videos\" \\\n"
"  -H \"Content-Type: application/json\" \\\n"
"  -H \"Authorization: Bearer sk-proj-1234567890\" \\\n"
"  -d '{\n"
"        \"prompt\": \"A calico cat playing a piano on stage\",\n"
"        \"size\": \"1280x720\"\n"
"      }'\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:579
msgid "List videos"
msgstr ""

#: ../../../supported_models/diffusion_models.md:581
msgid "**Endpoint:** `GET /v1/videos`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:585
msgid ""
"videos = client.videos.list()\n"
"for item in videos.data:\n"
"    print(item.id, item.status)\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:593
msgid ""
"curl -sS -X GET \"http://localhost:30010/v1/videos\" \\\n"
"  -H \"Authorization: Bearer sk-proj-1234567890\"\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:598
msgid "Download video content"
msgstr ""

#: ../../../supported_models/diffusion_models.md:600
msgid "**Endpoint:** `GET /v1/videos/{video_id}/content`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:604
msgid ""
"import time\n"
"\n"
"# Poll for completion\n"
"while True:\n"
"    page = client.videos.list()\n"
"    item = next((v for v in page.data if v.id == video_id), None)\n"
"    if item and item.status == \"completed\":\n"
"        break\n"
"    time.sleep(5)\n"
"\n"
"# Download content\n"
"resp = client.videos.download_content(video_id=video_id)\n"
"with open(\"output.mp4\", \"wb\") as f:\n"
"    f.write(resp.read())\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:623
msgid ""
"curl -sS -L \"http://localhost:30010/v1/videos/<VIDEO_ID>/content\" \\\n"
"  -H \"Authorization: Bearer sk-proj-1234567890\" \\\n"
"  -o output.mp4\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:631
msgid "LoRA Management"
msgstr ""

#: ../../../supported_models/diffusion_models.md:633
msgid ""
"The server supports dynamic loading, merging, and unmerging of LoRA adapters."
msgstr ""

#: ../../../supported_models/diffusion_models.md:635
msgid "**Important Notes:**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:636
msgid "Mutual Exclusion: Only one LoRA can be *merged* (active) at a time"
msgstr ""

#: ../../../supported_models/diffusion_models.md:637
msgid ""
"Switching: To switch LoRAs, you must first `unmerge` the current one, then "
"`set` the new one"
msgstr ""

#: ../../../supported_models/diffusion_models.md:638
msgid ""
"Caching: The server caches loaded LoRA weights in memory. Switching back to "
"a previously loaded LoRA (same path) has little cost"
msgstr ""

#: ../../../supported_models/diffusion_models.md:640
msgid "Set LoRA Adapter"
msgstr ""

#: ../../../supported_models/diffusion_models.md:642
msgid ""
"Loads one or more LoRA adapters and merges their weights into the model. "
"Supports both single LoRA (backward compatible) and multiple LoRA adapters."
msgstr ""

#: ../../../supported_models/diffusion_models.md:644
msgid "**Endpoint:** `POST /v1/set_lora`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:646
#: ../../../supported_models/diffusion_models.md:711
#: ../../../supported_models/diffusion_models.md:1077
#: ../../../supported_models/diffusion_models.md:1096
#: ../../../supported_models/diffusion_models.md:1179
msgid "**Parameters:**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:647
msgid ""
"`lora_nickname` (string or list of strings, required): A unique identifier "
"for the LoRA adapter(s). Can be a single string or a list of strings for "
"multiple LoRAs"
msgstr ""

#: ../../../supported_models/diffusion_models.md:648
msgid ""
"`lora_path` (string or list of strings/None, optional): Path to the `."
"safetensors` file(s) or Hugging Face repo ID(s). Required for the first "
"load; optional if re-activating a cached nickname. If a list, must match the "
"length of `lora_nickname`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:649
msgid ""
"`target` (string or list of strings, optional): Which transformer(s) to "
"apply the LoRA to. If a list, must match the length of `lora_nickname`. "
"Valid values:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:650
msgid "`\"all\"` (default): Apply to all transformers"
msgstr ""

#: ../../../supported_models/diffusion_models.md:651
msgid ""
"`\"transformer\"`: Apply only to the primary transformer (high noise for "
"Wan2.2)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:652
msgid "`\"transformer_2\"`: Apply only to transformer_2 (low noise for Wan2.2)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:653
msgid "`\"critic\"`: Apply only to the critic model"
msgstr ""

#: ../../../supported_models/diffusion_models.md:654
msgid ""
"`strength` (float or list of floats, optional): LoRA strength for merge, "
"default 1.0. If a list, must match the length of `lora_nickname`. Values < "
"1.0 reduce the effect, values > 1.0 amplify the effect"
msgstr ""

#: ../../../supported_models/diffusion_models.md:656
msgid "**Single LoRA Example:**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:658
msgid ""
"curl -X POST http://localhost:30010/v1/set_lora \\\n"
"  -H \"Content-Type: application/json\" \\\n"
"  -d '{\n"
"        \"lora_nickname\": \"lora_name\",\n"
"        \"lora_path\": \"/path/to/lora.safetensors\",\n"
"        \"target\": \"all\",\n"
"        \"strength\": 0.8\n"
"      }'\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:669
msgid "**Multiple LoRA Example:**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:671
msgid ""
"curl -X POST http://localhost:30010/v1/set_lora \\\n"
"  -H \"Content-Type: application/json\" \\\n"
"  -d '{\n"
"        \"lora_nickname\": [\"lora_1\", \"lora_2\"],\n"
"        \"lora_path\": [\"/path/to/lora1.safetensors\", \"/path/to/lora2."
"safetensors\"],\n"
"        \"target\": [\"transformer\", \"transformer_2\"],\n"
"        \"strength\": [0.8, 1.0]\n"
"      }'\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:682
msgid "**Multiple LoRA with Same Target:**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:684
msgid ""
"curl -X POST http://localhost:30010/v1/set_lora \\\n"
"  -H \"Content-Type: application/json\" \\\n"
"  -d '{\n"
"        \"lora_nickname\": [\"style_lora\", \"character_lora\"],\n"
"        \"lora_path\": [\"/path/to/style.safetensors\", \"/path/to/character."
"safetensors\"],\n"
"        \"target\": \"all\",\n"
"        \"strength\": [0.7, 0.9]\n"
"      }'\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:695
msgid "[!NOTE] When using multiple LoRAs:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:697
msgid ""
"All list parameters (`lora_nickname`, `lora_path`, `target`, `strength`) "
"must have the same length"
msgstr ""

#: ../../../supported_models/diffusion_models.md:698
msgid ""
"If `target` or `strength` is a single value, it will be applied to all LoRAs"
msgstr ""

#: ../../../supported_models/diffusion_models.md:699
msgid "Multiple LoRAs applied to the same target will be merged in order"
msgstr ""

#: ../../../supported_models/diffusion_models.md:702
msgid "Merge LoRA Weights"
msgstr ""

#: ../../../supported_models/diffusion_models.md:704
msgid "Manually merges the currently set LoRA weights into the base model."
msgstr ""

#: ../../../supported_models/diffusion_models.md:706
msgid ""
"[!NOTE] `set_lora` automatically performs a merge, so this is typically only "
"needed if you have manually unmerged but want to re-apply the same LoRA "
"without calling `set_lora` again.*"
msgstr ""

#: ../../../supported_models/diffusion_models.md:709
msgid "**Endpoint:** `POST /v1/merge_lora_weights`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:712
msgid ""
"`target` (string, optional): Which transformer(s) to merge. One of "
"\"all\" (default), \"transformer\", \"transformer_2\", \"critic\""
msgstr ""

#: ../../../supported_models/diffusion_models.md:713
msgid ""
"`strength` (float, optional): LoRA strength for merge, default 1.0. Values < "
"1.0 reduce the effect, values > 1.0 amplify the effect"
msgstr ""

#: ../../../supported_models/diffusion_models.md:717
msgid ""
"curl -X POST http://localhost:30010/v1/merge_lora_weights \\\n"
"  -H \"Content-Type: application/json\" \\\n"
"  -d '{\"strength\": 0.8}'\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:724
msgid "Unmerge LoRA Weights"
msgstr ""

#: ../../../supported_models/diffusion_models.md:726
msgid ""
"Unmerges the currently active LoRA weights from the base model, restoring it "
"to its original state. This **must** be called before setting a different "
"LoRA."
msgstr ""

#: ../../../supported_models/diffusion_models.md:728
msgid "**Endpoint:** `POST /v1/unmerge_lora_weights`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:732
msgid ""
"curl -X POST http://localhost:30010/v1/unmerge_lora_weights \\\n"
"  -H \"Content-Type: application/json\"\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:737
msgid "List LoRA Adapters"
msgstr ""

#: ../../../supported_models/diffusion_models.md:739
msgid "Returns loaded LoRA adapters and current application status per module."
msgstr ""

#: ../../../supported_models/diffusion_models.md:741
msgid "**Endpoint:** `GET /v1/list_loras`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:745
msgid "curl -sS -X GET \"http://localhost:30010/v1/list_loras\"\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:751
msgid ""
"{\n"
"  \"loaded_adapters\": [\n"
"    { \"nickname\": \"lora_a\", \"path\": \"/weights/lora_a."
"safetensors\" },\n"
"    { \"nickname\": \"lora_b\", \"path\": \"/weights/lora_b.safetensors\" }\n"
"  ],\n"
"  \"active\": {\n"
"    \"transformer\": [\n"
"      {\n"
"        \"nickname\": \"lora2\",\n"
"        \"path\": \"tarn59/pixel_art_style_lora_z_image_turbo\",\n"
"        \"merged\": true,\n"
"        \"strength\": 1.0\n"
"      }\n"
"    ]\n"
"  }\n"
"}\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:770
msgid "Notes:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:771
msgid ""
"If LoRA is not enabled for the current pipeline, the server will return an "
"error."
msgstr ""

#: ../../../supported_models/diffusion_models.md:772
msgid ""
"`num_lora_layers_with_weights` counts only layers that have LoRA weights "
"applied for the active adapter."
msgstr ""

#: ../../../supported_models/diffusion_models.md:774
msgid "Example: Switching LoRAs"
msgstr ""

#: ../../../supported_models/diffusion_models.md:776
msgid "Set LoRA A:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:777
msgid ""
"curl -X POST http://localhost:30010/v1/set_lora -d '{\"lora_nickname\": "
"\"lora_a\", \"lora_path\": \"path/to/A\"}'\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:780
msgid "Generate with LoRA A..."
msgstr ""

#: ../../../supported_models/diffusion_models.md:781
msgid "Unmerge LoRA A:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:782
msgid "curl -X POST http://localhost:30010/v1/unmerge_lora_weights\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:785
msgid "Set LoRA B:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:786
msgid ""
"curl -X POST http://localhost:30010/v1/set_lora -d '{\"lora_nickname\": "
"\"lora_b\", \"lora_path\": \"path/to/B\"}'\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:789
msgid "Generate with LoRA B..."
msgstr ""

#: ../../../supported_models/diffusion_models.md:793
msgid "Attention Backends"
msgstr ""

#: ../../../supported_models/diffusion_models.md:795
msgid ""
"This document describes the attention backends available in sglang diffusion "
"(`sglang.multimodal_gen`) and how to select them."
msgstr ""

#: ../../../supported_models/diffusion_models.md:797
#: ../../../supported_models/diffusion_models.md:884
msgid "Overview"
msgstr ""

#: ../../../supported_models/diffusion_models.md:799
msgid ""
"Attention backends are defined by `AttentionBackendEnum` (`sglang."
"multimodal_gen.runtime.platforms.interface.AttentionBackendEnum`) and "
"selected via the CLI flag `--attention-backend`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:801
msgid ""
"Backend selection is performed by the shared attention layers (e.g. "
"`LocalAttention` / `USPAttention` / `UlyssesAttention` in `sglang."
"multimodal_gen.runtime.layers.attention.layer`) and therefore applies to any "
"model component using these layers (e.g. diffusion transformer / DiT and "
"encoders)."
msgstr ""

#: ../../../supported_models/diffusion_models.md:803
msgid ""
"**CUDA**: prefers FlashAttention (FA3/FA4) when supported; otherwise falls "
"back to PyTorch SDPA."
msgstr ""

#: ../../../supported_models/diffusion_models.md:804
msgid ""
"**ROCm**: uses FlashAttention when available; otherwise falls back to "
"PyTorch SDPA."
msgstr ""

#: ../../../supported_models/diffusion_models.md:805
msgid "**MPS**: always uses PyTorch SDPA."
msgstr ""

#: ../../../supported_models/diffusion_models.md:807
msgid "Backend options"
msgstr ""

#: ../../../supported_models/diffusion_models.md:809
msgid ""
"The CLI accepts the lowercase names of `AttentionBackendEnum`. The table "
"below lists the backends implemented by the built-in platforms. `fa3`/`fa4` "
"are accepted as aliases for `fa`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "CLI value"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Enum value"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
#: ../../../supported_models/diffusion_models.md:1184
msgid "Notes"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`fa` / `fa3` / `fa4`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`FA`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid ""
"FlashAttention. `fa3/fa4` are normalized to `fa` during argument parsing "
"(`ServerArgs.__post_init__`)."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`torch_sdpa`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`TORCH_SDPA`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "PyTorch `scaled_dot_product_attention`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`sliding_tile_attn`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SLIDING_TILE_ATTN`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid ""
"Sliding Tile Attention (STA). Requires `st_attn` and a mask-strategy config "
"file set via the `SGLANG_DIFFUSION_ATTENTION_CONFIG` environment variable."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`sage_attn`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SAGE_ATTN`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid ""
"Requires `sageattention`. Upstream SageAttention CUDA extensions target SM80/"
"SM86/SM89/SM90/SM120 (compute capability 8.0/8.6/8.9/9.0/12.0); see upstream "
"`setup.py`: https://github.com/thu-ml/SageAttention/blob/main/setup.py."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`sage_attn_3`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SAGE_ATTN_3`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Requires SageAttention3 installed per upstream instructions."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`video_sparse_attn`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`VIDEO_SPARSE_ATTN`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Requires `vsa`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`vmoba_attn`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`VMOBA_ATTN`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Requires `kernel.attn.vmoba_attn.vmoba`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`aiter`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`AITER`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Requires `aiter`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:822
msgid "Selection priority"
msgstr ""

#: ../../../supported_models/diffusion_models.md:824
msgid "The selection order in `runtime/layers/attention/selector.py` is:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:826
msgid ""
"`global_force_attn_backend(...)` / "
"`global_force_attn_backend_context_manager(...)`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:827
msgid "CLI `--attention-backend` (`ServerArgs.attention_backend`)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:828
msgid "Auto selection (platform capability, dtype, and installed packages)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:830
msgid "Platform support matrix"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Backend"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "CUDA"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "ROCm"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "MPS"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`fa`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid ""
"CUDA requires SM80+ and fp16/bf16. FlashAttention is only used when the "
"required runtime is installed; otherwise it falls back to `torch_sdpa`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Most compatible option across platforms."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "CUDA-only. Requires `st_attn` and `SGLANG_DIFFUSION_ATTENTION_CONFIG`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "CUDA-only (optional dependency)."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "CUDA-only. Requires `vsa`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "CUDA-only. Requires `kernel.attn.vmoba_attn.vmoba`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:843
#: ../../../supported_models/diffusion_models.md:960
msgid "Usage"
msgstr ""

#: ../../../supported_models/diffusion_models.md:845
msgid "Select a backend via CLI"
msgstr ""

#: ../../../supported_models/diffusion_models.md:847
msgid ""
"sglang generate \\\n"
"  --model-path <MODEL_PATH_OR_ID> \\\n"
"  --prompt \"...\" \\\n"
"  --attention-backend fa\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:854
msgid ""
"sglang generate \\\n"
"  --model-path <MODEL_PATH_OR_ID> \\\n"
"  --prompt \"...\" \\\n"
"  --attention-backend torch_sdpa\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:861
msgid "Using Sliding Tile Attention (STA)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:863
msgid ""
"export SGLANG_DIFFUSION_ATTENTION_CONFIG=/abs/path/to/mask_strategy.json\n"
"\n"
"sglang generate \\\n"
"  --model-path <MODEL_PATH_OR_ID> \\\n"
"  --prompt \"...\" \\\n"
"  --attention-backend sliding_tile_attn\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:872
msgid "Notes for ROCm / MPS"
msgstr ""

#: ../../../supported_models/diffusion_models.md:874
msgid ""
"ROCm: use `--attention-backend torch_sdpa` or `fa` depending on what is "
"available in your environment."
msgstr ""

#: ../../../supported_models/diffusion_models.md:875
msgid "MPS: the platform implementation always uses `torch_sdpa`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:879
msgid "Cache-DiT Acceleration"
msgstr ""

#: ../../../supported_models/diffusion_models.md:881
msgid ""
"SGLang integrates [Cache-DiT](https://github.com/vipshop/cache-dit), a "
"caching acceleration engine for Diffusion Transformers (DiT), to achieve up "
"to **7.4x inference speedup** with minimal quality loss."
msgstr ""

#: ../../../supported_models/diffusion_models.md:886
msgid ""
"**Cache-DiT** uses intelligent caching strategies to skip redundant "
"computation in the denoising loop:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:888
msgid ""
"**DBCache (Dual Block Cache)**: Dynamically decides when to cache "
"transformer blocks based on residual differences"
msgstr ""

#: ../../../supported_models/diffusion_models.md:889
msgid ""
"**TaylorSeer**: Uses Taylor expansion for calibration to optimize caching "
"decisions"
msgstr ""

#: ../../../supported_models/diffusion_models.md:890
msgid ""
"**SCM (Step Computation Masking)**: Step-level caching control for "
"additional speedup"
msgstr ""

#: ../../../supported_models/diffusion_models.md:892
msgid "Basic Usage"
msgstr ""

#: ../../../supported_models/diffusion_models.md:894
msgid ""
"Enable Cache-DiT by exporting the environment variable and using `sglang "
"generate` or `sglang serve` :"
msgstr ""

#: ../../../supported_models/diffusion_models.md:896
msgid ""
"SGLANG_CACHE_DIT_ENABLED=true \\\n"
"sglang generate --model-path Qwen/Qwen-Image \\\n"
"    --prompt \"A beautiful sunset over the mountains\"\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:902
msgid "Advanced Configuration"
msgstr ""

#: ../../../supported_models/diffusion_models.md:904
msgid "DBCache Parameters"
msgstr ""

#: ../../../supported_models/diffusion_models.md:906
msgid "DBCache controls block-level caching behavior:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Parameter"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Env Variable"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Default"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Fn"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SGLANG_CACHE_DIT_FN`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "1"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Number of first blocks to always compute"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Bn"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SGLANG_CACHE_DIT_BN`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "0"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Number of last blocks to always compute"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "W"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SGLANG_CACHE_DIT_WARMUP`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "4"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Warmup steps before caching starts"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "R"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SGLANG_CACHE_DIT_RDT`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "0.24"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Residual difference threshold"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "MC"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SGLANG_CACHE_DIT_MC`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "3"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Maximum continuous cached steps"
msgstr ""

#: ../../../supported_models/diffusion_models.md:916
msgid "TaylorSeer Configuration"
msgstr ""

#: ../../../supported_models/diffusion_models.md:918
msgid "TaylorSeer improves caching accuracy using Taylor expansion:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Enable"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SGLANG_CACHE_DIT_TAYLORSEER`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "false"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Enable TaylorSeer calibrator"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Order"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SGLANG_CACHE_DIT_TS_ORDER`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Taylor expansion order (1 or 2)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:925
msgid "Combined Configuration Example"
msgstr ""

#: ../../../supported_models/diffusion_models.md:927
msgid ""
"DBCache and TaylorSeer are complementary strategies that work together, you "
"can configure both sets of parameters simultaneously:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:930
msgid ""
"SGLANG_CACHE_DIT_ENABLED=true \\\n"
"SGLANG_CACHE_DIT_FN=2 \\\n"
"SGLANG_CACHE_DIT_BN=1 \\\n"
"SGLANG_CACHE_DIT_WARMUP=4 \\\n"
"SGLANG_CACHE_DIT_RDT=0.4 \\\n"
"SGLANG_CACHE_DIT_MC=4 \\\n"
"SGLANG_CACHE_DIT_TAYLORSEER=true \\\n"
"SGLANG_CACHE_DIT_TS_ORDER=2 \\\n"
"sglang generate --model-path black-forest-labs/FLUX.1-dev \\\n"
"    --prompt \"A curious raccoon in a forest\"\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:943
msgid "SCM (Step Computation Masking)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:945
msgid ""
"SCM provides step-level caching control for additional speedup. It decides "
"which denoising steps to compute fully and which to use cached results."
msgstr ""

#: ../../../supported_models/diffusion_models.md:948
msgid "SCM Presets"
msgstr ""

#: ../../../supported_models/diffusion_models.md:950
msgid "SCM is configured with presets:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Preset"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Compute Ratio"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Speed"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Quality"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`none`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "100%"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Baseline"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Best"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`slow`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "~75%"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "~1.3x"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "High"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`medium`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "~50%"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "~2x"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Good"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`fast`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "~35%"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "~3x"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Acceptable"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`ultra`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "~25%"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "~4x"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Lower"
msgstr ""

#: ../../../supported_models/diffusion_models.md:962
msgid ""
"SGLANG_CACHE_DIT_ENABLED=true \\\n"
"SGLANG_CACHE_DIT_SCM_PRESET=medium \\\n"
"sglang generate --model-path Qwen/Qwen-Image \\\n"
"    --prompt \"A futuristic cityscape at sunset\"\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:969
msgid "Custom SCM Bins"
msgstr ""

#: ../../../supported_models/diffusion_models.md:971
msgid "For fine-grained control over which steps to compute vs cache:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:973
msgid ""
"SGLANG_CACHE_DIT_ENABLED=true \\\n"
"SGLANG_CACHE_DIT_SCM_COMPUTE_BINS=\"8,3,3,2,2\" \\\n"
"SGLANG_CACHE_DIT_SCM_CACHE_BINS=\"1,2,2,2,3\" \\\n"
"sglang generate --model-path Qwen/Qwen-Image \\\n"
"    --prompt \"A futuristic cityscape at sunset\"\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:981
msgid "SCM Policy"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Policy"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`dynamic`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SGLANG_CACHE_DIT_SCM_POLICY=dynamic`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Adaptive caching based on content (default)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`static`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SGLANG_CACHE_DIT_SCM_POLICY=static`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Fixed caching pattern"
msgstr ""

#: ../../../supported_models/diffusion_models.md:988
msgid "Environment Variables"
msgstr ""

#: ../../../supported_models/diffusion_models.md:990
msgid ""
"All Cache-DiT parameters can be set via the following environment variables:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Environment Variable"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SGLANG_CACHE_DIT_ENABLED`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Enable Cache-DiT acceleration"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "First N blocks to always compute"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Last N blocks to always compute"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Warmup steps before caching"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Max continuous cached steps"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "TaylorSeer order (1 or 2)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SGLANG_CACHE_DIT_SCM_PRESET`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "none"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "SCM preset (none/slow/medium/fast/ultra)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SGLANG_CACHE_DIT_SCM_POLICY`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "dynamic"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "SCM caching policy"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SGLANG_CACHE_DIT_SCM_COMPUTE_BINS`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "not set"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Custom SCM compute bins"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "`SGLANG_CACHE_DIT_SCM_CACHE_BINS`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Custom SCM cache bins"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1007
msgid "Supported Models"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1009
msgid ""
"SGLang Diffusion x Cache-DiT supports almost all models originally supported "
"in SGLang Diffusion:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Model Family"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Example Models"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Wan"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Wan2.1, Wan2.2"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "FLUX.1-dev, FLUX.2-dev, FLUX.2-Klein"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Z-Image"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Qwen"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Qwen-Image, Qwen-Image-Edit"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "GLM"
msgstr ""

#: ../../../supported_models/diffusion_models.md:0
msgid "Hunyuan"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1020
msgid "Performance Tips"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1022
msgid ""
"**Start with defaults**: The default parameters work well for most models"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1023
msgid "**Use TaylorSeer**: It typically improves both speed and quality"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1024
msgid ""
"**Tune R threshold**: Lower values = better quality, higher values = faster"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1025
msgid ""
"**SCM for extra speed**: Use `medium` preset for good speed/quality balance"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1026
msgid "**Warmup matters**: Higher warmup = more stable caching decisions"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1028
msgid "Limitations"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1030
msgid ""
"**Single GPU only**: Distributed support (TP/SP) is not yet validated; Cache-"
"DiT will be automatically disabled when `world_size > 1`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1032
msgid ""
"**SCM minimum steps**: SCM requires >= 8 inference steps to be effective"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1033
msgid ""
"**Model support**: Only models registered in Cache-DiT's "
"BlockAdapterRegister are supported"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1035
msgid "Troubleshooting"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1037
msgid "Distributed environment warning"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1039
msgid ""
"WARNING: cache-dit is disabled in distributed environment (world_size=N)\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1043
msgid ""
"This is expected behavior. Cache-DiT currently only supports single-GPU "
"inference."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1045
msgid "SCM disabled for low step count"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1047
msgid ""
"For models with < 8 inference steps (e.g., DMD distilled models), SCM will "
"be automatically disabled. DBCache acceleration still works."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1050
#: ../../../supported_models/diffusion_models.md:1272
msgid "References"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1052
msgid "[Cache-Dit](https://github.com/vipshop/cache-dit)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1053
msgid ""
"[SGLang Diffusion](https://github.com/sgl-project/sglang/tree/main/python/"
"sglang/multimodal_gen)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1057
msgid "Profiling Multimodal Generation"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1059
msgid ""
"This guide covers profiling techniques for multimodal generation pipelines "
"in SGLang."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1061
msgid "PyTorch Profiler"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1063
msgid ""
"PyTorch Profiler provides detailed kernel execution time, call stack, and "
"GPU utilization metrics."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1065
msgid "Denoising Stage Profiling"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1067
msgid ""
"Profile the denoising stage with sampled timesteps (default: 5 steps after 1 "
"warmup step):"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1069
msgid ""
"sglang generate \\\n"
"  --model-path Qwen/Qwen-Image \\\n"
"  --prompt \"A Logo With Bold Large Text: SGL Diffusion\" \\\n"
"  --seed 0 \\\n"
"  --profile\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1078
msgid "`--profile`: Enable profiling for the denoising stage"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1079
msgid ""
"`--num-profiled-timesteps N`: Number of timesteps to profile after warmup "
"(default: 5)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1080
msgid "Smaller values reduce trace file size"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1081
msgid ""
"Example: `--num-profiled-timesteps 10` profiles 10 steps after 1 warmup step"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1083
msgid "Full Pipeline Profiling"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1085
msgid ""
"Profile all pipeline stages (text encoding, denoising, VAE decoding, etc.):"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1087
msgid ""
"sglang generate \\\n"
"  --model-path Qwen/Qwen-Image \\\n"
"  --prompt \"A Logo With Bold Large Text: SGL Diffusion\" \\\n"
"  --seed 0 \\\n"
"  --profile \\\n"
"  --profile-all-stages\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1097
msgid ""
"`--profile-all-stages`: Used with `--profile`, profile all pipeline stages "
"instead of just denoising"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1099
msgid "Output Location"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1101
msgid "By default, trace files are saved in the ./logs/ directory."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1103
msgid ""
"The exact output file path will be shown in the console output, for example:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1105
msgid ""
"[mm-dd hh:mm:ss] Saved profiler traces to: /sgl-workspace/sglang/logs/"
"mocked_fake_id_for_offline_generate-5_steps-global-rank0.trace.json.gz\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1109
msgid "View Traces"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1111
msgid "Load and visualize trace files at:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1112
msgid "https://ui.perfetto.dev/ (recommended)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1113
msgid "chrome://tracing (Chrome only)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1115
msgid ""
"For large trace files, reduce `--num-profiled-timesteps` or avoid using `--"
"profile-all-stages`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1118
msgid "`--perf-dump-path` (Stage/Step Timing Dump)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1120
msgid ""
"Besides profiler traces, you can also dump a lightweight JSON report that "
"contains:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1121
msgid "stage-level timing breakdown for the full pipeline"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1122
msgid ""
"step-level timing breakdown for the denoising stage (per diffusion step)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1124
msgid ""
"This is useful to quickly identify which stage dominates end-to-end latency, "
"and whether denoising steps have uniform runtimes (and if not, which step "
"has an abnormal spike)."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1126
msgid ""
"The dumped JSON contains a `denoise_steps_ms` field formatted as an array of "
"objects, each with a `step` key (the step index) and a `duration_ms` key."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1128
msgid "Example:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1130
msgid ""
"sglang generate \\\n"
"  --model-path <MODEL_PATH_OR_ID> \\\n"
"  --prompt \"<PROMPT>\" \\\n"
"  --perf-dump-path perf.json\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1137
msgid "Nsight Systems"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1139
msgid ""
"Nsight Systems provides low-level CUDA profiling with kernel details, "
"register usage, and memory access patterns."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1141
msgid "Installation"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1143
msgid ""
"See the [SGLang profiling guide](https://github.com/sgl-project/sglang/blob/"
"main/docs/developer_guide/benchmark_and_profiling.md#profile-with-nsight) "
"for installation instructions."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1145
msgid "Basic Profiling"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1147
msgid "Profile the entire pipeline execution:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1149
msgid ""
"nsys profile \\\n"
"  --trace-fork-before-exec=true \\\n"
"  --cuda-graph-trace=node \\\n"
"  --force-overwrite=true \\\n"
"  -o QwenImage \\\n"
"  sglang generate \\\n"
"    --model-path Qwen/Qwen-Image \\\n"
"    --prompt \"A Logo With Bold Large Text: SGL Diffusion\" \\\n"
"    --seed 0\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1161
msgid "Targeted Stage Profiling"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1163
msgid ""
"Use `--delay` and `--duration` to capture specific stages and reduce file "
"size:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1165
msgid ""
"nsys profile \\\n"
"  --trace-fork-before-exec=true \\\n"
"  --cuda-graph-trace=node \\\n"
"  --force-overwrite=true \\\n"
"  --delay 10 \\\n"
"  --duration 30 \\\n"
"  -o QwenImage_denoising \\\n"
"  sglang generate \\\n"
"    --model-path Qwen/Qwen-Image \\\n"
"    --prompt \"A Logo With Bold Large Text: SGL Diffusion\" \\\n"
"    --seed 0\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1180
msgid ""
"`--delay N`: Wait N seconds before starting capture (skip initialization "
"overhead)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1181
msgid "`--duration N`: Capture for N seconds (focus on specific stages)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1182
msgid "`--force-overwrite`: Overwrite existing output files"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1186
msgid ""
"**Reduce trace size**: Use `--num-profiled-timesteps` with smaller values or "
"`--delay`/`--duration` with Nsight Systems"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1187
msgid ""
"**Stage-specific analysis**: Use `--profile` alone for denoising stage, add "
"`--profile-all-stages` for full pipeline"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1188
msgid ""
"**Multiple runs**: Profile with different prompts and resolutions to "
"identify bottlenecks across workloads"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1190
msgid "FAQ"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1192
msgid ""
"If you are profiling `sglang generate` with Nsight Systems and find that the "
"generated profiler file did not capture any CUDA kernels, you can resolve "
"this issue by increasing the model's inference steps to extend the execution "
"time."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1196
msgid "Contributing to SGLang Diffusion"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1198
msgid ""
"This guide outlines the requirements for contributing to the SGLang "
"Diffusion module (`sglang.multimodal_gen`)."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1200
msgid "1. Commit Message Convention"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1202
msgid ""
"We follow a structured commit message format to maintain a clean history."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1204
msgid "**Format:**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1205
msgid "[diffusion] <scope>: <subject>\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1209
msgid "**Examples:**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1210
msgid "`[diffusion] cli: add --perf-dump-path argument`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1211
msgid "`[diffusion] scheduler: fix deadlock in batch processing`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1212
msgid "`[diffusion] model: support Stable Diffusion 3.5`"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1214
msgid "**Rules:**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1215
msgid "**Prefix**: Always start with `[diffusion]`."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1216
msgid ""
"**Scope** (Optional): `cli`, `scheduler`, `model`, `pipeline`, `docs`, etc."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1217
msgid ""
"**Subject**: Imperative mood, short and clear (e.g., \"add feature\" not "
"\"added feature\")."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1219
msgid "2. Performance Reporting"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1221
msgid ""
"For PRs that impact **latency**, **throughput**, or **memory usage**, you "
"**should** provide a performance comparison report."
msgstr ""

#: ../../../supported_models/diffusion_models.md:1223
msgid "How to Generate a Report"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1225
msgid "**Baseline**: run the benchmark (for a single generation task)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1226
msgid ""
"$ sglang generate --model-path <model> --prompt \"A benchmark prompt\" --"
"perf-dump-path baseline.json\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1230
msgid ""
"**New**: run the same benchmark, without modifying any server_args or "
"sampling_params"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1231
msgid ""
"$ sglang generate --model-path <model> --prompt \"A benchmark prompt\" --"
"perf-dump-path new.json\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1235
msgid ""
"**Compare**: run the compare script, which will print a Markdown table to "
"the console"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1236
msgid ""
"$ python python/sglang/multimodal_gen/benchmarks/compare_perf.py baseline."
"json new.json [new2.json ...]\n"
"### Performance Comparison Report\n"
"...\n"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1241
msgid "**Paste**: paste the table into the PR description"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1243
msgid "3. CI-Based Change Protection"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1245
msgid ""
"Consider adding tests to the `pr-test` or `nightly-test` suites to safeguard "
"your changes, especially for PRs that:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1247
msgid "support a new model"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1248
msgid "support or fix important features"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1249
msgid "significantly improve performance"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1251
msgid ""
"See [test](https://github.com/sgl-project/sglang/tree/main/python/sglang/"
"multimodal_gen/test) for examples"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1255
msgid "How to Support New Diffusion Models"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1257
msgid ""
"SGLang diffusion uses a modular pipeline architecture built around two key "
"concepts:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1259
msgid ""
"**`ComposedPipeline`**: Orchestrates `PipelineStage`s to define the complete "
"generation process"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1260
msgid ""
"**`PipelineStage`**: Modular components (prompt encoding, denoising loop, "
"VAE decoding, etc.)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1262
msgid "To add a new model, you'll need to define:"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1263
msgid ""
"**`PipelineConfig`**: Static model configurations (paths, precision settings)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1264
msgid ""
"**`SamplingParams`**: Runtime generation parameters (prompt, guidance_scale, "
"steps)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1265
msgid "**`ComposedPipeline`**: Chain together pipeline stages"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1266
msgid ""
"**Modules**: Model components (text_encoder, transformer, vae, scheduler)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1268
msgid ""
"For the complete implementation guide with examples, see: **[How to Support "
"New Diffusion Models](https://github.com/sgl-project/sglang/blob/main/python/"
"sglang/multimodal_gen/docs/support_new_models.md)**"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1274
msgid "[SGLang GitHub](https://github.com/sgl-project/sglang)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1275
msgid "[Cache-DiT](https://github.com/vipshop/cache-dit)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1276
msgid "[FastVideo](https://github.com/hao-ai-lab/FastVideo)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1277
msgid "[xDiT](https://github.com/xdit-project/xDiT)"
msgstr ""

#: ../../../supported_models/diffusion_models.md:1278
msgid "[Diffusers](https://github.com/huggingface/diffusers)"
msgstr ""
