# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang 0.4\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-11-09 18:38+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../supported_models/support_new_models.md:1
msgid "How to Support New Models"
msgstr ""

#: ../../../supported_models/support_new_models.md:3
msgid ""
"This document explains how to add support for new language models and "
"multimodal large language models (MLLMs) in SGLang. It also covers how to "
"test new models and register external implementations."
msgstr ""

#: ../../../supported_models/support_new_models.md:6
msgid "How to Support a New Language Model"
msgstr ""

#: ../../../supported_models/support_new_models.md:8
msgid ""
"To support a new model in SGLang, you only need to add a single file under "
"the [SGLang Models Directory](https://github.com/sgl-project/sglang/tree/"
"main/python/sglang/srt/models). You can learn from existing model "
"implementations and create a new file for your model. For most models, you "
"should be able to find a similar model to start with (e.g., starting from "
"Llama). Also refer how to [port a Model from vLLM to SGLang](#port-a-model-"
"from-vllm-to-sglang)"
msgstr ""

#: ../../../supported_models/support_new_models.md:14
msgid "How to Support a New Multimodal Large Language Model"
msgstr ""

#: ../../../supported_models/support_new_models.md:16
msgid ""
"To support a new multimodal large language model (MLLM) in SGLang, there are "
"several key components in addition to the standard LLM support:"
msgstr ""

#: ../../../supported_models/support_new_models.md:19
msgid ""
"**Register your new model as multimodal**: Extend `is_multimodal_model` in "
"[model_config.py](https://github.com/sgl-project/sglang/"
"blob/0ab3f437aba729b348a683ab32b35b214456efc7/python/sglang/srt/configs/"
"model_config.py#L561) to return `True` for your model."
msgstr ""

#: ../../../supported_models/support_new_models.md:24
msgid ""
"**Register a new chat-template** See [conversation.py](https://github.com/"
"sgl-project/sglang/blob/86a779dbe9e815c02f71ea82574608f6eae016b5/python/"
"sglang/srt/conversation.py)"
msgstr ""

#: ../../../supported_models/support_new_models.md:27
msgid ""
"**Multimodal Data Processor**: Define a new `Processor` class that inherits "
"from `BaseMultimodalProcessor` and register this processor as your model’s "
"dedicated processor. See [multimodal_processor.py](https://github.com/sgl-"
"project/sglang/blob/main/python/sglang/srt/managers/multimodal_processor.py) "
"for more details."
msgstr ""

#: ../../../supported_models/support_new_models.md:33
msgid ""
"**Handle Multimodal Tokens**: Implement a `pad_input_ids` function for your "
"new model. In this function, multimodal tokens in the prompt should be "
"expanded (if necessary) and padded with multimodal-data-hashes so that "
"SGLang can recognize different multimodal data with `RadixAttention`."
msgstr ""

#: ../../../supported_models/support_new_models.md:38
msgid ""
"**Adapt to Vision Attention**: Adapt the multi-headed `Attention` of ViT "
"with SGLang’s `VisionAttention`."
msgstr ""

#: ../../../supported_models/support_new_models.md:41
msgid ""
"You can refer to [Qwen2VL](https://github.com/sgl-project/sglang/blob/main/"
"python/sglang/srt/models/qwen2_vl.py) or other mllm implementations. These "
"models demonstrate how to correctly handle both multimodal and textual "
"inputs."
msgstr ""

#: ../../../supported_models/support_new_models.md:44
msgid ""
"You should test the new MLLM locally against Hugging Face models. See the "
"[ `mmmu`](https://github.com/sgl-project/sglang/tree/main/benchmark/mmmu) "
"benchmark for an example."
msgstr ""

#: ../../../supported_models/support_new_models.md:47
msgid "Test the Correctness"
msgstr ""

#: ../../../supported_models/support_new_models.md:49
msgid "Interactive Debugging"
msgstr ""

#: ../../../supported_models/support_new_models.md:51
msgid ""
"For interactive debugging, compare the outputs of Hugging Face/Transformers "
"and SGLang. The following two commands should give the same text output and "
"very similar prefill logits:"
msgstr ""

#: ../../../supported_models/support_new_models.md:54
msgid "Get the reference output:"
msgstr ""

#: ../../../supported_models/support_new_models.md:55
msgid ""
"python3 scripts/playground/reference_hf.py --model-path [new model] --model-"
"type {text,mllm}\n"
msgstr ""

#: ../../../supported_models/support_new_models.md:58
msgid "Get the SGLang output:"
msgstr ""

#: ../../../supported_models/support_new_models.md:59
msgid "python3 -m sglang.bench_one_batch --correct --model [new model]\n"
msgstr ""

#: ../../../supported_models/support_new_models.md:63
msgid "Add the Model to the Test Suite"
msgstr ""

#: ../../../supported_models/support_new_models.md:65
msgid ""
"To ensure the new model is well maintained, add it to the test suite by "
"including it in the `ALL_OTHER_MODELS` list in the [test_generation_models."
"py](https://github.com/sgl-project/sglang/blob/main/test/srt/models/"
"test_generation_models.py) file, test the new model on your local machine "
"and report the results on demonstrative benchmarks (GSM8K, MMLU, MMMU, MMMU-"
"Pro, etc.) in your PR."
msgstr ""

#: ../../../supported_models/support_new_models.md:70
msgid "This is the command to test a new model on your local machine:"
msgstr ""

#: ../../../supported_models/support_new_models.md:72
msgid ""
"ONLY_RUN=Qwen/Qwen2-1.5B python3 -m unittest test_generation_models."
"TestGenerationModels.test_others\n"
msgstr ""

#: ../../../supported_models/support_new_models.md:76
msgid "Port a Model from vLLM to SGLang"
msgstr ""

#: ../../../supported_models/support_new_models.md:78
msgid ""
"The [vLLM Models Directory](https://github.com/vllm-project/vllm/tree/main/"
"vllm/model_executor/models) is a valuable resource, as vLLM covers many "
"models. SGLang reuses vLLM’s interface and some layers, making it easier to "
"port models from vLLM to SGLang."
msgstr ""

#: ../../../supported_models/support_new_models.md:82
msgid "To port a model from vLLM to SGLang:"
msgstr ""

#: ../../../supported_models/support_new_models.md:84
msgid "Compare these two files for guidance:"
msgstr ""

#: ../../../supported_models/support_new_models.md:85
msgid ""
"[SGLang Llama Implementation](https://github.com/sgl-project/sglang/blob/"
"main/python/sglang/srt/models/llama.py)"
msgstr ""

#: ../../../supported_models/support_new_models.md:86
msgid ""
"[vLLM Llama Implementation](https://github.com/vllm-project/vllm/blob/main/"
"vllm/model_executor/models/llama.py)"
msgstr ""

#: ../../../supported_models/support_new_models.md:87
msgid "The major differences include:"
msgstr ""

#: ../../../supported_models/support_new_models.md:88
msgid ""
"**Replace vLLM’s `Attention` with `RadixAttention`** (ensure you pass "
"`layer_id` to `RadixAttention`)."
msgstr ""

#: ../../../supported_models/support_new_models.md:89
msgid "**Replace vLLM’s `LogitsProcessor` with SGLang’s `LogitsProcessor`.**"
msgstr ""

#: ../../../supported_models/support_new_models.md:90
msgid ""
"**Replace the multi-headed `Attention` of ViT with SGLang’s "
"`VisionAttention`.**"
msgstr ""

#: ../../../supported_models/support_new_models.md:91
msgid ""
"**Replace other vLLM layers** (such as `RMSNorm`, `SiluAndMul`) with SGLang "
"layers."
msgstr ""

#: ../../../supported_models/support_new_models.md:92
msgid "**Remove `Sample`.**"
msgstr "**移除 `Sample`。**"

#: ../../../supported_models/support_new_models.md:93
msgid ""
"**Change the `forward()` functions** and add a `forward_batch()` method."
msgstr ""

#: ../../../supported_models/support_new_models.md:94
msgid "**Add `EntryClass`** at the end."
msgstr ""

#: ../../../supported_models/support_new_models.md:95
msgid ""
"**Ensure that the new implementation uses only SGLang components** and does "
"not rely on any vLLM components."
msgstr ""

#: ../../../supported_models/support_new_models.md:97
msgid ""
"Note: make sure you add your new model to the supported models list in the "
"supported models documentation."
msgstr ""

#: ../../../supported_models/support_new_models.md:99
msgid "Registering an External Model Implementation"
msgstr ""

#: ../../../supported_models/support_new_models.md:101
msgid ""
"In addition to the methods above, you can register your new model with the "
"`ModelRegistry` before launching the server. This allows you to integrate "
"your model without modifying the source code."
msgstr ""

#: ../../../supported_models/support_new_models.md:104
msgid "For example:"
msgstr "例如："

#: ../../../supported_models/support_new_models.md:106
msgid ""
"from sglang.srt.models.registry import ModelRegistry\n"
"from sglang.srt.entrypoints.http_server import launch_server\n"
"\n"
"# For a single model, add it to the registry:\n"
"ModelRegistry.models[model_name] = model_class\n"
"\n"
"# For multiple models, you can imitate the import_model_classes() function:\n"
"from functools import lru_cache\n"
"\n"
"@lru_cache()\n"
"def import_new_model_classes():\n"
"    model_arch_name_to_cls = {}\n"
"    # Populate model_arch_name_to_cls with your new model classes.\n"
"    ...\n"
"    return model_arch_name_to_cls\n"
"\n"
"ModelRegistry.models.update(import_new_model_classes())\n"
"\n"
"# Launch the server with your server arguments:\n"
"launch_server(server_args)\n"
msgstr ""

#: ../../../supported_models/support_new_models.md:131
msgid ""
"By following these guidelines, you can add support for new language models "
"and multimodal large language models in SGLang and ensure they are "
"thoroughly tested and easily integrated into the system."
msgstr ""
