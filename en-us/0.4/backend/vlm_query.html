
<!DOCTYPE html>


<html lang="en-US" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Querying Qwen-VL &#8212; SGLang</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=3e48b14c"></script>
    <script src="../_static/doctools.js?v=fd6eb6e6"></script>
    <script src="../_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=ccdb6887"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'backend/vlm_query';</script>
    <link rel="canonical" href="https://projects.localizethedocs.org/sglang-docs-l10n/backend/vlm_query.html" />
    <link rel="icon" href="../_static/logo.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="SGLang Frontend Language" href="../frontend/frontend.html" />
    <link rel="prev" title="PD Disaggregation" href="pd_disaggregation.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en-US"/>
    <meta name="docbuild:last-update" content="Feb 17, 2026"/>
<script type="text/javascript" src="../ltd-provenance.js"></script>
<script type="text/javascript" src="../ltd-current.js"></script>
<script type="text/javascript" src="../../../ltd-config.js"></script>
<script type="text/javascript" src="../../../ltd-flyout.js"></script>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="SGLang - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="SGLang - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../start/install.html">Install SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Backend Tutorial</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../references/deepseek.html">DeepSeek Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/llama4.html">Llama4 Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="send_request.html">Sending Requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="openai_api_completions.html">OpenAI APIs - Completions</a></li>
<li class="toctree-l1"><a class="reference internal" href="openai_api_vision.html">OpenAI APIs - Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="openai_api_embeddings.html">OpenAI APIs - Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="native_api.html">SGLang Native APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_engine_api.html">Offline Engine API</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Backend Configurations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="server_arguments.html">Server Arguments</a></li>
<li class="toctree-l1"><a class="reference internal" href="sampling_params.html">Sampling Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyperparameter_tuning.html">Hyperparameter Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="attention_backend.html">Attention Backend</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Supported Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../supported_models/generative_models.html">Large Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/multimodal_language_models.html">Multimodal Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/embedding_models.html">Embedding Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/reward_models.html">Reward Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/support_new_models.html">How to Support New Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/transformers_fallback.html">Transformers fallback in SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="speculative_decoding.html">Speculative Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="structured_outputs.html">Structured Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="function_calling.html">Tool and Function Calling</a></li>
<li class="toctree-l1"><a class="reference internal" href="separate_reasoning.html">Reasoning Parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="structured_outputs_for_reasoning_models.html">Structured Outputs For Reasoning Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_chat_template.html">Custom Chat Template</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="lora.html">LoRA Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="pd_disaggregation.html">PD Disaggregation</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Querying Qwen-VL</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Frontend Tutorial</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../frontend/frontend.html">SGLang Frontend Language</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontend/choices_methods.html">Choices Methods in SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SGLang Router</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../router/router.html">Router for Data Parallelism</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../references/general.html">General Guidance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/hardware.html">Hardware Supports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/advanced_deploy.html">Multi-Node Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/performance_analysis_and_optimization.html">Performance Analysis &amp; Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/developer.html">Developer Reference</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/blob/main/backend/vlm_query.ipynb?plain=1" target="_blank"
   class="btn btn-sm btn-source-file-button dropdown-item"
   title="Show source"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">Show source</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/edit/main/backend/vlm_query.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/issues/new?title=Issue%20on%20page%20%2Fbackend/vlm_query.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/backend/vlm_query.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Querying Qwen-VL</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Querying Qwen-VL</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Query-via-the-offline-Engine-API">Query via the offline Engine API</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Query-via-the-offline-Engine-API,-but-send-precomputed-embeddings">Query via the offline Engine API, but send precomputed embeddings</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Querying-Llama-4-(Vision)">Querying Llama 4 (Vision)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Query via the offline Engine API</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Query via the offline Engine API, but send precomputed embeddings</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <style>
    .output_area.stderr, .output_area.stdout {
        color: #d3d3d3 !important; /* light gray */
    }
</style><section id="Querying-Qwen-VL">
<h1>Querying Qwen-VL<a class="headerlink" href="#Querying-Qwen-VL" title="Link to this heading">#</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">nest_asyncio</span>

<span class="n">nest_asyncio</span><span class="o">.</span><span class="n">apply</span><span class="p">()</span>  <span class="c1"># Run this first.</span>

<span class="n">model_path</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen2.5-VL-3B-Instruct&quot;</span>
<span class="n">chat_template</span> <span class="o">=</span> <span class="s2">&quot;qwen2-vl&quot;</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Lets create a prompt.</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">io</span><span class="w"> </span><span class="kn">import</span> <span class="n">BytesIO</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.entrypoints.openai.protocol</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatCompletionRequest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.conversation</span><span class="w"> </span><span class="kn">import</span> <span class="n">chat_templates</span>

<span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span>
    <span class="n">BytesIO</span><span class="p">(</span>
        <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s2">&quot;https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true&quot;</span>
        <span class="p">)</span><span class="o">.</span><span class="n">content</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">conv</span> <span class="o">=</span> <span class="n">chat_templates</span><span class="p">[</span><span class="n">chat_template</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">conv</span><span class="o">.</span><span class="n">append_message</span><span class="p">(</span><span class="n">conv</span><span class="o">.</span><span class="n">roles</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="sa">f</span><span class="s2">&quot;What&#39;s shown here: </span><span class="si">{</span><span class="n">conv</span><span class="o">.</span><span class="n">image_token</span><span class="si">}</span><span class="s2">?&quot;</span><span class="p">)</span>
<span class="n">conv</span><span class="o">.</span><span class="n">append_message</span><span class="p">(</span><span class="n">conv</span><span class="o">.</span><span class="n">roles</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">conv</span><span class="o">.</span><span class="n">image_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">image</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">conv</span><span class="o">.</span><span class="n">get_prompt</span><span class="p">())</span>
<span class="n">image</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;|im_start|&gt;system
You are a helpful assistant.&lt;|im_end|&gt;
&lt;|im_start|&gt;user
What&#39;s shown here: &lt;|vision_start|&gt;&lt;|image_pad|&gt;&lt;|vision_end|&gt;?&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/backend_vlm_query_2_1.png" src="../_images/backend_vlm_query_2_1.png" />
</div>
</div>
<section id="Query-via-the-offline-Engine-API">
<h2>Query via the offline Engine API<a class="headerlink" href="#Query-via-the-offline-Engine-API" title="Link to this heading">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sglang</span><span class="w"> </span><span class="kn">import</span> <span class="n">Engine</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span>
    <span class="n">model_path</span><span class="o">=</span><span class="n">model_path</span><span class="p">,</span> <span class="n">chat_template</span><span class="o">=</span><span class="n">chat_template</span><span class="p">,</span> <span class="n">mem_fraction_static</span><span class="o">=</span><span class="mf">0.8</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00&lt;?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:03&lt;00:03,  3.13s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06&lt;00:00,  3.27s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06&lt;00:00,  3.25s/it]

Capturing batches (bs=1 avail_mem=21.63 GB): 100%|██████████| 35/35 [00:10&lt;00:00,  3.19it/s]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">conv</span><span class="o">.</span><span class="n">get_prompt</span><span class="p">(),</span> <span class="n">image_data</span><span class="o">=</span><span class="p">[</span><span class="n">image</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
In the picture, a person in a yellow shirt is hanging laundry on a clothesline attached to the back of a yellow taxi in an urban setting. There are city streets, buildings, and traffic lights visible in the background. The scene appears to be incongruous and amusing, as it shows an unusual and somewhat chaotic activity happening in a busy city environment.
</pre></div></div>
</div>
</section>
<section id="Query-via-the-offline-Engine-API,-but-send-precomputed-embeddings">
<h2>Query via the offline Engine API, but send precomputed embeddings<a class="headerlink" href="#Query-via-the-offline-Engine-API,-but-send-precomputed-embeddings" title="Link to this heading">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute the image embeddings using Huggingface.</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoProcessor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Qwen2_5_VLForConditionalGeneration</span>

<span class="n">processor</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">use_fast</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">vision</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">Qwen2_5_VLForConditionalGeneration</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">visual</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "7c94dead4660409c9acfac1f3461d7d9", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">processed_prompt</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span>
    <span class="n">images</span><span class="o">=</span><span class="p">[</span><span class="n">image</span><span class="p">],</span> <span class="n">text</span><span class="o">=</span><span class="n">conv</span><span class="o">.</span><span class="n">get_prompt</span><span class="p">(),</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
<span class="p">)</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">processed_prompt</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">precomputed_embeddings</span> <span class="o">=</span> <span class="n">vision</span><span class="p">(</span>
    <span class="n">processed_prompt</span><span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">processed_prompt</span><span class="p">[</span><span class="s2">&quot;image_grid_thw&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">mm_item</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">modality</span><span class="o">=</span><span class="s2">&quot;IMAGE&quot;</span><span class="p">,</span>
    <span class="n">image_grid_thw</span><span class="o">=</span><span class="n">processed_prompt</span><span class="p">[</span><span class="s2">&quot;image_grid_thw&quot;</span><span class="p">],</span>
    <span class="n">precomputed_embeddings</span><span class="o">=</span><span class="n">precomputed_embeddings</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">image_data</span><span class="o">=</span><span class="p">[</span><span class="n">mm_item</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The image shows a scene with two yellow taxis in an urban setting. The taxi on the left has a red light on top, indicating that it may be waiting or preparing to drive. The other taxi, which is facing left, has its hatch open with some clothing or fabric hanging out. The background features high-rise buildings and city streets, suggesting this is taking place in a downtown area of a city. The presence of multiple flags on flagpoles indicates that there might be some celebration or event within the vicinity.
</pre></div></div>
</div>
</section>
</section>
<section id="Querying-Llama-4-(Vision)">
<h1>Querying Llama 4 (Vision)<a class="headerlink" href="#Querying-Llama-4-(Vision)" title="Link to this heading">#</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">nest_asyncio</span>

<span class="n">nest_asyncio</span><span class="o">.</span><span class="n">apply</span><span class="p">()</span>  <span class="c1"># Run this first.</span>

<span class="n">model_path</span> <span class="o">=</span> <span class="s2">&quot;meta-llama/Llama-4-Scout-17B-16E-Instruct&quot;</span>
<span class="n">chat_template</span> <span class="o">=</span> <span class="s2">&quot;llama-4&quot;</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Lets create a prompt.</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">io</span><span class="w"> </span><span class="kn">import</span> <span class="n">BytesIO</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.entrypoints.openai.protocol</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatCompletionRequest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sglang.srt.conversation</span><span class="w"> </span><span class="kn">import</span> <span class="n">chat_templates</span>

<span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span>
    <span class="n">BytesIO</span><span class="p">(</span>
        <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s2">&quot;https://github.com/sgl-project/sglang/blob/main/test/lang/example_image.png?raw=true&quot;</span>
        <span class="p">)</span><span class="o">.</span><span class="n">content</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">conv</span> <span class="o">=</span> <span class="n">chat_templates</span><span class="p">[</span><span class="n">chat_template</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">conv</span><span class="o">.</span><span class="n">append_message</span><span class="p">(</span><span class="n">conv</span><span class="o">.</span><span class="n">roles</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="sa">f</span><span class="s2">&quot;What&#39;s shown here: </span><span class="si">{</span><span class="n">conv</span><span class="o">.</span><span class="n">image_token</span><span class="si">}</span><span class="s2">?&quot;</span><span class="p">)</span>
<span class="n">conv</span><span class="o">.</span><span class="n">append_message</span><span class="p">(</span><span class="n">conv</span><span class="o">.</span><span class="n">roles</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">conv</span><span class="o">.</span><span class="n">image_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">image</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">conv</span><span class="o">.</span><span class="n">get_prompt</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Image size: </span><span class="si">{</span><span class="n">image</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">image</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;|header_start|&gt;user&lt;|header_end|&gt;

What&#39;s shown here: &lt;|image|&gt;?&lt;|eot|&gt;&lt;|header_start|&gt;assistant&lt;|header_end|&gt;


Image size: (570, 380)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/backend_vlm_query_11_1.png" src="../_images/backend_vlm_query_11_1.png" />
</div>
</div>
<section id="id1">
<h2>Query via the offline Engine API<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sglang.test.test_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_in_ci</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">is_in_ci</span><span class="p">():</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">sglang</span><span class="w"> </span><span class="kn">import</span> <span class="n">Engine</span>

    <span class="n">llm</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span>
        <span class="n">model_path</span><span class="o">=</span><span class="n">model_path</span><span class="p">,</span>
        <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">enable_multimodal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">mem_fraction_static</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
        <span class="n">tp_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">attention_backend</span><span class="o">=</span><span class="s2">&quot;fa3&quot;</span><span class="p">,</span>
        <span class="n">context_length</span><span class="o">=</span><span class="mi">65536</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Loading safetensors checkpoint shards:   0% Completed | 0/50 [00:00&lt;?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 1/50 [00:22&lt;18:10, 22.26s/it]
Loading safetensors checkpoint shards:   4% Completed | 2/50 [00:44&lt;17:44, 22.17s/it]
Loading safetensors checkpoint shards:   6% Completed | 3/50 [01:06&lt;17:24, 22.22s/it]
Loading safetensors checkpoint shards:   8% Completed | 4/50 [01:28&lt;16:55, 22.07s/it]
Loading safetensors checkpoint shards:  10% Completed | 5/50 [01:50&lt;16:28, 21.96s/it]
Loading safetensors checkpoint shards:  12% Completed | 6/50 [02:11&lt;15:59, 21.80s/it]
Loading safetensors checkpoint shards:  14% Completed | 7/50 [02:34&lt;15:52, 22.14s/it]
Loading safetensors checkpoint shards:  16% Completed | 8/50 [02:54&lt;15:05, 21.57s/it]
Loading safetensors checkpoint shards:  18% Completed | 9/50 [03:17&lt;14:51, 21.74s/it]
Loading safetensors checkpoint shards:  20% Completed | 10/50 [03:29&lt;12:31, 18.79s/it]
Loading safetensors checkpoint shards:  22% Completed | 11/50 [03:32&lt;09:10, 14.13s/it]
Loading safetensors checkpoint shards:  24% Completed | 12/50 [03:36&lt;06:53, 10.89s/it]
Loading safetensors checkpoint shards:  26% Completed | 13/50 [03:39&lt;05:19,  8.65s/it]
Loading safetensors checkpoint shards:  28% Completed | 14/50 [03:43&lt;04:15,  7.09s/it]
Loading safetensors checkpoint shards:  30% Completed | 15/50 [03:46&lt;03:29,  6.00s/it]
Loading safetensors checkpoint shards:  32% Completed | 16/50 [03:50&lt;02:57,  5.23s/it]
Loading safetensors checkpoint shards:  34% Completed | 17/50 [03:53&lt;02:35,  4.73s/it]
Loading safetensors checkpoint shards:  36% Completed | 18/50 [03:57&lt;02:18,  4.33s/it]
Loading safetensors checkpoint shards:  38% Completed | 19/50 [04:00&lt;02:06,  4.09s/it]
Loading safetensors checkpoint shards:  40% Completed | 20/50 [04:04&lt;01:56,  3.87s/it]
Loading safetensors checkpoint shards:  42% Completed | 21/50 [04:07&lt;01:48,  3.74s/it]
Loading safetensors checkpoint shards:  44% Completed | 22/50 [04:11&lt;01:43,  3.71s/it]
Loading safetensors checkpoint shards:  46% Completed | 23/50 [04:14&lt;01:37,  3.63s/it]
Loading safetensors checkpoint shards:  48% Completed | 24/50 [04:18&lt;01:33,  3.60s/it]
Loading safetensors checkpoint shards:  50% Completed | 25/50 [04:21&lt;01:26,  3.45s/it]
Loading safetensors checkpoint shards:  52% Completed | 26/50 [04:21&lt;01:02,  2.61s/it]
Loading safetensors checkpoint shards:  54% Completed | 27/50 [04:25&lt;01:06,  2.91s/it]
Loading safetensors checkpoint shards:  56% Completed | 28/50 [04:28&lt;01:07,  3.09s/it]
Loading safetensors checkpoint shards:  58% Completed | 29/50 [04:32&lt;01:07,  3.20s/it]
Loading safetensors checkpoint shards:  60% Completed | 30/50 [04:35&lt;01:05,  3.25s/it]
Loading safetensors checkpoint shards:  62% Completed | 31/50 [04:39&lt;01:02,  3.30s/it]
Loading safetensors checkpoint shards:  64% Completed | 32/50 [04:42&lt;01:00,  3.37s/it]
Loading safetensors checkpoint shards:  66% Completed | 33/50 [04:46&lt;00:58,  3.45s/it]
Loading safetensors checkpoint shards:  68% Completed | 34/50 [04:49&lt;00:55,  3.45s/it]
Loading safetensors checkpoint shards:  70% Completed | 35/50 [04:53&lt;00:51,  3.45s/it]
Loading safetensors checkpoint shards:  72% Completed | 36/50 [04:56&lt;00:48,  3.46s/it]
Loading safetensors checkpoint shards:  74% Completed | 37/50 [05:00&lt;00:44,  3.45s/it]
Loading safetensors checkpoint shards:  76% Completed | 38/50 [05:03&lt;00:41,  3.45s/it]
Loading safetensors checkpoint shards:  78% Completed | 39/50 [05:07&lt;00:38,  3.50s/it]
Loading safetensors checkpoint shards:  80% Completed | 40/50 [05:10&lt;00:34,  3.49s/it]
Loading safetensors checkpoint shards:  82% Completed | 41/50 [05:14&lt;00:31,  3.49s/it]
Loading safetensors checkpoint shards:  84% Completed | 42/50 [05:17&lt;00:27,  3.47s/it]
Loading safetensors checkpoint shards:  86% Completed | 43/50 [05:20&lt;00:24,  3.43s/it]
Loading safetensors checkpoint shards:  88% Completed | 44/50 [05:24&lt;00:20,  3.46s/it]
Loading safetensors checkpoint shards:  90% Completed | 45/50 [05:27&lt;00:17,  3.44s/it]
Loading safetensors checkpoint shards:  92% Completed | 46/50 [05:31&lt;00:13,  3.44s/it]
Loading safetensors checkpoint shards:  94% Completed | 47/50 [05:34&lt;00:10,  3.43s/it]
Loading safetensors checkpoint shards:  96% Completed | 48/50 [05:38&lt;00:06,  3.43s/it]
Loading safetensors checkpoint shards:  98% Completed | 49/50 [05:41&lt;00:03,  3.45s/it]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Setting sliding_window_size to be attention_chunk_size: 8192Setting sliding_window_size to be attention_chunk_size: 8192

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Loading safetensors checkpoint shards: 100% Completed | 50/50 [05:44&lt;00:00,  3.43s/it]
Loading safetensors checkpoint shards: 100% Completed | 50/50 [05:44&lt;00:00,  6.90s/it]

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Setting sliding_window_size to be attention_chunk_size: 8192
Setting sliding_window_size to be attention_chunk_size: 8192
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Capturing batches (bs=1 avail_mem=21.53 GB): 100%|██████████| 35/35 [00:15&lt;00:00,  2.25it/s]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">is_in_ci</span><span class="p">():</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">conv</span><span class="o">.</span><span class="n">get_prompt</span><span class="p">(),</span> <span class="n">image_data</span><span class="o">=</span><span class="p">[</span><span class="n">image</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The image depicts a man ironing clothing on the back of a yellow SUV in a city street, with another yellow taxi passing by. The man is wearing a yellow shirt and appears to be ironing a blue shirt on a makeshift ironing board set up behind the SUV. The scene suggests that the man may be a street vendor or someone who is trying to make a living by providing ironing services to people on the go.
</pre></div></div>
</div>
</section>
<section id="id2">
<h2>Query via the offline Engine API, but send precomputed embeddings<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">is_in_ci</span><span class="p">():</span>
    <span class="c1"># Compute the image embeddings using Huggingface.</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoProcessor</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Llama4ForConditionalGeneration</span>

    <span class="n">processor</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">use_fast</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Llama4ForConditionalGeneration</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">model_path</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span>
    <span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">vision</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">multi_modal_projector</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">multi_modal_projector</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "0eae2e36d07d42b89bc4b5ac7d62f226", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">is_in_ci</span><span class="p">():</span>
    <span class="n">processed_prompt</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span>
        <span class="n">images</span><span class="o">=</span><span class="p">[</span><span class="n">image</span><span class="p">],</span> <span class="n">text</span><span class="o">=</span><span class="n">conv</span><span class="o">.</span><span class="n">get_prompt</span><span class="p">(),</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">processed_prompt</span><span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">=}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">processed_prompt</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="n">image_outputs</span> <span class="o">=</span> <span class="n">vision</span><span class="p">(</span>
        <span class="n">processed_prompt</span><span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">),</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">image_features</span> <span class="o">=</span> <span class="n">image_outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>
    <span class="n">vision_flat</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">image_features</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">precomputed_embeddings</span> <span class="o">=</span> <span class="n">multi_modal_projector</span><span class="p">(</span><span class="n">vision_flat</span><span class="p">)</span>

    <span class="n">mm_item</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">modality</span><span class="o">=</span><span class="s2">&quot;IMAGE&quot;</span><span class="p">,</span> <span class="n">precomputed_embeddings</span><span class="o">=</span><span class="n">precomputed_embeddings</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">image_data</span><span class="o">=</span><span class="p">[</span><span class="n">mm_item</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
processed_prompt[&#34;pixel_values&#34;].shape=torch.Size([5, 3, 336, 336])
The image depicts a man ironing on a makeshift ironing board set up on the back of a yellow SUV, in the middle of a busy street. The man is wearing a yellow shirt and appears to be ironing a blue shirt. In the background, there are other yellow taxis and tall buildings, suggesting that the scene is set in a city, likely New York City. The overall scene is one of a person going about their daily activities in a busy urban environment.
</pre></div></div>
</div>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="pd_disaggregation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">PD Disaggregation</p>
      </div>
    </a>
    <a class="right-next"
       href="../frontend/frontend.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">SGLang Frontend Language</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Querying Qwen-VL</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Query-via-the-offline-Engine-API">Query via the offline Engine API</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Query-via-the-offline-Engine-API,-but-send-precomputed-embeddings">Query via the offline Engine API, but send precomputed embeddings</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Querying-Llama-4-(Vision)">Querying Llama 4 (Vision)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Query via the offline Engine API</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Query via the offline Engine API, but send precomputed embeddings</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By SGLang Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023-2026, SGLang.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Feb 17, 2026.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>