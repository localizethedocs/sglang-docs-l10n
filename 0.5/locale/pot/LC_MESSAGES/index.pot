# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang 0.5\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-12-09 11:10+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../index.rst:14
msgid "Get Started"
msgstr ""

#: ../../../index.rst:20
msgid "Basic Usage"
msgstr ""

#: ../../../index.rst:31
msgid "Advanced Features"
msgstr ""

#: ../../../index.rst:55
msgid "Supported Models"
msgstr ""

#: ../../../index.rst:68
msgid "Hardware Platforms"
msgstr ""

#: ../../../index.rst:79
msgid "Developer Guide"
msgstr ""

#: ../../../index.rst:88
msgid "References"
msgstr ""

#: ../../../index.rst:102
msgid "Security Acknowledgement"
msgstr ""

#: ../../../index.rst:2
msgid "SGLang Documentation"
msgstr ""

#: ../../../index.rst:4
msgid ""
"SGLang is a high-performance serving framework for large language models and "
"vision-language models. It is designed to deliver low-latency and high-"
"throughput inference across a wide range of setups, from a single GPU to "
"large distributed clusters. Its core features include:"
msgstr ""

#: ../../../index.rst:8
msgid ""
"**Fast Backend Runtime**: Provides efficient serving with RadixAttention for "
"prefix caching, a zero-overhead CPU scheduler, prefill-decode "
"disaggregation, speculative decoding, continuous batching, paged attention, "
"tensor/pipeline/expert/data parallelism, structured outputs, chunked "
"prefill, quantization (FP4/FP8/INT4/AWQ/GPTQ), and multi-LoRA batching."
msgstr ""

#: ../../../index.rst:9
msgid ""
"**Extensive Model Support**: Supports a wide range of generative models "
"(Llama, Qwen, DeepSeek, Kimi, GLM, GPT, Gemma, Mistral, etc.), embedding "
"models (e5-mistral, gte, mcdse), reward models (Skywork), and diffusion "
"models (WAN, Qwen-Image), with easy extensibility for integrating new "
"models. Compatible with most Hugging Face models and OpenAI APIs."
msgstr ""

#: ../../../index.rst:10
msgid ""
"**Extensive Hardware Support**: Runs on NVIDIA GPUs (GB200/B300/H100/A100/"
"Spark), AMD GPUs (MI355/MI300), Intel Xeon CPUs, Google TPUs, Ascend NPUs, "
"and more."
msgstr ""

#: ../../../index.rst:11
msgid ""
"**Flexible Frontend Language**: Offers an intuitive interface for "
"programming LLM applications, supporting chained generation calls, advanced "
"prompting, control flow, multi-modal inputs, parallelism, and external "
"interactions."
msgstr ""

#: ../../../index.rst:12
msgid ""
"**Active Community**: SGLang is open-source and supported by a vibrant "
"community with widespread industry adoption, powering over 400,000 GPUs "
"worldwide."
msgstr ""
