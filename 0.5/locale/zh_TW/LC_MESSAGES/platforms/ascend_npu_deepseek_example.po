# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2026, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang 0.5\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-02-10 09:10+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../platforms/ascend_npu_deepseek_example.md:1
msgid "DeepSeek examples"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:3
msgid "Running DeepSeek-V3"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:5
msgid "Running DeepSeek in PD mixed mode on 1 x Atlas 800I A3."
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:7
#: ../../../platforms/ascend_npu_deepseek_example.md:56
msgid ""
"W4A8 Model weights could be found [here](https://modelers.cn/models/"
"Modelers_Park/DeepSeek-R1-0528-w4a8)."
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:9
msgid ""
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"#Deepep communication settings\n"
"export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=32\n"
"export HCCL_BUFFSIZE=1600\n"
"\n"
"#spec overlap\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"\n"
"#npu acceleration operator\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"\n"
"python3 -m sglang.launch_server \\\n"
"    --model-path ${MODEL_PATH} \\\n"
"    --tp 16 \\\n"
"    --trust-remote-code \\\n"
"    --attention-backend ascend \\\n"
"    --device npu \\\n"
"    --quantization modelslim \\\n"
"    --watchdog-timeout 9000 \\\n"
"    --cuda-graph-bs 8 16 24 28 32 \\\n"
"    --mem-fraction-static 0.68 \\\n"
"    --max-running-requests 128 \\\n"
"    --context-length 8188 \\\n"
"    --disable-radix-cache \\\n"
"    --chunked-prefill-size -1 \\\n"
"    --max-prefill-tokens 16384 \\\n"
"    --moe-a2a-backend deepep \\\n"
"    --deepep-mode auto \\\n"
"    --enable-dp-attention \\\n"
"    --dp-size 4 \\\n"
"    --enable-dp-lm-head \\\n"
"    --speculative-algorithm NEXTN \\\n"
"    --speculative-num-steps 3 \\\n"
"    --speculative-eagle-topk 1 \\\n"
"    --speculative-num-draft-tokens 4 \\\n"
"    --dtype bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:54
msgid "Running DeepSeek with PD disaggregation mode on 2 x Atlas 800I A3."
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:58
msgid "Prefill:"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:60
msgid ""
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"#memfabric config store\n"
"export ASCEND_MF_STORE_URL=\"tcp://<PREFILL_HOST_IP>:<PORT>\"\n"
"\n"
"#Deepep communication settings\n"
"export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"export HCCL_BUFFSIZE=1536\n"
"\n"
"#npu acceleration operator\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"export TASK_QUEUE_ENABLE=2\n"
"\n"
"python -m sglang.launch_server \\\n"
"    --model-path ${MODEL_PATH} \\\n"
"    --host $PREFILL_HOST_IP \\\n"
"    --port 8000 \\\n"
"    --disaggregation-mode prefill \\\n"
"    --disaggregation-bootstrap-port 8996 \\\n"
"    --disaggregation-transfer-backend ascend \\\n"
"    --trust-remote-code \\\n"
"    --nnodes 1 \\\n"
"    --node-rank 0 \\\n"
"    --tp-size 16 \\\n"
"    --mem-fraction-static 0.6 \\\n"
"    --attention-backend ascend \\\n"
"    --device npu \\\n"
"    --quantization modelslim \\\n"
"    --load-balance-method round_robin \\\n"
"    --max-running-requests 8 \\\n"
"    --context-length 8192 \\\n"
"    --disable-radix-cache \\\n"
"    --chunked-prefill-size -1 \\\n"
"    --max-prefill-tokens 28680 \\\n"
"    --moe-a2a-backend deepep \\\n"
"    --deepep-mode normal \\\n"
"    --speculative-algorithm NEXTN \\\n"
"    --speculative-num-steps 3 \\\n"
"    --speculative-eagle-topk 1 \\\n"
"    --speculative-num-draft-tokens 4 \\\n"
"    --dp-size 2 \\\n"
"    --enable-dp-attention \\\n"
"    --disable-shared-experts-fusion \\\n"
"    --dtype bfloat16\n"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:110
msgid "Decode:"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:112
msgid ""
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"#memfabric config store\n"
"export ASCEND_MF_STORE_URL=\"tcp://<PREFILL_HOST_IP>:<PORT>\"\n"
"\n"
"#Deepep communication settings\n"
"export HCCL_BUFFSIZE=720\n"
"export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=88\n"
"\n"
"#spec overlap\n"
"export SGLANG_ENABLE_SPEC_V2=1\n"
"export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"\n"
"#npu acceleration operator\n"
"unset TASK_QUEUE_ENABLE\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"export ENABLE_MOE_NZ=1\n"
"\n"
"# suggest max-running-requests <= max-cuda-graph-bs * dp_size, Because when "
"this value is exceeded, performance will significantly degrade.\n"
"python -m sglang.launch_server \\\n"
"    --model-path ${MODEL_PATH} \\\n"
"    --disaggregation-mode decode \\\n"
"    --host $DECODE_HOST_IP \\\n"
"    --port 8001 \\\n"
"    --trust-remote-code \\\n"
"    --nnodes 1 \\\n"
"    --node-rank 0 \\\n"
"    --tp-size 16 \\\n"
"    --dp-size 16 \\\n"
"    --mem-fraction-static 0.8 \\\n"
"    --max-running-requests 352 \\\n"
"    --attention-backend ascend \\\n"
"    --device npu \\\n"
"    --quantization modelslim \\\n"
"    --prefill-round-robin-balance \\\n"
"    --moe-a2a-backend deepep \\\n"
"    --enable-dp-attention \\\n"
"    --deepep-mode low_latency \\\n"
"    --enable-dp-lm-head \\\n"
"    --cuda-graph-bs 8 10 12 14 16 18 20 22 \\\n"
"    --disaggregation-transfer-backend ascend \\\n"
"    --watchdog-timeout 9000 \\\n"
"    --context-length 8192 \\\n"
"    --speculative-algorithm NEXTN \\\n"
"    --speculative-num-steps 3 \\\n"
"    --speculative-eagle-topk 1 \\\n"
"    --speculative-num-draft-tokens 4 \\\n"
"    --disable-shared-experts-fusion \\\n"
"    --dtype bfloat16 \\\n"
"    --tokenizer-worker-num 4\n"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:167
msgid "SGLang Model Gateway (former Router)"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:169
msgid ""
"python -m sglang_router.launch_router \\\n"
"    --pd-disaggregation \\\n"
"    --policy cache_aware \\\n"
"    --prefill http://<PREFILL_HOST_IP>:8000 8996 \\\n"
"    --decode http://<DECODE_HOST_IP>:8001 \\\n"
"    --host 127.0.0.1 \\\n"
"    --port 6688\n"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:179
msgid "Running DeepSeek with PD disaggregation on 4 x Atlas 800I A3."
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:181
msgid ""
"W8A8 Model weights could be found [here](https://modelers.cn/models/"
"State_Cloud/Deepseek-R1-bf16-hfd-w8a8)."
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:183
msgid "Prefill & Decode:"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:185
msgid ""
"echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/"
"scaling_governor\n"
"sysctl -w vm.swappiness=0\n"
"sysctl -w kernel.numa_balancing=0\n"
"sysctl -w kernel.sched_migration_cost_ns=50000\n"
"export SGLANG_SET_CPU_AFFINITY=1\n"
"unset ASCEND_LAUNCH_BLOCKING\n"
"source /usr/local/Ascend/ascend-toolkit/set_env.sh\n"
"source /usr/local/Ascend/nnal/atb/set_env.sh\n"
"export PATH=/usr/local/Ascend/8.5.0/compiler/bishengir/bin:$PATH\n"
"\n"
"export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True\n"
"export STREAMS_PER_DEVICE=32\n"
"\n"
"export ASCEND_MF_STORE_URL=\"tcp://your prefill ip1:24669\"\n"
"\n"
"P_IP=('your prefill ip1' 'your prefill ip2')\n"
"\n"
"D_IP=('your decode ip1' 'your decode ip2')\n"
"\n"
"MODEL_PATH=xxx\n"
"\n"
"export SGLANG_NPU_USE_MLAPO=1\n"
"export SGLANG_USE_FIA_NZ=1\n"
"\n"
"LOCAL_HOST1=`hostname -I|awk -F \" \" '{print$1}'`\n"
"LOCAL_HOST2=`hostname -I|awk -F \" \" '{print$2}'`\n"
"echo \"${LOCAL_HOST1}\"\n"
"echo \"${LOCAL_HOST2}\"\n"
"# prefill\n"
"for i in \"${!P_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${P_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${P_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${P_IP[$i]}\"\n"
"        export HCCL_BUFFSIZE=1536\n"
"        export DEEP_NORMAL_MODE_USE_INT8_QUANT=1\n"
"        export TASK_QUEUE_ENABLE=2\n"
"\n"
"        export HCCL_SOCKET_IFNAME=lo\n"
"        export GLOO_SOCKET_IFNAME=lo\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH}  --"
"disaggregation-mode prefill --host ${P_IP[$i]} \\\n"
"        --port 8000 --disaggregation-bootstrap-port $((8998+$i)) --trust-"
"remote-code --nnodes 1 --node-rank 0 \\\n"
"        --tp-size 16 --mem-fraction-static 0.81 --attention-backend ascend --"
"device npu --quantization modelslim \\\n"
"        --disaggregation-transfer-backend ascend --max-running-requests 8 --"
"context-length 8192  --disable-radix-cache \\\n"
"        --chunked-prefill-size -1 --max-prefill-tokens 28680 --moe-a2a-"
"backend deepep --deepep-mode normal \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 1 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 2  \\\n"
"        --dp-size 2 --enable-dp-attention --disable-shared-experts-fusion --"
"dtype bfloat16 --enable-attn-tp-input-scattered\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
"\n"
"# decode\n"
"for i in \"${!D_IP[@]}\";\n"
"do\n"
"    if [[ \"$LOCAL_HOST1\" == \"${D_IP[$i]}\" || \"$LOCAL_HOST2\" == "
"\"${D_IP[$i]}\" ]];\n"
"    then\n"
"        echo \"${D_IP[$i]}\"\n"
"        export SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1\n"
"        export SGLANG_ENABLE_SPEC_V2=1\n"
"        export HCCL_BUFFSIZE=650\n"
"        export SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=78\n"
"        export TASK_QUEUE_ENABLE=1\n"
"        export SGLANG_SCHEDULER_SKIP_ALL_GATHER=1\n"
"        export HCCL_SOCKET_IFNAME=xxx\n"
"        export GLOO_SOCKET_IFNAME=xxx\n"
"        python -m sglang.launch_server --model-path ${MODEL_PATH} --"
"disaggregation-mode decode --host ${D_IP[$i]} \\\n"
"        --port 8001 --trust-remote-code --dist-init-addr ${D_IP[0]}:5000 --"
"nnodes 2 --node-rank $i --tp-size 32 --dp-size 32 \\\n"
"        --mem-fraction-static 0.815 --max-running-requests 832 --attention-"
"backend ascend --device npu --quantization modelslim \\\n"
"        --moe-a2a-backend deepep --enable-dp-attention --deepep-mode "
"low_latency --enable-dp-lm-head --moe-dense-tp 1 \\\n"
"        --cuda-graph-bs 12 14 16 18 20 22 24 26 --disaggregation-transfer-"
"backend ascend --watchdog-timeout 9000 --context-length 8192 \\\n"
"        --speculative-algorithm NEXTN --speculative-num-steps 2 --"
"speculative-eagle-topk 1 --speculative-num-draft-tokens 3  \\\n"
"        --tokenizer-worker-num 4 --prefill-round-robin-balance --disable-"
"shared-experts-fusion --dtype bfloat16 \\\n"
"        --load-balance-method decode_round_robin\n"
"        NODE_RANK=$i\n"
"        break\n"
"    fi\n"
"done\n"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:266
msgid "SGLang Model Gateway (former Router):"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:268
msgid ""
"export SGLANG_DP_ROUND_ROBIN=1\n"
"python -m sglang_router.launch_router \\\n"
"    --pd-disaggregation \\\n"
"    --policy cache_aware \\\n"
"    --prefill http://P_IP:8000 8998 \\\n"
"    --prefill http://P_IP:8000 8999 \\\n"
"    --decode http://D_IP:8001 \\\n"
"    --host 127.0.0.1 \\\n"
"    --port 6688 \\\n"
"    --mini-lb\n"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:281
msgid "test gsm8k"
msgstr ""

#: ../../../platforms/ascend_npu_deepseek_example.md:283
msgid ""
"from types import SimpleNamespace\n"
"from sglang.test.few_shot_gsm8k import run_eval\n"
"\n"
"def gsm8k():\n"
"    args = SimpleNamespace(\n"
"        num_shots=5,\n"
"        data_path=None,\n"
"        num_questions=200,\n"
"        max_new_tokens=512,\n"
"        parallel=32,\n"
"        host=f\"http://127.0.0.1\",\n"
"        port=6688,\n"
"    )\n"
"    metrics = run_eval(args)\n"
"    print(f\"{metrics=}\")\n"
"    print(f\"{metrics['accuracy']=}\")\n"
"if __name__ == \"__main__\":\n"
"    gsm8k()\n"
msgstr ""
