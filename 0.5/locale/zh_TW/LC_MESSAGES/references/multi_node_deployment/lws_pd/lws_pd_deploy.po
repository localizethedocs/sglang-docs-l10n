# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, SGLang
# This file is distributed under the same license as the SGLang package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SGLang 0.5\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-11-09 18:38+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:1
msgid "LWS Based PD Deploy"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:3
msgid "0. Prerequisites"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:5
msgid "k8s >=1.26"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:6
msgid "lws installed on k8s."
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:8
msgid "1. Image Preparation"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:10
msgid "`lmsysorg/sglang:deepep`"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:12
msgid "2. Deployment Manifest Files"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:14
msgid ""
"***Notice: We will package all deployment files into Helm Chart format in "
"the near future. Interested community members can contact us to contribute***"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:16
msgid "Prefill"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:18
msgid "Prefill manifest file [prefill.yaml](lws-examples/p.yaml)"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:20
#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:341
msgid ""
"*Note: The NodeSelector section, model location section, and taint "
"toleration section can be adjusted according to your actual deployment "
"environment*"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:22
msgid ""
"apiVersion: leaderworkerset.x-k8s.io/v1\n"
"kind: LeaderWorkerSet\n"
"metadata:\n"
"  name: deepseekr10528-prefill-main\n"
"spec:\n"
"  leaderWorkerTemplate:\n"
"    leaderTemplate:\n"
"      metadata:\n"
"        labels:\n"
"          role: leader\n"
"      spec:\n"
"        containers:\n"
"        - command:\n"
"          - python3\n"
"          - -m\n"
"          - sglang.launch_server\n"
"          - --port\n"
"          - \"30000\"\n"
"          - --host\n"
"          - \"0.0.0.0\"\n"
"          - --model-path\n"
"          - /work/models\n"
"          - --disaggregation-ib-device\n"
"          # should modify according your rdma env\n"
"          - mlx5_bond_0,mlx5_bond_1,mlx5_bond_2,mlx5_bond_3\n"
"          - --chunked-prefill-size\n"
"          - \"524288\"\n"
"          - --max-prefill-tokens\n"
"          - \"32768\"\n"
"          - --page-size\n"
"          - \"64\"\n"
"          #          - --init-expert-location\n"
"          #          - /home/aiges/tuned/attachment_ep_statistics/"
"prefill_in1024.json\n"
"          - --ep-dispatch-algorithm\n"
"          - dynamic\n"
"          - --eplb-algorithm\n"
"          - deepseek\n"
"          #          - --deepep-config\n"
"          #          -  /home/aiges/tuned/tuned_8sms.json\n"
"          - --enable-dp-lm-head\n"
"          - --enable-dp-attention\n"
"          - --dp-size\n"
"          - \"16\"\n"
"          - --disable-radix-cache\n"
"          - --moe-a2a-backend\n"
"          - deepep\n"
"          - --disaggregation-mode\n"
"          - prefill\n"
"          - --mem-fraction-static\n"
"          - \"0.7\"\n"
"          - --context-length\n"
"          - \"32768\"\n"
"          - --tp\n"
"          - \"16\"\n"
"          - --dist-init-addr\n"
"          - $(LWS_LEADER_ADDRESS):20102\n"
"          - --nnodes\n"
"          - $(LWS_GROUP_SIZE)\n"
"          - --node-rank\n"
"          - $(LWS_WORKER_INDEX)\n"
"          - --trust-remote-code\n"
"          - --ep-num-redundant-experts\n"
"          - \"32\"\n"
"          - --moe-dense-tp-size\n"
"          - \"1\"\n"
"          - --max-running-requests\n"
"          - \"1024\"\n"
"          env:\n"
"#          - name: NVSHMEM_HCA_PE_MAPPING\n"
"#            value: \"mlx5_bond_0:1:2,mlx5_bond_1:1:2,mlx5_bond_2:1:2,"
"mlx5_bond_3:1:2\"\n"
"#          - name: NVSHMEM_HCA_LIST\n"
"#            value: \"mlx5_bond_0:1,mlx5_bond_1:1,mlx5_bond_2:1,"
"mlx5_bond_3:1\"\n"
"          - name: NVSHMEM_IB_GID_INDEX\n"
"            value: \"3\"\n"
"          - name: NVSHMEM_ENABLE_NIC_PE_MAPPING\n"
"            value: \"1\"\n"
"          - name: SGLANG_SET_CPU_AFFINITY\n"
"            value: \"true\"\n"
"          - name: SGLANG_ENABLE_JIT_DEEPGEMM\n"
"            value: \"1\"\n"
"          - name: NCCL_IB_QPS_PER_CONNECTION\n"
"            value: \"8\"\n"
"          - name: NCCL_IB_SPLIT_DATA_ON_QPS\n"
"            value: \"1\"\n"
"          - name: NCCL_NET_PLUGIN\n"
"            value: none\n"
"          - name: NCCL_IB_TC\n"
"            value: \"136\"\n"
"          - name: NCCL_MIN_NCHANNELS\n"
"            value: \"4\"\n"
"          - name: MC_TE_METRIC\n"
"            value: \"false\"\n"
"          - name: NCCL_IB_SL\n"
"            value: \"5\"\n"
"          - name: NCCL_IB_HCA\n"
"            value: ^=mlx5_0,mlx5_5,mlx5_6\n"
"          - name: LWS_WORKER_INDEX\n"
"            valueFrom:\n"
"              fieldRef:\n"
"                fieldPath: metadata.labels['leaderworkerset.sigs.k8s.io/"
"worker-index']\n"
"          image: lmsysorg/sglang:deepep\n"
"          name: sglang-leader\n"
"          ports:\n"
"          - containerPort: 30000\n"
"            protocol: TCP\n"
"          readinessProbe:\n"
"            periodSeconds: 30\n"
"            tcpSocket:\n"
"              port: 30000\n"
"          resources:\n"
"            limits:\n"
"              nvidia.com/gpu: \"8\"\n"
"          securityContext:\n"
"            capabilities:\n"
"              add:\n"
"              - IPC_LOCK\n"
"            privileged: true\n"
"          volumeMounts:\n"
"          - mountPath: /dev/shm\n"
"            name: dshm\n"
"          - mountPath: /work/models\n"
"            name: model\n"
"          - mountPath: /dev/infiniband\n"
"            name: ib\n"
"          - mountPath: /sgl-workspace/sglang/python/sglang/srt/layers/moe/"
"fused_moe_triton/configs\n"
"            name: cf\n"
"          - mountPath: /root/.cache\n"
"            name: sgl-cache\n"
"        dnsPolicy: ClusterFirstWithHostNet\n"
"        hostIPC: true\n"
"        hostNetwork: true\n"
"        nodeSelector:\n"
"          pd: \"yes\"\n"
"        tolerations:\n"
"        - key: pd\n"
"          operator: Exists\n"
"        - key: node-role\n"
"          operator: Exists\n"
"        volumes:\n"
"        - emptyDir:\n"
"            medium: Memory\n"
"          name: dshm\n"
"        - hostPath:\n"
"            # modify according to you deployment env\n"
"            path: /data1/maas_hosted_models/models/DeepSeek-R1-0528/"
"deepseek_r1_0528\n"
"          name: model\n"
"        - hostPath:\n"
"            path: /dev/infiniband\n"
"          name: ib\n"
"        - hostPath:\n"
"            # modify according to you deployment env\n"
"            path: /data1/maas_hosted_models/models/fused_moe_triton/configs\n"
"          name: cf\n"
"        - hostPath:\n"
"            # modify according to you deployment env\n"
"            path: /data1/sgl_cache\n"
"            type: DirectoryOrCreate\n"
"          name: sgl-cache\n"
"    restartPolicy: RecreateGroupOnPodRestart\n"
"    size: 2\n"
"    workerTemplate:\n"
"      metadata: {}\n"
"      spec:\n"
"        containers:\n"
"        - command:\n"
"          - python3\n"
"          - -m\n"
"          - sglang.launch_server\n"
"          - --model-path\n"
"          - /work/models\n"
"          - --disaggregation-ib-device\n"
"          - mlx5_bond_0,mlx5_bond_1,mlx5_bond_2,mlx5_bond_3\n"
"          - --chunked-prefill-size\n"
"          - \"524288\"\n"
"          - --max-prefill-tokens\n"
"          - \"32768\"\n"
"          - --page-size\n"
"          - \"64\"\n"
"          #- --init-expert-location\n"
"          #- /home/aiges/tuned/attachment_ep_statistics/prefill_in1024.json\n"
"          - --ep-dispatch-algorithm\n"
"          - dynamic\n"
"          - --eplb-algorithm\n"
"          - deepseek\n"
"#          - --deepep-config\n"
"#          -  /home/aiges/tuned/tuned_8sms.json\n"
"          - --enable-dp-lm-head\n"
"          - --enable-dp-attention\n"
"          - --dp-size\n"
"          - \"16\"\n"
"          - --disable-radix-cache\n"
"          - --moe-a2a-backend\n"
"          - deepep\n"
"          - --disaggregation-mode\n"
"          - prefill\n"
"          - --mem-fraction-static\n"
"          - \"0.7\"\n"
"          - --context-length\n"
"          - \"32768\"\n"
"          - --tp\n"
"          - \"16\"\n"
"          - --dist-init-addr\n"
"          - $(LWS_LEADER_ADDRESS):20102\n"
"          - --nnodes\n"
"          - $(LWS_GROUP_SIZE)\n"
"          - --node-rank\n"
"          - $(LWS_WORKER_INDEX)\n"
"          - --trust-remote-code\n"
"          - --ep-num-redundant-experts\n"
"          - \"32\"\n"
"          - --moe-dense-tp-size\n"
"          - \"1\"\n"
"          - --max-running-requests\n"
"          - \"1024\"\n"
"          env:\n"
"          - name: SGLANG_SET_CPU_AFFINITY\n"
"            value: \"true\"\n"
"          - name: SGLANG_HACK_DEEPEP_NUM_SMS\n"
"            value: \"8\"\n"
"          - name: SGLANG_HACK_DEEPEP_NEW_MODE\n"
"            value: \"0\"\n"
"#          - name: NVSHMEM_HCA_PE_MAPPING\n"
"#            value: \"mlx5_bond_0:1:2,mlx5_bond_1:1:2,mlx5_bond_2:1:2,"
"mlx5_bond_3:1:2\"\n"
"#          - name: NVSHMEM_HCA_LIST\n"
"#            value: \"mlx5_bond_0:1,mlx5_bond_1:1,mlx5_bond_2:1,"
"mlx5_bond_3:1\"\n"
"          - name: NCCL_IB_HCA\n"
"            value: ^=mlx5_0,mlx5_5,mlx5_6\n"
"          - name: NVSHMEM_IB_TRAFFIC_CLASS\n"
"            value: \"16\"\n"
"          - name: NVSHMEM_IB_GID_INDEX\n"
"            value: \"3\"\n"
"          - name: NVSHMEM_ENABLE_NIC_PE_MAPPING\n"
"            value: \"1\"\n"
"          - name: CUDA_LAUNCH_BLOCKING\n"
"            value: \"0\"\n"
"          - name: SGLANG_MOONCAKE_TRANS_THREAD\n"
"            value: \"8\"\n"
"          - name: SGLANG_ENABLE_JIT_DEEPGEMM\n"
"            value: \"1\"\n"
"          - name: SGL_CHUNKED_PREFIX_CACHE_THRESHOLD\n"
"            value: \"0\"\n"
"          - name: NCCL_IB_QPS_PER_CONNECTION\n"
"            value: \"8\"\n"
"          - name: NCCL_IB_SPLIT_DATA_ON_QPS\n"
"            value: \"1\"\n"
"          - name: NCCL_NET_PLUGIN\n"
"            value: none\n"
"          - name: NCCL_IB_TC\n"
"            value: \"136\"\n"
"          - name: NCCL_MIN_NCHANNELS\n"
"            value: \"4\"\n"
"          - name: MC_TE_METRIC\n"
"            value: \"true\"\n"
"          - name: NCCL_IB_SL\n"
"            value: \"5\"\n"
"          - name: LWS_WORKER_INDEX\n"
"            valueFrom:\n"
"              fieldRef:\n"
"                fieldPath: metadata.labels['leaderworkerset.sigs.k8s.io/"
"worker-index']\n"
"          image: lmsysorg/sglang:deepep\n"
"          name: sglang-worker\n"
"          ports:\n"
"          - containerPort: 30001\n"
"            protocol: TCP\n"
"          resources:\n"
"            limits:\n"
"              nvidia.com/gpu: \"8\"\n"
"          securityContext:\n"
"            capabilities:\n"
"              add:\n"
"              - IPC_LOCK\n"
"            privileged: true\n"
"          volumeMounts:\n"
"\n"
"          - mountPath: /root/.cache\n"
"            name: sgl-cache\n"
"          - mountPath: /dev/shm\n"
"            name: dshm\n"
"          - mountPath: /work/models\n"
"            name: model\n"
"          - mountPath: /dev/infiniband\n"
"            name: ib\n"
"          - mountPath: /sgl-workspace/sglang/python/sglang/srt/layers/moe/"
"fused_moe_triton/configs\n"
"            name: cf\n"
"        dnsPolicy: ClusterFirstWithHostNet\n"
"        hostIPC: true\n"
"        hostNetwork: true\n"
"        nodeSelector:\n"
"          pd: \"yes\"\n"
"        tolerations:\n"
"        - key: pd\n"
"          operator: Exists\n"
"        - key: node-role\n"
"          operator: Exists\n"
"        volumes:\n"
"        - emptyDir:\n"
"            medium: Memory\n"
"          name: dshm\n"
"        - hostPath:\n"
"            path: /dev/infiniband\n"
"          name: ib\n"
"        - hostPath:\n"
"            path: /data1/maas_hosted_models/models/DeepSeek-R1-0528/"
"deepseek_r1_0528\n"
"          name: model\n"
"        - hostPath:\n"
"            path: /data1/maas_hosted_models/models/fused_moe_triton/configs\n"
"          name: cf\n"
"        - hostPath:\n"
"            path: /data1/sgl_cache\n"
"            type: DirectoryOrCreate\n"
"          name: sgl-cache\n"
"\n"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:337
msgid "Decode"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:339
msgid "Decode node deployment manifest file [decode.yaml](lws-examples/d.yaml)"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:343
msgid ""
"apiVersion: leaderworkerset.x-k8s.io/v1\n"
"kind: LeaderWorkerSet\n"
"metadata:\n"
"  name: deepseekr10528-decode-main\n"
"spec:\n"
"  leaderWorkerTemplate:\n"
"    leaderTemplate:\n"
"      metadata:\n"
"        labels:\n"
"          role: leader\n"
"      spec:\n"
"        containers:\n"
"        - command:\n"
"          - python3\n"
"          - -m\n"
"          - sglang.launch_server\n"
"          - --port\n"
"          - \"30000\"\n"
"          - --host\n"
"          - \"0.0.0.0\"\n"
"          - --model-path\n"
"          - /work/models\n"
"          - --chunked-prefill-size\n"
"          - \"262144\"\n"
"          - --page-size\n"
"          - \"64\"\n"
"          - --enable-dp-attention\n"
"          - --enable-dp-lm-head\n"
"          - --dp-size\n"
"          - \"16\"\n"
"          - --moe-a2a-backend\n"
"          - deepep\n"
"          - --disaggregation-mode\n"
"          - decode\n"
"          - --mem-fraction-static\n"
"          -  \"0.849\"\n"
"          - --context-length\n"
"          - \"32768\"\n"
"          - --disaggregation-ib-device\n"
"          - \"mlx5_bond_0,mlx5_bond_1,mlx5_bond_2,mlx5_bond_3\"\n"
"          - --cuda-graph-max-bs\n"
"          - \"64\"\n"
"          - --max-running-requests\n"
"          - \"2048\"\n"
"          - --tp-size\n"
"          - \"16\" # Size of Tensor Parallelism\n"
"          - --dist-init-addr\n"
"          - $(LWS_LEADER_ADDRESS):20102\n"
"          - --nnodes\n"
"          - $(LWS_GROUP_SIZE)\n"
"          - --node-rank\n"
"          - $(LWS_WORKER_INDEX)\n"
"          - --trust-remote-code\n"
"          - --ep-num-redundant-experts\n"
"          - \"32\"\n"
"          - --moe-dense-tp-size\n"
"          - \"1\"\n"
"          env:\n"
"          - name: CUDA_LAUNCH_BLOCKING\n"
"            value: \"0\"\n"
"          - name: NVSHMEM_IB_GID_INDEX\n"
"            value: \"3\"\n"
"          - name: NVSHMEM_ENABLE_NIC_PE_MAPPING\n"
"            value: \"1\"\n"
"          - name:  NCCL_IB_QPS_PER_CONNECTION\n"
"            value: \"8\"\n"
"          - name: NCCL_IB_SPLIT_DATA_ON_QPS\n"
"            value: \"1\"\n"
"          - name: NCCL_NET_PLUGIN\n"
"            value: \"none\"\n"
"          - name: NCCL_IB_TC\n"
"            value: \"136\"\n"
"          - name: NCCL_MIN_NCHANNELS\n"
"            value: \"4\"\n"
"          - name: NCCL_IB_SL\n"
"            value: \"5\"\n"
"          - name: MC_TE_METRIC\n"
"            value: \"true\"\n"
"          - name: SGLANG_MOONCAKE_TRANS_THREAD\n"
"            value: \"16\"\n"
"          - name: SGLANG_ENABLE_JIT_DEEPGEMM\n"
"            value: \"1\"\n"
"          - name: NCCL_IB_HCA\n"
"            value: ^=mlx5_0,mlx5_5,mlx5_6\n"
"          - name: LWS_WORKER_INDEX\n"
"            valueFrom:\n"
"              fieldRef:\n"
"                fieldPath: metadata.labels['leaderworkerset.sigs.k8s.io/"
"worker-index']\n"
"          image: lmsysorg/sglang:deepep\n"
"          name: sglang-leader\n"
"          ports:\n"
"          - containerPort: 30000\n"
"            protocol: TCP\n"
"          readinessProbe:\n"
"            periodSeconds: 30\n"
"            tcpSocket:\n"
"              port: 30000\n"
"          resources:\n"
"            limits:\n"
"              nvidia.com/gpu: \"8\"\n"
"          securityContext:\n"
"            capabilities:\n"
"              add:\n"
"              - IPC_LOCK\n"
"            privileged: true\n"
"          volumeMounts:\n"
"          - mountPath: /root/.cache\n"
"            name: sgl-cache\n"
"          - mountPath: /dev/shm\n"
"            name: dshm\n"
"          - mountPath: /work/models\n"
"            name: model\n"
"          - mountPath: /dev/infiniband\n"
"            name: ib\n"
"          - mountPath: /sgl-workspace/sglang/python/sglang/srt/layers/moe/"
"fused_moe_triton/configs\n"
"            name: cf\n"
"        dnsPolicy: ClusterFirstWithHostNet\n"
"        hostIPC: true\n"
"        hostNetwork: true\n"
"        nodeSelector:\n"
"          pd: \"yes\"\n"
"        tolerations:\n"
"        - key: pd\n"
"          operator: Exists\n"
"        - key: node-role\n"
"          operator: Exists\n"
"        volumes:\n"
"        - hostPath:\n"
"            path: /data1/sgl_cache1\n"
"            type: DirectoryOrCreate\n"
"          name: sgl-cache\n"
"        - emptyDir:\n"
"            medium: Memory\n"
"          name: dshm\n"
"        - hostPath:\n"
"            path: /data1/maas_hosted_models/models/DeepSeek-R1-0528/"
"deepseek_r1_0528\n"
"          name: model\n"
"        - hostPath:\n"
"            path: /dev/infiniband\n"
"          name: ib\n"
"        - hostPath:\n"
"            path: /data1/maas_hosted_models/models/fused_moe_triton/configs\n"
"          name: cf\n"
"    restartPolicy: RecreateGroupOnPodRestart\n"
"    size:  2\n"
"    workerTemplate:\n"
"      metadata: {}\n"
"      spec:\n"
"        containers:\n"
"        - command:\n"
"          - python3\n"
"          - -m\n"
"          - sglang.launch_server\n"
"          - --model-path\n"
"          - /work/models\n"
"          - --chunked-prefill-size\n"
"          - \"262144\"\n"
"          - --page-size\n"
"          - \"64\"\n"
"          - --enable-dp-attention\n"
"          - --enable-dp-lm-head\n"
"            #- --enable-two-batch-overlap\n"
"          - --dp-size\n"
"          - \"16\"\n"
"          - --moe-a2a-backend\n"
"          - deepep\n"
"          - --disaggregation-mode\n"
"          - decode\n"
"          - --mem-fraction-static\n"
"          -  \"0.849\"\n"
"          - --context-length\n"
"          - \"32768\"\n"
"          - --disaggregation-ib-device\n"
"          # should modify according your rdma env\n"
"          - \"mlx5_bond_0,mlx5_bond_1,mlx5_bond_2,mlx5_bond_3\"\n"
"          - --cuda-graph-max-bs\n"
"          - \"64\"\n"
"          - --max-running-requests\n"
"          - \"2048\"\n"
"          - --tp-size\n"
"          - \"16\" # Size of Tensor Parallelism\n"
"          - --dist-init-addr\n"
"          - $(LWS_LEADER_ADDRESS):20102\n"
"          - --nnodes\n"
"          - $(LWS_GROUP_SIZE)\n"
"          - --node-rank\n"
"          - $(LWS_WORKER_INDEX)\n"
"          - --trust-remote-code\n"
"          - --ep-num-redundant-experts\n"
"          - \"32\"\n"
"          - --moe-dense-tp-size\n"
"          - \"1\"\n"
"          env:\n"
"          - name: SGLANG_HACK_DEEPEP_NUM_SMS\n"
"            value: \"24\"\n"
"          - name: SGLANG_HACK_DEEPEP_NEW_MODE\n"
"            value: \"0\"\n"
"          - name: NVSHMEM_IB_TRAFFIC_CLASS\n"
"            value: \"16\"\n"
"          - name: NVSHMEM_IB_GID_INDEX\n"
"            value: \"3\"\n"
"          - name: NVSHMEM_ENABLE_NIC_PE_MAPPING\n"
"            value: \"1\"\n"
"          - name:  NCCL_IB_QPS_PER_CONNECTION\n"
"            value: \"8\"\n"
"          - name: NCCL_IB_SPLIT_DATA_ON_QPS\n"
"            value: \"1\"\n"
"          - name: NCCL_NET_PLUGIN\n"
"            value: \"none\"\n"
"          - name: NCCL_IB_TC\n"
"            value: \"136\"\n"
"          - name: NCCL_MIN_NCHANNELS\n"
"            value: \"4\"\n"
"          - name: MC_TE_METRIC\n"
"            value: \"true\"\n"
"          - name: NCCL_IB_SL\n"
"            value: \"5\"\n"
"          - name: SGLANG_MOONCAKE_TRANS_THREAD\n"
"            value: \"16\"\n"
"          - name: SGLANG_ENABLE_JIT_DEEPGEMM\n"
"            value: \"1\"\n"
"          - name: NCCL_IB_HCA\n"
"            value: ^=mlx5_0,mlx5_5,mlx5_6\n"
"          - name: LWS_WORKER_INDEX\n"
"            valueFrom:\n"
"              fieldRef:\n"
"                fieldPath: metadata.labels['leaderworkerset.sigs.k8s.io/"
"worker-index']\n"
"          image: lmsysorg/sglang:deepep\n"
"          name: sglang-worker\n"
"          ports:\n"
"          - containerPort: 30001\n"
"          resources:\n"
"            limits:\n"
"              nvidia.com/gpu: \"8\"\n"
"          securityContext:\n"
"            capabilities:\n"
"              add:\n"
"              - IPC_LOCK\n"
"            privileged: true\n"
"          volumeMounts:\n"
"          - mountPath: /root/.cache\n"
"            name: sgl-cache\n"
"          - mountPath: /dev/shm\n"
"            name: dshm\n"
"          - mountPath: /work/models\n"
"            name: model\n"
"          - mountPath: /dev/infiniband\n"
"            name: ib\n"
"          - mountPath: /sgl-workspace/sglang/python/sglang/srt/layers/moe/"
"fused_moe_triton/configs\n"
"            name: cf\n"
"        dnsPolicy: ClusterFirstWithHostNet\n"
"        hostIPC: true\n"
"        hostNetwork: true\n"
"        nodeSelector:\n"
"          pd: \"yes\"\n"
"        tolerations:\n"
"        - key: pd\n"
"          operator: Exists\n"
"        - key: node-role\n"
"          operator: Exists\n"
"        volumes:\n"
"        - hostPath:\n"
"            path: /data1/sgl_cache1\n"
"            type: DirectoryOrCreate\n"
"          name: sgl-cache\n"
"        - emptyDir:\n"
"            medium: Memory\n"
"          name: dshm\n"
"        - hostPath:\n"
"            path: /dev/infiniband\n"
"          name: ib\n"
"        - hostPath:\n"
"            # modify according to you deployment env\n"
"            path: /data1/maas_hosted_models/models/DeepSeek-R1-0528/"
"deepseek_r1_0528\n"
"          name: model\n"
"        - hostPath:\n"
"            # modify according to you deployment env\n"
"            path: /data1/maas_hosted_models/models/fused_moe_triton/configs\n"
"          name: cf\n"
"  networkConfig:\n"
"    subdomainPolicy: Shared\n"
"  replicas: 1\n"
"  rolloutStrategy:\n"
"    rollingUpdateConfiguration:\n"
"      maxSurge: 0\n"
"      maxUnavailable: 1\n"
"    type: RollingUpdate\n"
"  startupPolicy: LeaderCreated\n"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:634
msgid "Execute separately:"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:636
msgid ""
"kubectl apply -f p.yaml\n"
"kubectl apply -f d.yaml\n"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:641
msgid ""
"At this point, we have completed the deployment of the 1P1D SGlang engine "
"part."
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:643
msgid ""
"To allow our users to directly experience the model API, we still need a "
"load balancer to handle sequential calls between prefill and decode. "
"Different companies implement LBs differently, and the community will also "
"officially release a new LB component written in Rust in the near future."
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:645
msgid ""
"Currently, we use a static K8S service + minilb approach to implement model "
"API calls."
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:647
msgid "Creating Service for Prefill and Decode"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:649
msgid "Create prefill k8s service"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:650
msgid "[p-svc.yaml](lws-examples/p-svc.yaml)"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:651
msgid ""
"apiVersion: v1\n"
"kind: Service\n"
"metadata:\n"
"  name: deepseekr10528-prefill-main\n"
"spec:\n"
"  selector:\n"
"    leaderworkerset.sigs.k8s.io/name: deepseekr10528-prefill-main\n"
"    role: leader\n"
"  ports:\n"
"    - protocol: TCP\n"
"      port: 30000\n"
"      targetPort: 30000\n"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:665
msgid "Execute `kubectl apply -f p-svc.yaml`"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:667
msgid "Create decode k8s service"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:668
msgid "[d-svc.yaml](lws-examples/d-svc.yaml)"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:669
msgid ""
"apiVersion: v1\n"
"kind: Service\n"
"metadata:\n"
"  name: deepseekr10528-decode-main\n"
"spec:\n"
"  selector:\n"
"    leaderworkerset.sigs.k8s.io/name: deepseekr10528-decode-main\n"
"    role: leader\n"
"  ports:\n"
"    - protocol: TCP\n"
"      port: 30000\n"
"      targetPort: 30000\n"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:683
msgid "Execute `kubectl apply -f d-svc.yaml`"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:685
msgid "Deploy minilb and lb service"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:686
msgid "[lb.yaml](lws-examples/lb.yaml)"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:687
msgid ""
"apiVersion: apps/v1\n"
"kind: Deployment\n"
"metadata:\n"
"  name: deepseekr10528-lb-main\n"
"  labels:\n"
"    app: deepseekr10528-lb\n"
"spec:\n"
"  replicas: 1\n"
"  selector:\n"
"    matchLabels:\n"
"      app: deepseekr10528-lb\n"
"  template:\n"
"    metadata:\n"
"      labels:\n"
"        app: deepseekr10528-lb\n"
"    spec:\n"
"      nodeSelector:\n"
"          pd: \"yes\"\n"
"      tolerations:\n"
"        - key: pd\n"
"          operator: Exists\n"
"        - key: node-role\n"
"          operator: Exists\n"
"      containers:\n"
"        - name: sgl-minilb\n"
"          image: lmsysorg/sglang:deepep\n"
"          command:\n"
"          - python\n"
"          - -m\n"
"          - sglang_router.launch_router\n"
"          - --pd-disaggregation\n"
"          - --prefill\n"
"          - http://deepseekr10528-prefill-main:30000\n"
"          - --decode\n"
"          - http://deepseekr10528-decode-main:30000\n"
"          - --host\n"
"          - 0.0.0.0\n"
"          - --port\n"
"          -  \"8000\"\n"
"          ports:\n"
"            - containerPort: 8000\n"
"---\n"
"apiVersion: v1\n"
"kind: Service\n"
"metadata:\n"
"  name: deepseekr10528-lb-service\n"
"spec:\n"
"  type: NodePort\n"
"  selector:\n"
"    app: deepseekr10528-lb\n"
"  ports:\n"
"    - protocol: TCP\n"
"      port: 8000         # Service PortÔºàIn-ClusterÔºâ\n"
"      targetPort: 8000   # Exposed Container\n"
"      nodePort: 30800\n"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:744
msgid "Execute `kubectl apply -f lb.yaml`"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:746
msgid ""
"After waiting for all model deployments to succeed, you will get the "
"following output:"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:748
msgid ""
"[root@ecs-001]# kubectl get po\n"
"deepseekr10528-decode-main-0             1/1     Running   0          74m\n"
"deepseekr10528-decode-main-0-1           1/1     Running   0          74m\n"
"deepseekr10528-lb-main-9c5dbfc57-6lcbd   1/1     Running   0          22m\n"
"deepseekr10528-prefill-main-0            1/1     Running   0          74m\n"
"deepseekr10528-prefill-main-0-1          1/1     Running   0          74m\n"
"[root@ecs-cbm-x1-pd-cpu-001 main_doc]# kubectl  get svc |grep dee\n"
"deepseekr10528-decode-main    ClusterIP   None             <none>        "
"<none>           97m\n"
"deepseekr10528-lb-service     NodePort    172.16.242.169   <none>        "
"8000:30800/TCP   22m\n"
"deepseekr10528-prefill-main   ClusterIP   None             <none>        "
"<none>           97m\n"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:761
msgid "At this point, select a nodePort:30800 to access:"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:763
msgid ""
"[root@ecs-001]# curl -X POST \"http://{nodePort}:30800/v1/chat/completions\" "
"\\\n"
">     -H \"Content-Type: application/json\" \\\n"
">     -H \"Authorization: Bearer None\" \\\n"
">     -d '{\n"
">        \"rid\":\"ccccdd\",\n"
">         \"model\": \"r1\",\n"
">         \"messages\": [\n"
">             {\"role\": \"system\", \"content\": \"0: You are a helpful AI "
"assistant\"},\n"
">             {\"role\": \"user\", \"content\": \"‰Ω†ÊòØË∞ÅÔºü.\"}\n"
">         ],\n"
">         \"max_tokens\":221\n"
">     }'\n"
"{\"id\":\"ccccdd\",\"object\":\"chat.completion\",\"created\":1750252498,"
"\"model\":\"qwen2\",\"choices\":[{\"index\":0,\"message\":{\"role\":"
"\"assistant\",\"content\":\"<think>\\nÂóØÔºåÁî®Êà∑ÈóÆ‰∫Ü‰∏Ä‰∏™ÂæàÂü∫Á°ÄÁöÑËá™Êàë‰ªãÁªçÈóÆÈ¢ò"
"\"‰Ω†ÊòØË∞ÅÔºü\"„ÄÇËøôÂèØËÉΩÊòØÁ¨¨‰∏ÄÊ¨°‰∫íÂä®Êó∂ÁöÑÂ∏∏ËßÑÂºÄÂú∫ÁôΩÔºå‰πüÂèØËÉΩÊòØÊÉ≥Á°ÆËÆ§ÊàëÁöÑË∫´‰ªΩÂíåÂäüËÉΩ"
"ËåÉÂõ¥„ÄÇ\\n\\nÁî®Êà∑Ê≤°ÊúâÊèê‰æõ‰ªª‰ΩïËÉåÊôØ‰ø°ÊÅØÔºåËØ≠Ê∞îÁÆÄÊ¥Å‰∏≠ÊÄß„ÄÇËøôÁßçÂú∫ÊôØ‰∏ãÊñ∞Áî®Êà∑ÁöÑÂèØËÉΩÊÄß"
"ËæÉÈ´òÔºåÈúÄË¶ÅÁªôÂá∫Ê∏ÖÊô∞ÂèãÂ•ΩÁöÑËá™Êàë‰ªãÁªçÔºåÂêåÊó∂Á™ÅÂá∫ÂÆûÁî®‰ª∑ÂÄºÊù•Èôç‰ΩéÈôåÁîüÊÑü„ÄÇ\\n\\nËÄÉËôëÂà∞"
"‰∏≠ÊñáÁî®Êà∑ÔºåÂ∫îËØ•Áî®ÁÆÄ‰Ωì‰∏≠ÊñáÂõûÂ§ç„ÄÇÈáçÁÇπË¶ÅËØ¥Êòé‰∏âÁÇπÔºöË∫´‰ªΩÂΩíÂ±ûÔºàÊ∑±Â∫¶Ê±ÇÁ¥¢Ôºâ„ÄÅÂäüËÉΩÂÆö‰Ωç"
"ÔºàAIÂä©ÊâãÔºâ„ÄÅÊúçÂä°ËåÉÂõ¥ÔºàÂ≠¶‰π†/Â∑•‰Ωú/ÁîüÊ¥ªÔºâ„ÄÇÁªìÂ∞æÁî®ÂºÄÊîæÊÄßÈóÆÈ¢òÂºïÂØºÂØπËØùÂæàÂÖ≥ÈîÆ‚Äî‚ÄîÊó¢ËÉΩ"
"‰∫ÜËß£ÈúÄÊ±ÇÔºåÂèàËÉΩÈÅøÂÖçËÆ©Áî®Êà∑Èù¢ÂØπÁ©∫ÁôΩËæìÂÖ•Ê°ÜÊó∂‰∏çÁü•ÊâÄÊé™„ÄÇ\\n\\nÁî®Ê≥¢Êµ™Á∫øÁªìÂ∞æÂèØ‰ª•ËΩØÂåñ"
"ËØ≠Ê∞îÔºåÈÇ£‰∏™Á¨ëËÑ∏Ë°®ÊÉÖüòäÂàöÂ•ΩËÉΩ‰∏≠ÂíåAIÁöÑÊú∫Ê¢∞ÊÑü„ÄÇ‰∏çËøáË¶ÅÊéßÂà∂Ë°®ÊÉÖÁ¨¶Âè∑Êï∞ÈáèÔºåÈÅøÂÖçÊòæÂæóËΩª"
"ÊµÆ„ÄÇ\\n</think>\\n‰Ω†Â•ΩÂëÄÔºÅÊàëÊòØ‰Ω†ÁöÑAIÂä©ÊâãÔºåÁî±Ê∑±Â∫¶Ê±ÇÁ¥¢ÂÖ¨Âè∏ÔºàDeepSeekÔºâÂºÄÂèëÁöÑËØ≠"
"Ë®ÄÊ®°ÂûãÔºåÂêçÂ≠óÂè´ **DeepSeek-R1**„ÄÇ‰Ω†ÂèØ‰ª•ÊääÊàëÂΩìÊàê‰∏Ä‰∏™Áü•ËØÜ‰∏∞ÂØå„ÄÅÈöèÂè´ÈöèÂà∞ÁöÑÂ∞èÂ∏ÆÊâã"
"ÔΩûüòä\\n\\nÊàëÁöÑ‰ªªÂä°Â∞±ÊòØÈô™‰Ω†ËÅäÂ§©„ÄÅËß£Á≠îÈóÆÈ¢ò„ÄÅ\",\"reasoning_content\":null,"
"\"tool_calls\":null},\"logprobs\":null,\"finish_reason\":\"length\","
"\"matched_stop\":null}],\"usage\":{\"prompt_tokens\":14,\"total_tokens\":235,"
"\"completion_tokens\":221,\"prompt_tokens_details\":null}}\n"
"\n"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:779
msgid "FAQ"
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:781
msgid ""
"The current deployment startup parameters may not be fully compatible with "
"all RDMA scenarios. Different RDMA NCCL-related environment configurations "
"may be needed in different network environments."
msgstr ""

#: ../../../references/multi_node_deployment/lws_pd/lws_pd_deploy.md:783
msgid ""
"Some preset, optimized configurations for EPLB are not used here. You can "
"adjust them according to [6017](https://github.com/sgl-project/sglang/"
"issues/6017) as needed."
msgstr ""
